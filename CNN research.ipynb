{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35018dbf-f7f1-4415-bf0a-b92c3638cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "import io\n",
    "import imageio\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12950e-baa9-4455-b617-b1c600f6336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'A://workspace//datasets//tiny_imagenet//train.parquet'\n",
    "dir_valid = 'A://workspace//datasets//tiny_imagenet//valid.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82ff8d-8919-4f26-bffe-78e3bbb52606",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_parquet(dir_train, engine='pyarrow')\n",
    "valid_dataset = pd.read_parquet(dir_valid, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9baf2-60f8-4e40-8454-ff92f40b3356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['image_matrix'] = train_dataset['image'].apply(lambda x: np.array(Image.open(io.BytesIO(x['bytes']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ee2f7-0a6e-41d7-8a97-7987c4594a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in train_dataset['image_matrix'][:4500:500].items():\n",
    "    ax = plt.subplot(3, 3, i//500 + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ff06d-665f-4064-8a8a-401f3d99ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset['image_matrix'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bffabc-d42f-4d04-97c3-8e3351f30242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check count and amount of classes\n",
    "labels_count = list(train_dataset['label'].value_counts())\n",
    "len(labels_count), set(labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70f399-98a9-40ba-80b6-ccacb9b3cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset with stratify\n",
    "img_train_orig, img_test_orig, label_train, label_test = train_test_split(train_dataset['image_matrix'], train_dataset['label'], test_size=0.2, random_state=42,\n",
    "                                                               stratify=train_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6989dcd-8481-49d3-95b3-9654b7933f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_orig.shape, label_train.shape, img_test_orig.shape, label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1996d3-3663-448e-ac0e-d5bbe7c7332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenter():\n",
    "    data_augmentation = tf.keras.Sequential()\n",
    "    data_augmentation.add(RandomFlip(\"horizontal\"))\n",
    "    data_augmentation.add(RandomFlip(\"vertical\"))\n",
    "    data_augmentation.add(RandomRotation(0.2))\n",
    "    data_augmentation.add(RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)))\n",
    "    \n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc4d1c-85b3-4ee6-be91-5b6b167c0c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = data_augmenter()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "first_image = img_train_orig.iloc[3]\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77851d21-edfd-4abc-a067-d09c8223a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train_orig/255\n",
    "img_test = img_test_orig/255\n",
    "\n",
    "img_train = (np.repeat(im[:, :, np.newaxis], 3, axis=2) if im.shape == (64,64) else im for im in img_train)\n",
    "img_test = (np.repeat(im[:, :, np.newaxis], 3, axis=2) if im.shape == (64,64) else im for im in img_test)\n",
    "\n",
    "img_train = np.stack(list(img_train))\n",
    "img_test = np.stack(list(img_test))\n",
    "\n",
    "img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebfbaa-0cca-40d5-9c6f-cd73a40533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = pd.get_dummies(label_train, dtype='float32')\n",
    "label_test= pd.get_dummies(label_test, dtype='float32')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    label_train = tf.convert_to_tensor(label_train.values, np.float32)\n",
    "    label_test = tf.convert_to_tensor(label_test.values, np.float32)\n",
    "    img_train = tf.convert_to_tensor(img_train, np.float32)\n",
    "    img_test = tf.convert_to_tensor(img_test, np.float32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((img_train, label_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((img_test, label_test)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2af339-56ba-4764-a5c0-c7df0bd72275",
   "metadata": {},
   "source": [
    "# Написать блоки кода, чтобы можно было через цикл собирать модели и тестить. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d3421-127d-4c3e-a7c7-1763daeb2a09",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d401b-0a44-4211-8fc7-1a6e46c89bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    \n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    \n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    \n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    \n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73011e9-d101-4a9a-a7f3-2041a2702adb",
   "metadata": {},
   "source": [
    "# Лучшие модели\n",
    "## Порядок слоев\n",
    "- Conv\n",
    "- Batch\n",
    "- Relu?\n",
    "- MaxPool\n",
    "- DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af1465-ec95-4563-82aa-03c2da505ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 20\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(units=2048, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd69fb7-4a76-41a5-860d-e3b071ab795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011016d-78d2-4ec9-85ba-65443841c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1a1bf-3ca1-4c82-ba50-b175a3e5f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 30\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e848cc4-d274-4354-94ae-06ec8de18dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 40\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3c230b-f8f4-4f2a-a69c-c6a88385b5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilyau\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom\n",
    "import io\n",
    "import imageio\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee43a76d-0a72-4ffe-8ed0-8c534b995d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow-gpu==2.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba19ad0-3e03-42e4-869b-4c7dc02e8da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc57614-8cc7-4fe0-9be0-ccc95c54fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train = 'A://workspace//datasets//tiny_imagenet//train.parquet'\n",
    "dir_valid = 'A://workspace//datasets//tiny_imagenet//valid.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f1b8c8-b93f-41c3-9cde-24ded34b1ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_parquet(dir_train, engine='pyarrow')\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040c61ab-eaae-4be7-beb0-600f2f3aaca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = pd.read_parquet(dir_valid, engine='pyarrow')\n",
    "valid_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8d94e7-e0c4-42ee-aad9-73d9f90dfc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14 s\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>image_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[255, 136, 193], [255, 138, 192], [249, 146,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[20, 33, 7], [19, 32, 6], [23, 31, 10], [28,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[120, 124, 127], [89, 93, 96], [80, 84, 87],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[144, 170, 245], [121, 147, 221], [140, 166,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[144, 145, 147], [141, 142, 144], [140, 140,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label  \\\n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0   \n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0   \n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0   \n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0   \n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0   \n",
       "\n",
       "                                        image_matrix  \n",
       "0  [[[255, 136, 193], [255, 138, 192], [249, 146,...  \n",
       "1  [[[20, 33, 7], [19, 32, 6], [23, 31, 10], [28,...  \n",
       "2  [[[120, 124, 127], [89, 93, 96], [80, 84, 87],...  \n",
       "3  [[[144, 170, 245], [121, 147, 221], [140, 166,...  \n",
       "4  [[[144, 145, 147], [141, 142, 144], [140, 140,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_dataset['image_matrix'] = train_dataset['image'].apply(lambda x: np.array(Image.open(io.BytesIO(x['bytes']))))\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d6a88a-d1c5-4730-8e7e-c23a9878890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in train_dataset['image_matrix'][:4500:500].items():\n",
    "    ax = plt.subplot(3, 3, i//500 + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8f58a8f-0c2d-45ac-a4d0-1b5bf8f3fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['image_matrix'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfc63df0-a736-45ed-921c-6cf261c9c864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, {500})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check count and amount of classes\n",
    "labels_count = list(train_dataset['label'].value_counts())\n",
    "len(labels_count), set(labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346bd87c-9ed1-4c47-b0cc-dc003e5aaf49",
   "metadata": {},
   "source": [
    "Split train into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6cbc3d0-283f-412d-8aab-bae855c04d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset with stratify\n",
    "img_train_orig, img_test_orig, label_train, label_test = train_test_split(train_dataset['image_matrix'], train_dataset['label'], test_size=0.2, random_state=42,\n",
    "                                                               stratify=train_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b1283e-f579-416f-9c5a-7df57d8c1982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000,), (80000,), (20000,), (20000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train_orig.shape, label_train.shape, img_test_orig.shape, label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f52a4e-1287-454c-b5ea-05df0faf862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmenter():\n",
    "    data_augmentation = tf.keras.Sequential()\n",
    "    data_augmentation.add(RandomFlip(\"horizontal\"))\n",
    "    data_augmentation.add(RandomFlip(\"vertical\"))\n",
    "    data_augmentation.add(RandomRotation(0.2))\n",
    "    data_augmentation.add(RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)))\n",
    "    \n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c59b0f30-c698-4d93-ba4e-67de4a3c8897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_augmentation = data_augmenter()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "first_image = img_train_orig.iloc[3]\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7369344-964d-4d16-bb0f-a18ecc0ef612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x225c973c370>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_augmentation(tf.expand_dims(first_image, 0))[0]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec9843af-0b10-4f6d-8535-1dfec98aa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_one_hot(Y, C):\n",
    "#     Y = np.eye(C)[Y.reshape(-1)].T\n",
    "#     return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca002ea-cb81-473b-b3de-15748fa2f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train_orig/255\n",
    "img_test = img_test_orig/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db900cbb-c26a-44d6-b4b7-6f5d50d00e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = (np.repeat(im[:, :, np.newaxis], 3, axis=2) if im.shape == (64,64) else im for im in img_train)\n",
    "img_test = (np.repeat(im[:, :, np.newaxis], 3, axis=2) if im.shape == (64,64) else im for im in img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f34653d-9c9b-4afb-b851-6184f32b5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = np.stack(list(img_train))\n",
    "img_test = np.stack(list(img_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "868d3829-3bf9-4284-8526-f3c4a237b219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 64, 64, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "217db7d0-b865-423c-819f-f85e9a12f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = pd.get_dummies(label_train, dtype='float32')\n",
    "label_test= pd.get_dummies(label_test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d853fd-b14c-4e8c-b57c-1ebb8fa278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    label_train = tf.convert_to_tensor(label_train.values, np.float32)\n",
    "    label_test = tf.convert_to_tensor(label_test.values, np.float32)\n",
    "    img_train = tf.convert_to_tensor(img_train, np.float32)\n",
    "    img_test = tf.convert_to_tensor(img_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5870686-5c14-46d6-9a39-2a7f0600f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((img_train, label_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((img_test, label_test)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0df537e8-32da-459d-b3d8-b606b7b360e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 64, 64, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 64, 64, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 262144)            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 200)               52429000  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,452,584\n",
      "Trainable params: 52,452,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 16 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10708124-7213-4ca0-8a0d-c54a0bbfec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731,848\n",
      "Trainable params: 1,731,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ffca0c2-8d86-4538-ad11-eb304fe5de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 17s 11ms/step - loss: 4.8675 - accuracy: 0.0477 - val_loss: 4.7219 - val_accuracy: 0.0768\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 4.4346 - accuracy: 0.1015 - val_loss: 4.5772 - val_accuracy: 0.1028\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 4.2624 - accuracy: 0.1234 - val_loss: 4.5490 - val_accuracy: 0.1172\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 4.1565 - accuracy: 0.1393 - val_loss: 4.4902 - val_accuracy: 0.1279\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 4.0719 - accuracy: 0.1508 - val_loss: 4.4693 - val_accuracy: 0.1311\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.9959 - accuracy: 0.1621 - val_loss: 4.4179 - val_accuracy: 0.1381\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.9286 - accuracy: 0.1718 - val_loss: 4.4146 - val_accuracy: 0.1412\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.8657 - accuracy: 0.1804 - val_loss: 4.3564 - val_accuracy: 0.1478\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.8115 - accuracy: 0.1890 - val_loss: 4.3328 - val_accuracy: 0.1525\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.7567 - accuracy: 0.1984 - val_loss: 4.3073 - val_accuracy: 0.1561\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.7105 - accuracy: 0.2045 - val_loss: 4.2883 - val_accuracy: 0.1606\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.6642 - accuracy: 0.2130 - val_loss: 4.2672 - val_accuracy: 0.1646\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.6192 - accuracy: 0.2192 - val_loss: 4.3091 - val_accuracy: 0.1631\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.5806 - accuracy: 0.2262 - val_loss: 4.3047 - val_accuracy: 0.1640\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.5406 - accuracy: 0.2332 - val_loss: 4.3521 - val_accuracy: 0.1639\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.5065 - accuracy: 0.2381 - val_loss: 4.3378 - val_accuracy: 0.1673\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.4731 - accuracy: 0.2442 - val_loss: 4.3433 - val_accuracy: 0.1697\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.4414 - accuracy: 0.2497 - val_loss: 4.3467 - val_accuracy: 0.1691\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.4113 - accuracy: 0.2569 - val_loss: 4.3547 - val_accuracy: 0.1711\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.3786 - accuracy: 0.2607 - val_loss: 4.3943 - val_accuracy: 0.1666\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.3564 - accuracy: 0.2645 - val_loss: 4.3747 - val_accuracy: 0.1712\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 3.3256 - accuracy: 0.2684 - val_loss: 4.4404 - val_accuracy: 0.1695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset,epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0280a66-fe8c-4a1b-8ea0-3b7cc077a6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,390,664\n",
      "Trainable params: 4,390,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec500ba6-57b2-49b5-bcad-4ed696104ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.9278 - accuracy: 0.0383 - val_loss: 4.7290 - val_accuracy: 0.0657\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.4928 - accuracy: 0.0883 - val_loss: 4.5236 - val_accuracy: 0.0970\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.2968 - accuracy: 0.1119 - val_loss: 4.4762 - val_accuracy: 0.1067\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.1635 - accuracy: 0.1302 - val_loss: 4.4653 - val_accuracy: 0.1160\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.0678 - accuracy: 0.1423 - val_loss: 4.4440 - val_accuracy: 0.1211\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.9899 - accuracy: 0.1544 - val_loss: 4.4124 - val_accuracy: 0.1276\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.9205 - accuracy: 0.1647 - val_loss: 4.4011 - val_accuracy: 0.1312\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.8577 - accuracy: 0.1745 - val_loss: 4.3620 - val_accuracy: 0.1393\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.8000 - accuracy: 0.1818 - val_loss: 4.3424 - val_accuracy: 0.1412\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.7442 - accuracy: 0.1909 - val_loss: 4.2853 - val_accuracy: 0.1473\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.6969 - accuracy: 0.1990 - val_loss: 4.2747 - val_accuracy: 0.1514\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.6472 - accuracy: 0.2063 - val_loss: 4.3014 - val_accuracy: 0.1494\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.6022 - accuracy: 0.2138 - val_loss: 4.2527 - val_accuracy: 0.1549\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.5570 - accuracy: 0.2209 - val_loss: 4.2929 - val_accuracy: 0.1532\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.5159 - accuracy: 0.2279 - val_loss: 4.2696 - val_accuracy: 0.1564\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.4768 - accuracy: 0.2332 - val_loss: 4.2806 - val_accuracy: 0.1585\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.4359 - accuracy: 0.2407 - val_loss: 4.3026 - val_accuracy: 0.1572\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.4034 - accuracy: 0.2466 - val_loss: 4.2633 - val_accuracy: 0.1613\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3658 - accuracy: 0.2522 - val_loss: 4.2809 - val_accuracy: 0.1631\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.3346 - accuracy: 0.2601 - val_loss: 4.2537 - val_accuracy: 0.1656\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.2959 - accuracy: 0.2653 - val_loss: 4.2375 - val_accuracy: 0.1681\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.2653 - accuracy: 0.2703 - val_loss: 4.2520 - val_accuracy: 0.1687\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.2381 - accuracy: 0.2752 - val_loss: 4.2712 - val_accuracy: 0.1702\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.2080 - accuracy: 0.2796 - val_loss: 4.2607 - val_accuracy: 0.1711\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.1798 - accuracy: 0.2842 - val_loss: 4.2300 - val_accuracy: 0.1735\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.1511 - accuracy: 0.2892 - val_loss: 4.2196 - val_accuracy: 0.1772\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.1192 - accuracy: 0.2945 - val_loss: 4.2685 - val_accuracy: 0.1729\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.0974 - accuracy: 0.2994 - val_loss: 4.2882 - val_accuracy: 0.1743\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.0736 - accuracy: 0.3025 - val_loss: 4.2015 - val_accuracy: 0.1831\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.0456 - accuracy: 0.3086 - val_loss: 4.2206 - val_accuracy: 0.1812\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 3.0227 - accuracy: 0.3124 - val_loss: 4.2114 - val_accuracy: 0.1824\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.9988 - accuracy: 0.3158 - val_loss: 4.3026 - val_accuracy: 0.1773\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.9739 - accuracy: 0.3225 - val_loss: 4.2365 - val_accuracy: 0.1851\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.9582 - accuracy: 0.3251 - val_loss: 4.2952 - val_accuracy: 0.1805\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.9344 - accuracy: 0.3280 - val_loss: 4.2203 - val_accuracy: 0.1867\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.9104 - accuracy: 0.3339 - val_loss: 4.2949 - val_accuracy: 0.1848\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.8893 - accuracy: 0.3373 - val_loss: 4.2434 - val_accuracy: 0.1887\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.8684 - accuracy: 0.3414 - val_loss: 4.2486 - val_accuracy: 0.1863\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 2.8482 - accuracy: 0.3455 - val_loss: 4.2686 - val_accuracy: 0.1874\n"
     ]
    }
   ],
   "source": [
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "375c1805-bf1d-415e-9f56-7b2585699418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731,848\n",
      "Trainable params: 1,731,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.8717 - accuracy: 0.0478 - val_loss: 4.6793 - val_accuracy: 0.0767\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.4468 - accuracy: 0.0992 - val_loss: 4.5180 - val_accuracy: 0.1053\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.2674 - accuracy: 0.1224 - val_loss: 4.4413 - val_accuracy: 0.1205\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.1467 - accuracy: 0.1396 - val_loss: 4.3847 - val_accuracy: 0.1293\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.0538 - accuracy: 0.1533 - val_loss: 4.3379 - val_accuracy: 0.1385\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.9800 - accuracy: 0.1637 - val_loss: 4.3003 - val_accuracy: 0.1460\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.9198 - accuracy: 0.1713 - val_loss: 4.2659 - val_accuracy: 0.1507\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.8591 - accuracy: 0.1820 - val_loss: 4.2650 - val_accuracy: 0.1548\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.8149 - accuracy: 0.1892 - val_loss: 4.2409 - val_accuracy: 0.1596\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.7643 - accuracy: 0.1978 - val_loss: 4.2306 - val_accuracy: 0.1613\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.7192 - accuracy: 0.2045 - val_loss: 4.2211 - val_accuracy: 0.1650\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.6763 - accuracy: 0.2105 - val_loss: 4.1892 - val_accuracy: 0.1692\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.6391 - accuracy: 0.2162 - val_loss: 4.1953 - val_accuracy: 0.1699\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5988 - accuracy: 0.2233 - val_loss: 4.2161 - val_accuracy: 0.1680\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5642 - accuracy: 0.2285 - val_loss: 4.1940 - val_accuracy: 0.1729\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5272 - accuracy: 0.2344 - val_loss: 4.2030 - val_accuracy: 0.1735\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4978 - accuracy: 0.2401 - val_loss: 4.1951 - val_accuracy: 0.1772\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4596 - accuracy: 0.2466 - val_loss: 4.1677 - val_accuracy: 0.1791\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4303 - accuracy: 0.2506 - val_loss: 4.2121 - val_accuracy: 0.1754\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3979 - accuracy: 0.2570 - val_loss: 4.2243 - val_accuracy: 0.1771\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3753 - accuracy: 0.2623 - val_loss: 4.1924 - val_accuracy: 0.1813\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3430 - accuracy: 0.2661 - val_loss: 4.1934 - val_accuracy: 0.1847\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3157 - accuracy: 0.2707 - val_loss: 4.2354 - val_accuracy: 0.1815\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.2912 - accuracy: 0.2736 - val_loss: 4.2240 - val_accuracy: 0.1822\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.2669 - accuracy: 0.2784 - val_loss: 4.2265 - val_accuracy: 0.1840\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.2415 - accuracy: 0.2840 - val_loss: 4.2185 - val_accuracy: 0.1830\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.2209 - accuracy: 0.2876 - val_loss: 4.2268 - val_accuracy: 0.1859\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.2028 - accuracy: 0.2902 - val_loss: 4.2653 - val_accuracy: 0.1830\n"
     ]
    }
   ],
   "source": [
    "# # stride = 2 valid\n",
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1d86e8a-3c1c-49d8-bb74-8539a7d6f146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731,848\n",
      "Trainable params: 1,731,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 4.8512 - accuracy: 0.0496 - val_loss: 4.6970 - val_accuracy: 0.0759\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.4220 - accuracy: 0.1020 - val_loss: 4.5516 - val_accuracy: 0.1054\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.2545 - accuracy: 0.1248 - val_loss: 4.5470 - val_accuracy: 0.1133\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.1469 - accuracy: 0.1407 - val_loss: 4.4915 - val_accuracy: 0.1240\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 4.0653 - accuracy: 0.1526 - val_loss: 4.4494 - val_accuracy: 0.1297\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.9948 - accuracy: 0.1630 - val_loss: 4.4007 - val_accuracy: 0.1388\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.9331 - accuracy: 0.1711 - val_loss: 4.3889 - val_accuracy: 0.1412\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.8722 - accuracy: 0.1805 - val_loss: 4.3444 - val_accuracy: 0.1478\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.8182 - accuracy: 0.1886 - val_loss: 4.3058 - val_accuracy: 0.1540\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.7654 - accuracy: 0.1972 - val_loss: 4.2989 - val_accuracy: 0.1566\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.7200 - accuracy: 0.2028 - val_loss: 4.2527 - val_accuracy: 0.1622\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.6748 - accuracy: 0.2105 - val_loss: 4.2476 - val_accuracy: 0.1638\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.6319 - accuracy: 0.2177 - val_loss: 4.2462 - val_accuracy: 0.1634\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5873 - accuracy: 0.2231 - val_loss: 4.2589 - val_accuracy: 0.1658\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5538 - accuracy: 0.2318 - val_loss: 4.2500 - val_accuracy: 0.1683\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.5137 - accuracy: 0.2362 - val_loss: 4.3049 - val_accuracy: 0.1657\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4764 - accuracy: 0.2435 - val_loss: 4.2561 - val_accuracy: 0.1717\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4478 - accuracy: 0.2486 - val_loss: 4.3023 - val_accuracy: 0.1688\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.4128 - accuracy: 0.2535 - val_loss: 4.2813 - val_accuracy: 0.1706\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3829 - accuracy: 0.2598 - val_loss: 4.3178 - val_accuracy: 0.1709\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 3.3556 - accuracy: 0.2645 - val_loss: 4.3690 - val_accuracy: 0.1685\n"
     ]
    }
   ],
   "source": [
    "# # stride = 2 same\n",
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2782c78-dbc7-42d0-9bd2-81212c155c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731,848\n",
      "Trainable params: 1,731,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 4.8394 - accuracy: 0.0517 - val_loss: 4.7290 - val_accuracy: 0.0780\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 4.4123 - accuracy: 0.1038 - val_loss: 4.5829 - val_accuracy: 0.1020\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 4.2329 - accuracy: 0.1294 - val_loss: 4.5050 - val_accuracy: 0.1186\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 4.1233 - accuracy: 0.1431 - val_loss: 4.4811 - val_accuracy: 0.1266\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 4.0391 - accuracy: 0.1547 - val_loss: 4.4205 - val_accuracy: 0.1339\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.9678 - accuracy: 0.1662 - val_loss: 4.3933 - val_accuracy: 0.1378\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.9023 - accuracy: 0.1756 - val_loss: 4.3491 - val_accuracy: 0.1440\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.8449 - accuracy: 0.1849 - val_loss: 4.3133 - val_accuracy: 0.1488\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.7837 - accuracy: 0.1928 - val_loss: 4.3011 - val_accuracy: 0.1505\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.7355 - accuracy: 0.2020 - val_loss: 4.2787 - val_accuracy: 0.1550\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.6874 - accuracy: 0.2075 - val_loss: 4.2766 - val_accuracy: 0.1585\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.6408 - accuracy: 0.2154 - val_loss: 4.2404 - val_accuracy: 0.1663\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.5941 - accuracy: 0.2237 - val_loss: 4.2571 - val_accuracy: 0.1664\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.5557 - accuracy: 0.2298 - val_loss: 4.2522 - val_accuracy: 0.1672\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.5205 - accuracy: 0.2359 - val_loss: 4.2329 - val_accuracy: 0.1720\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.4854 - accuracy: 0.2423 - val_loss: 4.2584 - val_accuracy: 0.1711\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.4504 - accuracy: 0.2478 - val_loss: 4.2369 - val_accuracy: 0.1745\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.4206 - accuracy: 0.2535 - val_loss: 4.2770 - val_accuracy: 0.1717\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3871 - accuracy: 0.2587 - val_loss: 4.2454 - val_accuracy: 0.1757\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3683 - accuracy: 0.2619 - val_loss: 4.2728 - val_accuracy: 0.1755\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3318 - accuracy: 0.2686 - val_loss: 4.2643 - val_accuracy: 0.1786\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.3052 - accuracy: 0.2732 - val_loss: 4.2294 - val_accuracy: 0.1819\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2831 - accuracy: 0.2762 - val_loss: 4.2802 - val_accuracy: 0.1816\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2549 - accuracy: 0.2821 - val_loss: 4.2927 - val_accuracy: 0.1813\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2351 - accuracy: 0.2855 - val_loss: 4.2762 - val_accuracy: 0.1817\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.2130 - accuracy: 0.2885 - val_loss: 4.2990 - val_accuracy: 0.1841\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1909 - accuracy: 0.2917 - val_loss: 4.3250 - val_accuracy: 0.1820\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1737 - accuracy: 0.2965 - val_loss: 4.3087 - val_accuracy: 0.1820\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1470 - accuracy: 0.2999 - val_loss: 4.3080 - val_accuracy: 0.1845\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1330 - accuracy: 0.3015 - val_loss: 4.3065 - val_accuracy: 0.1861\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.1092 - accuracy: 0.3070 - val_loss: 4.2999 - val_accuracy: 0.1878\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 3.0939 - accuracy: 0.3081 - val_loss: 4.3343 - val_accuracy: 0.1862\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0ec0f07-08c1-4006-89d5-c4811fe1db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,731,848\n",
      "Trainable params: 1,731,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 5.0520 - accuracy: 0.0252 - val_loss: 4.8122 - val_accuracy: 0.0591\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.6465 - accuracy: 0.0725 - val_loss: 4.6036 - val_accuracy: 0.0871\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 4.4564 - accuracy: 0.0956 - val_loss: 4.4945 - val_accuracy: 0.1014\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.3574 - accuracy: 0.1075 - val_loss: 4.4423 - val_accuracy: 0.1087\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.2842 - accuracy: 0.1195 - val_loss: 4.4075 - val_accuracy: 0.1159\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.2246 - accuracy: 0.1274 - val_loss: 4.3666 - val_accuracy: 0.1212\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 4.1654 - accuracy: 0.1350 - val_loss: 4.3287 - val_accuracy: 0.1288\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.1152 - accuracy: 0.1409 - val_loss: 4.2922 - val_accuracy: 0.1346\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 4.0600 - accuracy: 0.1491 - val_loss: 4.2948 - val_accuracy: 0.1368\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 4.0149 - accuracy: 0.1551 - val_loss: 4.2692 - val_accuracy: 0.1402\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 3.9743 - accuracy: 0.1624 - val_loss: 4.2453 - val_accuracy: 0.1459\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.9336 - accuracy: 0.1681 - val_loss: 4.2359 - val_accuracy: 0.1485\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.8984 - accuracy: 0.1726 - val_loss: 4.2032 - val_accuracy: 0.1523\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.8671 - accuracy: 0.1767 - val_loss: 4.1909 - val_accuracy: 0.1542\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.8312 - accuracy: 0.1815 - val_loss: 4.1868 - val_accuracy: 0.1566\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.7990 - accuracy: 0.1857 - val_loss: 4.1889 - val_accuracy: 0.1553\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.7674 - accuracy: 0.1902 - val_loss: 4.1599 - val_accuracy: 0.1605\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.7367 - accuracy: 0.1967 - val_loss: 4.1426 - val_accuracy: 0.1630\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 3.7110 - accuracy: 0.2007 - val_loss: 4.1380 - val_accuracy: 0.1639\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.6802 - accuracy: 0.2046 - val_loss: 4.1241 - val_accuracy: 0.1664\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.6572 - accuracy: 0.2087 - val_loss: 4.0814 - val_accuracy: 0.1728\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.6257 - accuracy: 0.2137 - val_loss: 4.0853 - val_accuracy: 0.1725\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.6044 - accuracy: 0.2181 - val_loss: 4.0599 - val_accuracy: 0.1752\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.5783 - accuracy: 0.2205 - val_loss: 4.0771 - val_accuracy: 0.1748\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.5518 - accuracy: 0.2243 - val_loss: 4.0893 - val_accuracy: 0.1743\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 3.5380 - accuracy: 0.2279 - val_loss: 4.0662 - val_accuracy: 0.1773\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.5083 - accuracy: 0.2324 - val_loss: 4.0770 - val_accuracy: 0.1769\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.4907 - accuracy: 0.2365 - val_loss: 4.0935 - val_accuracy: 0.1734\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.4713 - accuracy: 0.2394 - val_loss: 4.0341 - val_accuracy: 0.1821\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.4503 - accuracy: 0.2435 - val_loss: 4.0540 - val_accuracy: 0.1817\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.4358 - accuracy: 0.2440 - val_loss: 4.0436 - val_accuracy: 0.1832\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.4135 - accuracy: 0.2493 - val_loss: 4.0364 - val_accuracy: 0.1854\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3976 - accuracy: 0.2510 - val_loss: 4.0988 - val_accuracy: 0.1790\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3847 - accuracy: 0.2511 - val_loss: 4.0934 - val_accuracy: 0.1809\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3664 - accuracy: 0.2568 - val_loss: 4.0638 - val_accuracy: 0.1854\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3557 - accuracy: 0.2585 - val_loss: 4.1029 - val_accuracy: 0.1808\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3355 - accuracy: 0.2618 - val_loss: 4.0850 - val_accuracy: 0.1831\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 3.3259 - accuracy: 0.2643 - val_loss: 4.0666 - val_accuracy: 0.1857\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 3.3108 - accuracy: 0.2642 - val_loss: 4.0566 - val_accuracy: 0.1874\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46b87017-ed3c-4270-b07a-32b4455d6d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,390,664\n",
      "Trainable params: 4,390,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 5.0830 - accuracy: 0.0217 - val_loss: 4.8954 - val_accuracy: 0.0465\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.6537 - accuracy: 0.0682 - val_loss: 4.6006 - val_accuracy: 0.0795\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.4357 - accuracy: 0.0949 - val_loss: 4.4951 - val_accuracy: 0.0955\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.3074 - accuracy: 0.1115 - val_loss: 4.4214 - val_accuracy: 0.1054\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.2099 - accuracy: 0.1230 - val_loss: 4.3854 - val_accuracy: 0.1114\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.1250 - accuracy: 0.1333 - val_loss: 4.3417 - val_accuracy: 0.1199\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 4.0540 - accuracy: 0.1421 - val_loss: 4.3114 - val_accuracy: 0.1237\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.9948 - accuracy: 0.1502 - val_loss: 4.2953 - val_accuracy: 0.1283\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.9424 - accuracy: 0.1599 - val_loss: 4.2784 - val_accuracy: 0.1310\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.8915 - accuracy: 0.1672 - val_loss: 4.2494 - val_accuracy: 0.1348\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.8488 - accuracy: 0.1718 - val_loss: 4.1960 - val_accuracy: 0.1450\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.8062 - accuracy: 0.1787 - val_loss: 4.1967 - val_accuracy: 0.1454\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.7660 - accuracy: 0.1850 - val_loss: 4.1811 - val_accuracy: 0.1472\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.7224 - accuracy: 0.1919 - val_loss: 4.1470 - val_accuracy: 0.1497\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.6862 - accuracy: 0.1972 - val_loss: 4.1162 - val_accuracy: 0.1558\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.6508 - accuracy: 0.2028 - val_loss: 4.0940 - val_accuracy: 0.1599\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.6140 - accuracy: 0.2073 - val_loss: 4.1146 - val_accuracy: 0.1578\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.5838 - accuracy: 0.2134 - val_loss: 4.0142 - val_accuracy: 0.1674\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.5514 - accuracy: 0.2175 - val_loss: 4.0724 - val_accuracy: 0.1622\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.5204 - accuracy: 0.2214 - val_loss: 4.0279 - val_accuracy: 0.1685\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.4882 - accuracy: 0.2284 - val_loss: 4.0151 - val_accuracy: 0.1714\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.4612 - accuracy: 0.2329 - val_loss: 4.0139 - val_accuracy: 0.1730\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.4303 - accuracy: 0.2380 - val_loss: 3.9884 - val_accuracy: 0.1762\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.4049 - accuracy: 0.2422 - val_loss: 4.0111 - val_accuracy: 0.1738\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.3780 - accuracy: 0.2460 - val_loss: 3.9476 - val_accuracy: 0.1814\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.3564 - accuracy: 0.2494 - val_loss: 3.9815 - val_accuracy: 0.1793\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.3289 - accuracy: 0.2543 - val_loss: 4.0161 - val_accuracy: 0.1757\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.3062 - accuracy: 0.2584 - val_loss: 3.9385 - val_accuracy: 0.1866\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.2796 - accuracy: 0.2632 - val_loss: 3.9586 - val_accuracy: 0.1840\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.2534 - accuracy: 0.2675 - val_loss: 4.0384 - val_accuracy: 0.1773\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.2321 - accuracy: 0.2699 - val_loss: 3.9520 - val_accuracy: 0.1880\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.2143 - accuracy: 0.2731 - val_loss: 3.9806 - val_accuracy: 0.1841\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.1894 - accuracy: 0.2781 - val_loss: 3.9548 - val_accuracy: 0.1887\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.1695 - accuracy: 0.2819 - val_loss: 3.9893 - val_accuracy: 0.1869\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.1453 - accuracy: 0.2853 - val_loss: 3.9898 - val_accuracy: 0.1861\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#                   loss='categorical_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0.01,\n",
    "#         patience=10,\n",
    "#         verbose=0,\n",
    "#         mode='auto',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False\n",
    "#     )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294bd99-79ed-4b8f-aa72-ae2a10ea662c",
   "metadata": {},
   "source": [
    "# NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d35d6b70-1c78-435d-8322-048e4d6967c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2048)              16779264  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,603,080\n",
      "Trainable params: 19,600,584\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 5.1086 - accuracy: 0.0334 - val_loss: 5.5632 - val_accuracy: 0.0243\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 4.6188 - accuracy: 0.0710 - val_loss: 5.9386 - val_accuracy: 0.0291\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 4.3956 - accuracy: 0.0947 - val_loss: 5.9157 - val_accuracy: 0.0358\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 4.2339 - accuracy: 0.1142 - val_loss: 5.6699 - val_accuracy: 0.0470\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 4.1032 - accuracy: 0.1296 - val_loss: 5.5676 - val_accuracy: 0.0556\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 3.9967 - accuracy: 0.1452 - val_loss: 5.5529 - val_accuracy: 0.0567\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 3.8923 - accuracy: 0.1584 - val_loss: 5.0283 - val_accuracy: 0.0816\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.7984 - accuracy: 0.1729 - val_loss: 4.9788 - val_accuracy: 0.0844\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.7158 - accuracy: 0.1859 - val_loss: 4.7148 - val_accuracy: 0.1021\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.6356 - accuracy: 0.1985 - val_loss: 4.8234 - val_accuracy: 0.0957\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.5540 - accuracy: 0.2098 - val_loss: 4.6526 - val_accuracy: 0.1107\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.4870 - accuracy: 0.2200 - val_loss: 4.4809 - val_accuracy: 0.1302\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.4256 - accuracy: 0.2295 - val_loss: 4.6269 - val_accuracy: 0.1157\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 3.3588 - accuracy: 0.2413 - val_loss: 4.7179 - val_accuracy: 0.1103\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.2968 - accuracy: 0.2521 - val_loss: 4.5944 - val_accuracy: 0.1235\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.2491 - accuracy: 0.2588 - val_loss: 4.5122 - val_accuracy: 0.1299\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.1968 - accuracy: 0.2695 - val_loss: 4.4439 - val_accuracy: 0.1364\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.1440 - accuracy: 0.2775 - val_loss: 4.3011 - val_accuracy: 0.1492\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 3.0964 - accuracy: 0.2850 - val_loss: 4.3089 - val_accuracy: 0.1505\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 3.0484 - accuracy: 0.2944 - val_loss: 4.2508 - val_accuracy: 0.1571\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 27s 21ms/step - loss: 3.0007 - accuracy: 0.3011 - val_loss: 4.2718 - val_accuracy: 0.1579\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.9614 - accuracy: 0.3096 - val_loss: 4.2965 - val_accuracy: 0.1539\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 2.9187 - accuracy: 0.3166 - val_loss: 4.1341 - val_accuracy: 0.1736\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8781 - accuracy: 0.3234 - val_loss: 4.2466 - val_accuracy: 0.1682\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8357 - accuracy: 0.3310 - val_loss: 4.3306 - val_accuracy: 0.1617\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8027 - accuracy: 0.3370 - val_loss: 4.1580 - val_accuracy: 0.1798\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.7598 - accuracy: 0.3433 - val_loss: 4.1899 - val_accuracy: 0.1732\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.7216 - accuracy: 0.3536 - val_loss: 4.0572 - val_accuracy: 0.1910\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.6915 - accuracy: 0.3577 - val_loss: 4.2711 - val_accuracy: 0.1733\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.6463 - accuracy: 0.3646 - val_loss: 4.0526 - val_accuracy: 0.1922\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.6120 - accuracy: 0.3717 - val_loss: 3.9781 - val_accuracy: 0.1994\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 2.5744 - accuracy: 0.3784 - val_loss: 4.2160 - val_accuracy: 0.1825\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.5443 - accuracy: 0.3819 - val_loss: 4.1119 - val_accuracy: 0.1912\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.5135 - accuracy: 0.3904 - val_loss: 4.1348 - val_accuracy: 0.1907\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.4752 - accuracy: 0.3983 - val_loss: 4.2864 - val_accuracy: 0.1787\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 2.4467 - accuracy: 0.4032 - val_loss: 3.9977 - val_accuracy: 0.2081\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 2.4088 - accuracy: 0.4077 - val_loss: 4.0553 - val_accuracy: 0.2018\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 2.3821 - accuracy: 0.4148 - val_loss: 4.3466 - val_accuracy: 0.1766\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 2.3472 - accuracy: 0.4192 - val_loss: 4.1868 - val_accuracy: 0.1898\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 2.3184 - accuracy: 0.4276 - val_loss: 4.2061 - val_accuracy: 0.1932\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 2.2831 - accuracy: 0.4340 - val_loss: 4.1063 - val_accuracy: 0.2048\n"
     ]
    }
   ],
   "source": [
    "# 40 20\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis=3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(units=2048, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "954be4d0-b46c-44b5-ae2a-8dda71ab2199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               2097408   \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,243,976\n",
      "Trainable params: 2,243,016\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 19s 14ms/step - loss: 4.8277 - accuracy: 0.0558 - val_loss: 5.0292 - val_accuracy: 0.0865\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 4.2806 - accuracy: 0.1072 - val_loss: 4.6527 - val_accuracy: 0.0837\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 4.0743 - accuracy: 0.1340 - val_loss: 4.0987 - val_accuracy: 0.1358\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.9319 - accuracy: 0.1537 - val_loss: 4.1121 - val_accuracy: 0.1357\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.8336 - accuracy: 0.1679 - val_loss: 3.9742 - val_accuracy: 0.1512\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.7596 - accuracy: 0.1792 - val_loss: 3.8635 - val_accuracy: 0.1681\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.7030 - accuracy: 0.1870 - val_loss: 3.6109 - val_accuracy: 0.2021\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.6470 - accuracy: 0.1977 - val_loss: 3.8940 - val_accuracy: 0.1718\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.6016 - accuracy: 0.2046 - val_loss: 3.7542 - val_accuracy: 0.1916\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.5601 - accuracy: 0.2123 - val_loss: 3.5875 - val_accuracy: 0.2143\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.5220 - accuracy: 0.2187 - val_loss: 3.7600 - val_accuracy: 0.1886\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.4949 - accuracy: 0.2215 - val_loss: 3.7159 - val_accuracy: 0.1974\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.4636 - accuracy: 0.2287 - val_loss: 3.7111 - val_accuracy: 0.2003\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.4421 - accuracy: 0.2317 - val_loss: 3.6676 - val_accuracy: 0.2115\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.4138 - accuracy: 0.2357 - val_loss: 3.5869 - val_accuracy: 0.2213\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.3959 - accuracy: 0.2388 - val_loss: 3.7078 - val_accuracy: 0.2033\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.3772 - accuracy: 0.2424 - val_loss: 3.6056 - val_accuracy: 0.2162\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.3566 - accuracy: 0.2443 - val_loss: 3.5821 - val_accuracy: 0.2202\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.3414 - accuracy: 0.2481 - val_loss: 3.5972 - val_accuracy: 0.2244\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.3293 - accuracy: 0.2523 - val_loss: 3.3685 - val_accuracy: 0.2545\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.3101 - accuracy: 0.2528 - val_loss: 3.5171 - val_accuracy: 0.2307\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.2998 - accuracy: 0.2540 - val_loss: 3.3630 - val_accuracy: 0.2530\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 3.2859 - accuracy: 0.2577 - val_loss: 3.4588 - val_accuracy: 0.2408\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.2695 - accuracy: 0.2597 - val_loss: 3.4053 - val_accuracy: 0.2503\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2557 - accuracy: 0.2626 - val_loss: 3.5450 - val_accuracy: 0.2321\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.2488 - accuracy: 0.2627 - val_loss: 3.5426 - val_accuracy: 0.2299\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2391 - accuracy: 0.2654 - val_loss: 3.3465 - val_accuracy: 0.2578\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2283 - accuracy: 0.2668 - val_loss: 3.3002 - val_accuracy: 0.2667\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2162 - accuracy: 0.2681 - val_loss: 3.3801 - val_accuracy: 0.2528\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2061 - accuracy: 0.2707 - val_loss: 3.4460 - val_accuracy: 0.2423\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.2056 - accuracy: 0.2712 - val_loss: 3.2726 - val_accuracy: 0.2688\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1877 - accuracy: 0.2757 - val_loss: 3.3816 - val_accuracy: 0.2551\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1795 - accuracy: 0.2762 - val_loss: 3.5008 - val_accuracy: 0.2386\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1744 - accuracy: 0.2789 - val_loss: 3.3210 - val_accuracy: 0.2632\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1727 - accuracy: 0.2753 - val_loss: 3.3746 - val_accuracy: 0.2563\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1660 - accuracy: 0.2773 - val_loss: 3.2719 - val_accuracy: 0.2728\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1578 - accuracy: 0.2791 - val_loss: 3.3726 - val_accuracy: 0.2567\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1459 - accuracy: 0.2803 - val_loss: 3.2564 - val_accuracy: 0.2749\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1442 - accuracy: 0.2817 - val_loss: 3.3138 - val_accuracy: 0.2684\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1350 - accuracy: 0.2823 - val_loss: 3.3783 - val_accuracy: 0.2585\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1242 - accuracy: 0.2857 - val_loss: 3.2922 - val_accuracy: 0.2702\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1231 - accuracy: 0.2863 - val_loss: 3.2303 - val_accuracy: 0.2775\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1237 - accuracy: 0.2854 - val_loss: 3.3078 - val_accuracy: 0.2669\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1091 - accuracy: 0.2874 - val_loss: 3.3261 - val_accuracy: 0.2648\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1097 - accuracy: 0.2881 - val_loss: 3.2902 - val_accuracy: 0.2686\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.1001 - accuracy: 0.2900 - val_loss: 3.2582 - val_accuracy: 0.2756\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.0963 - accuracy: 0.2891 - val_loss: 3.1865 - val_accuracy: 0.2844\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.0867 - accuracy: 0.2917 - val_loss: 3.3026 - val_accuracy: 0.2675\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.0852 - accuracy: 0.2920 - val_loss: 3.1689 - val_accuracy: 0.2875\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.0842 - accuracy: 0.2930 - val_loss: 3.2424 - val_accuracy: 0.2794\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.0779 - accuracy: 0.2964 - val_loss: 3.2984 - val_accuracy: 0.2661\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.0695 - accuracy: 0.2943 - val_loss: 3.3199 - val_accuracy: 0.2673\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.0634 - accuracy: 0.2954 - val_loss: 3.2749 - val_accuracy: 0.2714\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.0643 - accuracy: 0.2979 - val_loss: 3.3071 - val_accuracy: 0.2704\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 3.0622 - accuracy: 0.2947 - val_loss: 3.2441 - val_accuracy: 0.2778\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.0501 - accuracy: 0.2988 - val_loss: 3.1639 - val_accuracy: 0.2925\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.0507 - accuracy: 0.2972 - val_loss: 3.2694 - val_accuracy: 0.2750\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 3.0485 - accuracy: 0.2985 - val_loss: 3.1993 - val_accuracy: 0.2862\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 3.0427 - accuracy: 0.2990 - val_loss: 3.3466 - val_accuracy: 0.2646\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40bb3049-3ecd-43df-9157-6a60b6be616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,592,648\n",
      "Trainable params: 2,590,664\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 5.0613 - accuracy: 0.0467 - val_loss: 4.6097 - val_accuracy: 0.0767\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 4.3138 - accuracy: 0.1043 - val_loss: 4.4067 - val_accuracy: 0.1103\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 4.0235 - accuracy: 0.1404 - val_loss: 4.0443 - val_accuracy: 0.1486\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.8389 - accuracy: 0.1689 - val_loss: 4.3034 - val_accuracy: 0.1409\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.7186 - accuracy: 0.1854 - val_loss: 3.6457 - val_accuracy: 0.2063\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.6254 - accuracy: 0.1989 - val_loss: 3.7496 - val_accuracy: 0.1938\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.5333 - accuracy: 0.2143 - val_loss: 3.5087 - val_accuracy: 0.2286\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.4698 - accuracy: 0.2244 - val_loss: 3.6868 - val_accuracy: 0.2002\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.4084 - accuracy: 0.2349 - val_loss: 3.7053 - val_accuracy: 0.2012\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.3596 - accuracy: 0.2413 - val_loss: 3.6453 - val_accuracy: 0.2104\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.3074 - accuracy: 0.2519 - val_loss: 3.3146 - val_accuracy: 0.2606\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.2760 - accuracy: 0.2562 - val_loss: 3.4921 - val_accuracy: 0.2332\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.2368 - accuracy: 0.2638 - val_loss: 3.4727 - val_accuracy: 0.2356\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.2085 - accuracy: 0.2689 - val_loss: 3.3533 - val_accuracy: 0.2538\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.1755 - accuracy: 0.2734 - val_loss: 3.3493 - val_accuracy: 0.2585\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.1468 - accuracy: 0.2783 - val_loss: 3.2773 - val_accuracy: 0.2692\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 3.1190 - accuracy: 0.2855 - val_loss: 3.2709 - val_accuracy: 0.2715\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.1023 - accuracy: 0.2872 - val_loss: 3.1948 - val_accuracy: 0.2828\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.0768 - accuracy: 0.2920 - val_loss: 3.2232 - val_accuracy: 0.2792\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 3.0533 - accuracy: 0.2956 - val_loss: 3.3413 - val_accuracy: 0.2589\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.0376 - accuracy: 0.3008 - val_loss: 3.2468 - val_accuracy: 0.2755\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.0217 - accuracy: 0.3021 - val_loss: 3.1749 - val_accuracy: 0.2851\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 3.0049 - accuracy: 0.3045 - val_loss: 3.0865 - val_accuracy: 0.3009\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.9784 - accuracy: 0.3098 - val_loss: 3.2860 - val_accuracy: 0.2678\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.9689 - accuracy: 0.3114 - val_loss: 3.1179 - val_accuracy: 0.2986\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.9581 - accuracy: 0.3118 - val_loss: 3.0890 - val_accuracy: 0.3039\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.9386 - accuracy: 0.3180 - val_loss: 3.2007 - val_accuracy: 0.2826\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 21s 16ms/step - loss: 2.9284 - accuracy: 0.3196 - val_loss: 3.2188 - val_accuracy: 0.2835\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.9183 - accuracy: 0.3213 - val_loss: 3.2464 - val_accuracy: 0.2826\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.9017 - accuracy: 0.3217 - val_loss: 3.1826 - val_accuracy: 0.2900\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 21s 16ms/step - loss: 2.8876 - accuracy: 0.3261 - val_loss: 3.1171 - val_accuracy: 0.2982\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.8808 - accuracy: 0.3289 - val_loss: 3.2027 - val_accuracy: 0.2824\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.8743 - accuracy: 0.3263 - val_loss: 3.1553 - val_accuracy: 0.2925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    \n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2056b071-084c-4efa-83f0-a9ae7613f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              4195328   \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,219,208\n",
      "Trainable params: 5,215,176\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 5.1674 - accuracy: 0.0394 - val_loss: 5.1311 - val_accuracy: 0.0503\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 4.4418 - accuracy: 0.0870 - val_loss: 4.6326 - val_accuracy: 0.0834\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 4.1488 - accuracy: 0.1196 - val_loss: 4.2983 - val_accuracy: 0.1147\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.9657 - accuracy: 0.1444 - val_loss: 4.1157 - val_accuracy: 0.1323\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.8307 - accuracy: 0.1639 - val_loss: 3.8266 - val_accuracy: 0.1675\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.7243 - accuracy: 0.1778 - val_loss: 3.9789 - val_accuracy: 0.1575\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.6423 - accuracy: 0.1927 - val_loss: 3.6509 - val_accuracy: 0.1992\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.5718 - accuracy: 0.2035 - val_loss: 3.6451 - val_accuracy: 0.1989\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.5075 - accuracy: 0.2128 - val_loss: 3.4793 - val_accuracy: 0.2279\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.4617 - accuracy: 0.2210 - val_loss: 3.5592 - val_accuracy: 0.2124\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.4081 - accuracy: 0.2288 - val_loss: 3.4858 - val_accuracy: 0.2237\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.3666 - accuracy: 0.2361 - val_loss: 3.3363 - val_accuracy: 0.2526\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.3303 - accuracy: 0.2444 - val_loss: 3.3795 - val_accuracy: 0.2455\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.3009 - accuracy: 0.2492 - val_loss: 3.3325 - val_accuracy: 0.2515\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.2655 - accuracy: 0.2553 - val_loss: 3.3400 - val_accuracy: 0.2507\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.2405 - accuracy: 0.2604 - val_loss: 3.2892 - val_accuracy: 0.2584\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.2186 - accuracy: 0.2631 - val_loss: 3.2396 - val_accuracy: 0.2708\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 3.1892 - accuracy: 0.2686 - val_loss: 3.2143 - val_accuracy: 0.2752\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 3.1731 - accuracy: 0.2712 - val_loss: 3.3743 - val_accuracy: 0.2479\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.1429 - accuracy: 0.2761 - val_loss: 3.1405 - val_accuracy: 0.2860\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.1223 - accuracy: 0.2801 - val_loss: 3.2325 - val_accuracy: 0.2709\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.1096 - accuracy: 0.2819 - val_loss: 3.2210 - val_accuracy: 0.2719\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.0920 - accuracy: 0.2833 - val_loss: 3.2245 - val_accuracy: 0.2762\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 3.0785 - accuracy: 0.2905 - val_loss: 3.1174 - val_accuracy: 0.2943\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 3.0572 - accuracy: 0.2901 - val_loss: 3.1513 - val_accuracy: 0.2885\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.0420 - accuracy: 0.2952 - val_loss: 3.1202 - val_accuracy: 0.2924\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.0327 - accuracy: 0.2966 - val_loss: 3.2129 - val_accuracy: 0.2792\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 3.0063 - accuracy: 0.3005 - val_loss: 3.1620 - val_accuracy: 0.2816\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.9999 - accuracy: 0.3020 - val_loss: 3.1884 - val_accuracy: 0.2825\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.9871 - accuracy: 0.3037 - val_loss: 3.1179 - val_accuracy: 0.2936\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 2.9718 - accuracy: 0.3067 - val_loss: 3.1441 - val_accuracy: 0.2896\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 2.9596 - accuracy: 0.3098 - val_loss: 3.0762 - val_accuracy: 0.2986\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.9508 - accuracy: 0.3106 - val_loss: 3.0812 - val_accuracy: 0.2995\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.9387 - accuracy: 0.3121 - val_loss: 3.2439 - val_accuracy: 0.2736\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.9240 - accuracy: 0.3137 - val_loss: 3.1240 - val_accuracy: 0.2935\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 2.9204 - accuracy: 0.3159 - val_loss: 3.0663 - val_accuracy: 0.3004\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 2.9096 - accuracy: 0.3183 - val_loss: 3.1291 - val_accuracy: 0.2974\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.9014 - accuracy: 0.3200 - val_loss: 2.9837 - val_accuracy: 0.3201\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8875 - accuracy: 0.3220 - val_loss: 3.0590 - val_accuracy: 0.3052\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8822 - accuracy: 0.3228 - val_loss: 3.0668 - val_accuracy: 0.3077\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8696 - accuracy: 0.3227 - val_loss: 3.0412 - val_accuracy: 0.3090\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8699 - accuracy: 0.3269 - val_loss: 3.3508 - val_accuracy: 0.2578\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8485 - accuracy: 0.3284 - val_loss: 3.0680 - val_accuracy: 0.3009\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8515 - accuracy: 0.3283 - val_loss: 3.1820 - val_accuracy: 0.2880\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8394 - accuracy: 0.3324 - val_loss: 3.1692 - val_accuracy: 0.2909\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8264 - accuracy: 0.3341 - val_loss: 3.0430 - val_accuracy: 0.3112\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8236 - accuracy: 0.3343 - val_loss: 3.1406 - val_accuracy: 0.2932\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.8195 - accuracy: 0.3334 - val_loss: 3.1206 - val_accuracy: 0.2969\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdd13992-e964-4e1f-b0b7-b4616a2e6d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               1638600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,120,264\n",
      "Trainable params: 2,119,816\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 37s 29ms/step - loss: 5.2424 - accuracy: 0.0370 - val_loss: 5.6862 - val_accuracy: 0.0343\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 37s 29ms/step - loss: 4.3781 - accuracy: 0.0972 - val_loss: 5.0668 - val_accuracy: 0.0732\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 4.0860 - accuracy: 0.1357 - val_loss: 4.7024 - val_accuracy: 0.1082\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 3.8733 - accuracy: 0.1658 - val_loss: 4.6039 - val_accuracy: 0.1157\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.7118 - accuracy: 0.1916 - val_loss: 5.0137 - val_accuracy: 0.0997\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 3.5718 - accuracy: 0.2132 - val_loss: 4.3312 - val_accuracy: 0.1549\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 3.4602 - accuracy: 0.2327 - val_loss: 4.1417 - val_accuracy: 0.1697\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.3650 - accuracy: 0.2488 - val_loss: 4.3874 - val_accuracy: 0.1590\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.2837 - accuracy: 0.2636 - val_loss: 4.0610 - val_accuracy: 0.1891\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.2177 - accuracy: 0.2740 - val_loss: 3.7693 - val_accuracy: 0.2193\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 3.1513 - accuracy: 0.2869 - val_loss: 3.8668 - val_accuracy: 0.2015\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.0932 - accuracy: 0.2974 - val_loss: 3.8956 - val_accuracy: 0.2135\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.0416 - accuracy: 0.3064 - val_loss: 3.7930 - val_accuracy: 0.2232\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 3.0032 - accuracy: 0.3134 - val_loss: 3.8133 - val_accuracy: 0.2272\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.9584 - accuracy: 0.3205 - val_loss: 3.7901 - val_accuracy: 0.2343\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.9179 - accuracy: 0.3272 - val_loss: 3.5705 - val_accuracy: 0.2466\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.8821 - accuracy: 0.3341 - val_loss: 3.8661 - val_accuracy: 0.2284\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 2.8536 - accuracy: 0.3387 - val_loss: 3.7753 - val_accuracy: 0.2327\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.8249 - accuracy: 0.3449 - val_loss: 3.7288 - val_accuracy: 0.2421\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.7942 - accuracy: 0.3502 - val_loss: 3.5793 - val_accuracy: 0.2596\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 2.7730 - accuracy: 0.3552 - val_loss: 3.7950 - val_accuracy: 0.2369\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.7616 - accuracy: 0.3593 - val_loss: 3.5544 - val_accuracy: 0.2602\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.7294 - accuracy: 0.3630 - val_loss: 3.4936 - val_accuracy: 0.2713\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6973 - accuracy: 0.3683 - val_loss: 3.3953 - val_accuracy: 0.2849\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6863 - accuracy: 0.3711 - val_loss: 3.5188 - val_accuracy: 0.2618\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6596 - accuracy: 0.3740 - val_loss: 3.5357 - val_accuracy: 0.2683\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6432 - accuracy: 0.3808 - val_loss: 3.5447 - val_accuracy: 0.2676\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 2.6219 - accuracy: 0.3856 - val_loss: 3.5038 - val_accuracy: 0.2752\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6042 - accuracy: 0.3865 - val_loss: 3.4297 - val_accuracy: 0.2816\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.5909 - accuracy: 0.3887 - val_loss: 3.5271 - val_accuracy: 0.2645\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 2.5802 - accuracy: 0.3925 - val_loss: 3.4452 - val_accuracy: 0.2747\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.5629 - accuracy: 0.3939 - val_loss: 3.6127 - val_accuracy: 0.2643\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.6433 - accuracy: 0.3878 - val_loss: 3.4917 - val_accuracy: 0.2794\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 2.5530 - accuracy: 0.3966 - val_loss: 3.6420 - val_accuracy: 0.2601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    # X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization()(X)\n",
    "    # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897cf474-63c6-4e7d-980d-187f033d9564",
   "metadata": {},
   "source": [
    "# NOT BAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b98e84d-0b05-4c79-9992-f7c2e8df47a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,160,328\n",
      "Trainable params: 4,158,344\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.5326 - accuracy: 0.0146 - val_loss: 7.4329 - val_accuracy: 0.0068\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0624 - accuracy: 0.0342 - val_loss: 4.6589 - val_accuracy: 0.0569\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.7122 - accuracy: 0.0592 - val_loss: 4.5741 - val_accuracy: 0.0680\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.4055 - accuracy: 0.0862 - val_loss: 4.4273 - val_accuracy: 0.0954\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1827 - accuracy: 0.1143 - val_loss: 4.3735 - val_accuracy: 0.1047\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 4.0133 - accuracy: 0.1356 - val_loss: 4.2997 - val_accuracy: 0.1125\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.8657 - accuracy: 0.1578 - val_loss: 3.9036 - val_accuracy: 0.1543\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.7420 - accuracy: 0.1767 - val_loss: 4.1558 - val_accuracy: 0.1372\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.6325 - accuracy: 0.1919 - val_loss: 3.9363 - val_accuracy: 0.1627\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5405 - accuracy: 0.2089 - val_loss: 3.4925 - val_accuracy: 0.2192\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.4556 - accuracy: 0.2202 - val_loss: 3.6307 - val_accuracy: 0.2050\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3880 - accuracy: 0.2329 - val_loss: 3.7341 - val_accuracy: 0.2202\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3228 - accuracy: 0.2456 - val_loss: 3.6649 - val_accuracy: 0.2072\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2646 - accuracy: 0.2560 - val_loss: 3.5005 - val_accuracy: 0.2304\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2164 - accuracy: 0.2633 - val_loss: 3.4513 - val_accuracy: 0.2283\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1620 - accuracy: 0.2711 - val_loss: 3.2880 - val_accuracy: 0.2616\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1235 - accuracy: 0.2786 - val_loss: 3.2591 - val_accuracy: 0.2657\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0744 - accuracy: 0.2886 - val_loss: 3.4843 - val_accuracy: 0.2358\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0428 - accuracy: 0.2957 - val_loss: 3.2909 - val_accuracy: 0.2679\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.9993 - accuracy: 0.3023 - val_loss: 3.1885 - val_accuracy: 0.2792\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9633 - accuracy: 0.3086 - val_loss: 3.3901 - val_accuracy: 0.2569\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9390 - accuracy: 0.3126 - val_loss: 3.4376 - val_accuracy: 0.2476\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9040 - accuracy: 0.3188 - val_loss: 3.1258 - val_accuracy: 0.2928\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.8801 - accuracy: 0.3243 - val_loss: 3.0646 - val_accuracy: 0.3083\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.8611 - accuracy: 0.3286 - val_loss: 3.1654 - val_accuracy: 0.2882\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.8276 - accuracy: 0.3328 - val_loss: 3.3037 - val_accuracy: 0.2761\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.8006 - accuracy: 0.3359 - val_loss: 3.0575 - val_accuracy: 0.3085\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.7807 - accuracy: 0.3415 - val_loss: 2.9029 - val_accuracy: 0.3388\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.7550 - accuracy: 0.3456 - val_loss: 2.9695 - val_accuracy: 0.3275\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.7308 - accuracy: 0.3516 - val_loss: 2.9432 - val_accuracy: 0.3223\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7130 - accuracy: 0.3544 - val_loss: 3.1579 - val_accuracy: 0.2937\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.6967 - accuracy: 0.3598 - val_loss: 3.0008 - val_accuracy: 0.3172\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.6775 - accuracy: 0.3622 - val_loss: 2.9959 - val_accuracy: 0.3183\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.6561 - accuracy: 0.3653 - val_loss: 2.8407 - val_accuracy: 0.3434\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.6359 - accuracy: 0.3697 - val_loss: 3.1891 - val_accuracy: 0.2953\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.6277 - accuracy: 0.3725 - val_loss: 3.0584 - val_accuracy: 0.3091\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.6064 - accuracy: 0.3763 - val_loss: 3.2270 - val_accuracy: 0.2968\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5895 - accuracy: 0.3790 - val_loss: 2.9296 - val_accuracy: 0.3336\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5794 - accuracy: 0.3822 - val_loss: 3.0772 - val_accuracy: 0.3146\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5574 - accuracy: 0.3843 - val_loss: 2.9340 - val_accuracy: 0.3347\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5479 - accuracy: 0.3872 - val_loss: 3.0317 - val_accuracy: 0.3205\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5244 - accuracy: 0.3910 - val_loss: 3.1520 - val_accuracy: 0.3088\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5145 - accuracy: 0.3934 - val_loss: 3.2147 - val_accuracy: 0.3187\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 2.5057 - accuracy: 0.3933 - val_loss: 3.1725 - val_accuracy: 0.3068\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b2fbe9f-3a74-4e80-be27-a9e0b7045277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1024)              4195328   \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,786,888\n",
      "Trainable params: 6,782,856\n",
      "Non-trainable params: 4,032\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 5.5595 - accuracy: 0.0140 - val_loss: 5.3072 - val_accuracy: 0.0211\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0129 - accuracy: 0.0324 - val_loss: 4.9811 - val_accuracy: 0.0373\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6829 - accuracy: 0.0560 - val_loss: 4.4868 - val_accuracy: 0.0764\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.4148 - accuracy: 0.0842 - val_loss: 4.2786 - val_accuracy: 0.1045\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2164 - accuracy: 0.1075 - val_loss: 4.2134 - val_accuracy: 0.1144\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0562 - accuracy: 0.1287 - val_loss: 4.2695 - val_accuracy: 0.1073\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9160 - accuracy: 0.1480 - val_loss: 4.2700 - val_accuracy: 0.1152\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.7929 - accuracy: 0.1647 - val_loss: 4.2125 - val_accuracy: 0.1277\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6909 - accuracy: 0.1817 - val_loss: 3.9300 - val_accuracy: 0.1572\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6050 - accuracy: 0.1945 - val_loss: 3.6838 - val_accuracy: 0.1857\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5230 - accuracy: 0.2072 - val_loss: 3.5313 - val_accuracy: 0.2104\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4484 - accuracy: 0.2199 - val_loss: 3.7146 - val_accuracy: 0.1886\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3822 - accuracy: 0.2307 - val_loss: 3.6561 - val_accuracy: 0.1947\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3202 - accuracy: 0.2417 - val_loss: 3.5235 - val_accuracy: 0.2207\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 3.2688 - accuracy: 0.2509 - val_loss: 3.4652 - val_accuracy: 0.2299\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2096 - accuracy: 0.2618 - val_loss: 3.7322 - val_accuracy: 0.1963\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1675 - accuracy: 0.2679 - val_loss: 3.7936 - val_accuracy: 0.1935\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1243 - accuracy: 0.2764 - val_loss: 3.5014 - val_accuracy: 0.2347\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.0817 - accuracy: 0.2841 - val_loss: 3.4922 - val_accuracy: 0.2361\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 3.0429 - accuracy: 0.2898 - val_loss: 3.3039 - val_accuracy: 0.2630\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 3.0147 - accuracy: 0.2965 - val_loss: 3.3892 - val_accuracy: 0.2401\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.9699 - accuracy: 0.3043 - val_loss: 3.2993 - val_accuracy: 0.2632\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.9420 - accuracy: 0.3112 - val_loss: 3.2655 - val_accuracy: 0.2695\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.9086 - accuracy: 0.3151 - val_loss: 3.1437 - val_accuracy: 0.2902\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8805 - accuracy: 0.3199 - val_loss: 3.2983 - val_accuracy: 0.2646\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.8575 - accuracy: 0.3261 - val_loss: 3.1431 - val_accuracy: 0.2878\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8248 - accuracy: 0.3315 - val_loss: 3.1551 - val_accuracy: 0.2862\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.8025 - accuracy: 0.3341 - val_loss: 3.1062 - val_accuracy: 0.2981\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.7765 - accuracy: 0.3424 - val_loss: 3.1445 - val_accuracy: 0.2883\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.7552 - accuracy: 0.3457 - val_loss: 3.3039 - val_accuracy: 0.2715\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.7279 - accuracy: 0.3518 - val_loss: 3.0809 - val_accuracy: 0.3036\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.7119 - accuracy: 0.3542 - val_loss: 3.0709 - val_accuracy: 0.3064\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6928 - accuracy: 0.3585 - val_loss: 3.1904 - val_accuracy: 0.2885\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6666 - accuracy: 0.3637 - val_loss: 3.0879 - val_accuracy: 0.3063\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6529 - accuracy: 0.3657 - val_loss: 3.2318 - val_accuracy: 0.2819\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6300 - accuracy: 0.3710 - val_loss: 3.0410 - val_accuracy: 0.3139\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.6093 - accuracy: 0.3729 - val_loss: 3.1428 - val_accuracy: 0.2980\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5992 - accuracy: 0.3749 - val_loss: 3.2727 - val_accuracy: 0.2842\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5801 - accuracy: 0.3782 - val_loss: 3.0744 - val_accuracy: 0.3086\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5657 - accuracy: 0.3820 - val_loss: 3.0135 - val_accuracy: 0.3183\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5462 - accuracy: 0.3871 - val_loss: 3.0490 - val_accuracy: 0.3131\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5216 - accuracy: 0.3891 - val_loss: 3.2815 - val_accuracy: 0.3037\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5129 - accuracy: 0.3912 - val_loss: 3.0437 - val_accuracy: 0.3144\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4955 - accuracy: 0.3954 - val_loss: 2.9972 - val_accuracy: 0.3221\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4850 - accuracy: 0.3983 - val_loss: 2.8624 - val_accuracy: 0.3489\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.4779 - accuracy: 0.3998 - val_loss: 3.0387 - val_accuracy: 0.3198\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.4536 - accuracy: 0.4026 - val_loss: 3.1817 - val_accuracy: 0.2969\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4354 - accuracy: 0.4063 - val_loss: 2.9816 - val_accuracy: 0.3268\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4305 - accuracy: 0.4073 - val_loss: 2.9775 - val_accuracy: 0.3286\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4124 - accuracy: 0.4116 - val_loss: 2.9487 - val_accuracy: 0.3341\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.4069 - accuracy: 0.4128 - val_loss: 3.0553 - val_accuracy: 0.3178\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3911 - accuracy: 0.4144 - val_loss: 3.1956 - val_accuracy: 0.3011\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3800 - accuracy: 0.4179 - val_loss: 3.0424 - val_accuracy: 0.3203\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.3701 - accuracy: 0.4204 - val_loss: 2.9227 - val_accuracy: 0.3419\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3502 - accuracy: 0.4214 - val_loss: 3.0449 - val_accuracy: 0.3230\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb48f0-d58b-4de9-82ee-063415b6f0ac",
   "metadata": {},
   "source": [
    "# START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4baf0cc-5ea5-4394-8d36-8d75dcf7ce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 128)       3584      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 1024)       4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 1024)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              16778240  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,689,352\n",
      "Trainable params: 48,682,440\n",
      "Non-trainable params: 6,912\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 278s 215ms/step - loss: 5.5893 - accuracy: 0.0114 - val_loss: 5.2248 - val_accuracy: 0.0178\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 5.2081 - accuracy: 0.0203 - val_loss: 4.9368 - val_accuracy: 0.0320\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 4.9050 - accuracy: 0.0380 - val_loss: 4.8226 - val_accuracy: 0.0555\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 295s 236ms/step - loss: 4.6757 - accuracy: 0.0564 - val_loss: 4.5204 - val_accuracy: 0.0759\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 255s 204ms/step - loss: 4.4898 - accuracy: 0.0762 - val_loss: 4.4012 - val_accuracy: 0.0910\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 11055s 9s/step - loss: 4.3198 - accuracy: 0.0973 - val_loss: 4.2973 - val_accuracy: 0.1110\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 255s 204ms/step - loss: 4.1522 - accuracy: 0.1176 - val_loss: 4.1161 - val_accuracy: 0.1330\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 4.0064 - accuracy: 0.1361 - val_loss: 4.1886 - val_accuracy: 0.1265\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 252s 201ms/step - loss: 3.8572 - accuracy: 0.1563 - val_loss: 4.1182 - val_accuracy: 0.1467\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 3.7329 - accuracy: 0.1749 - val_loss: 4.4666 - val_accuracy: 0.1137\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 3.6219 - accuracy: 0.1940 - val_loss: 3.8154 - val_accuracy: 0.1809\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 3.5222 - accuracy: 0.2083 - val_loss: 3.8109 - val_accuracy: 0.1820\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 3.4225 - accuracy: 0.2253 - val_loss: 3.5758 - val_accuracy: 0.2157\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 3.3497 - accuracy: 0.2377 - val_loss: 3.6808 - val_accuracy: 0.2068\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 3.2515 - accuracy: 0.2547 - val_loss: 3.4818 - val_accuracy: 0.2334\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 3.1849 - accuracy: 0.2652 - val_loss: 3.5959 - val_accuracy: 0.2229\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 3.1089 - accuracy: 0.2813 - val_loss: 3.7487 - val_accuracy: 0.2573\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 3.0394 - accuracy: 0.2903 - val_loss: 3.3323 - val_accuracy: 0.2524\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 252s 202ms/step - loss: 2.9776 - accuracy: 0.3050 - val_loss: 3.5844 - val_accuracy: 0.2307\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.9113 - accuracy: 0.3160 - val_loss: 3.2239 - val_accuracy: 0.2817\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 2.8586 - accuracy: 0.3249 - val_loss: 3.4479 - val_accuracy: 0.2731\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 2.7941 - accuracy: 0.3372 - val_loss: 3.0514 - val_accuracy: 0.3039\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.7435 - accuracy: 0.3484 - val_loss: 3.1850 - val_accuracy: 0.2857\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.6928 - accuracy: 0.3589 - val_loss: 2.9537 - val_accuracy: 0.3271\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 250s 200ms/step - loss: 2.6448 - accuracy: 0.3670 - val_loss: 3.0273 - val_accuracy: 0.3169\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.5917 - accuracy: 0.3778 - val_loss: 3.2466 - val_accuracy: 0.2876\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.5426 - accuracy: 0.3868 - val_loss: 3.1403 - val_accuracy: 0.3068\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 252s 201ms/step - loss: 2.4992 - accuracy: 0.3943 - val_loss: 3.5137 - val_accuracy: 0.2934\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.4481 - accuracy: 0.4049 - val_loss: 3.2247 - val_accuracy: 0.3115\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.4094 - accuracy: 0.4143 - val_loss: 3.1800 - val_accuracy: 0.3027\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.3608 - accuracy: 0.4221 - val_loss: 3.2803 - val_accuracy: 0.2968\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 2.3208 - accuracy: 0.4304 - val_loss: 3.0048 - val_accuracy: 0.3329\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 2.2735 - accuracy: 0.4392 - val_loss: 2.9119 - val_accuracy: 0.3539\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.2413 - accuracy: 0.4467 - val_loss: 2.9680 - val_accuracy: 0.3442\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 2.2182 - accuracy: 0.4534 - val_loss: 3.3570 - val_accuracy: 0.2940\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 254s 203ms/step - loss: 2.1648 - accuracy: 0.4625 - val_loss: 3.0077 - val_accuracy: 0.3417\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 259s 207ms/step - loss: 2.1213 - accuracy: 0.4718 - val_loss: 3.1560 - val_accuracy: 0.3279\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 2.1009 - accuracy: 0.4743 - val_loss: 2.9869 - val_accuracy: 0.3512\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 268s 215ms/step - loss: 2.0524 - accuracy: 0.4871 - val_loss: 2.8755 - val_accuracy: 0.3650\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 264s 211ms/step - loss: 2.0152 - accuracy: 0.4935 - val_loss: 2.8739 - val_accuracy: 0.3701\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 256s 205ms/step - loss: 1.9758 - accuracy: 0.5002 - val_loss: 3.0847 - val_accuracy: 0.3426\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 258s 206ms/step - loss: 1.9476 - accuracy: 0.5072 - val_loss: 2.8672 - val_accuracy: 0.3714\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 256s 205ms/step - loss: 1.9091 - accuracy: 0.5145 - val_loss: 2.8188 - val_accuracy: 0.3785\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 262s 210ms/step - loss: 1.8780 - accuracy: 0.5205 - val_loss: 3.0814 - val_accuracy: 0.3471\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 266s 213ms/step - loss: 1.8477 - accuracy: 0.5300 - val_loss: 3.3299 - val_accuracy: 0.3442\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 265s 212ms/step - loss: 1.8144 - accuracy: 0.5352 - val_loss: 2.8481 - val_accuracy: 0.3794\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 274s 219ms/step - loss: 1.7812 - accuracy: 0.5425 - val_loss: 2.8875 - val_accuracy: 0.3803\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 271s 217ms/step - loss: 1.7538 - accuracy: 0.5481 - val_loss: 2.8677 - val_accuracy: 0.3791\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 266s 213ms/step - loss: 1.7271 - accuracy: 0.5540 - val_loss: 2.8406 - val_accuracy: 0.3857\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 256s 205ms/step - loss: 1.6973 - accuracy: 0.5594 - val_loss: 3.0801 - val_accuracy: 0.3600\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 252s 201ms/step - loss: 1.6593 - accuracy: 0.5664 - val_loss: 2.8653 - val_accuracy: 0.3925\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 252s 201ms/step - loss: 1.6362 - accuracy: 0.5730 - val_loss: 2.8907 - val_accuracy: 0.3898\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 252s 201ms/step - loss: 1.6098 - accuracy: 0.5786 - val_loss: 3.0013 - val_accuracy: 0.3767\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb0d39c4-b4c7-4094-b23f-f161bca4a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 128)       3584      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 8, 8, 1024)       4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 1024)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               8389120   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,771,336\n",
      "Trainable params: 39,766,472\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 5.6337 - accuracy: 0.0106 - val_loss: 5.1980 - val_accuracy: 0.0149\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 247s 198ms/step - loss: 5.1896 - accuracy: 0.0242 - val_loss: 5.0236 - val_accuracy: 0.0335\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 248s 199ms/step - loss: 4.9350 - accuracy: 0.0370 - val_loss: 4.9297 - val_accuracy: 0.0423\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 4.6973 - accuracy: 0.0556 - val_loss: 4.9182 - val_accuracy: 0.0502\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 254s 203ms/step - loss: 4.5133 - accuracy: 0.0767 - val_loss: 4.3035 - val_accuracy: 0.1082\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 257s 206ms/step - loss: 4.3681 - accuracy: 0.0961 - val_loss: 4.4179 - val_accuracy: 0.1234\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 259s 207ms/step - loss: 4.2092 - accuracy: 0.1165 - val_loss: 4.3461 - val_accuracy: 0.1142\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 4.0775 - accuracy: 0.1327 - val_loss: 4.1159 - val_accuracy: 0.1393\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 262s 210ms/step - loss: 3.9614 - accuracy: 0.1493 - val_loss: 3.9076 - val_accuracy: 0.1670\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 261s 209ms/step - loss: 3.8553 - accuracy: 0.1640 - val_loss: 4.1189 - val_accuracy: 0.1376\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 263s 210ms/step - loss: 3.7621 - accuracy: 0.1792 - val_loss: 4.1161 - val_accuracy: 0.1455\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 261s 209ms/step - loss: 3.6496 - accuracy: 0.1957 - val_loss: 4.0494 - val_accuracy: 0.1631\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 3.5586 - accuracy: 0.2101 - val_loss: 3.8583 - val_accuracy: 0.1812\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.4693 - accuracy: 0.2234 - val_loss: 3.8980 - val_accuracy: 0.1926\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.3795 - accuracy: 0.2387 - val_loss: 3.6987 - val_accuracy: 0.2091\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.3094 - accuracy: 0.2513 - val_loss: 3.6842 - val_accuracy: 0.2100\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.2394 - accuracy: 0.2629 - val_loss: 3.6280 - val_accuracy: 0.2183\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.1706 - accuracy: 0.2737 - val_loss: 3.4891 - val_accuracy: 0.2402\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.1082 - accuracy: 0.2862 - val_loss: 3.6523 - val_accuracy: 0.2305\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 3.0512 - accuracy: 0.2960 - val_loss: 19.6157 - val_accuracy: 0.2404\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 2.9910 - accuracy: 0.3067 - val_loss: 3.1250 - val_accuracy: 0.2969\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 247s 198ms/step - loss: 2.9291 - accuracy: 0.3168 - val_loss: 3.3249 - val_accuracy: 0.2707\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 2.8916 - accuracy: 0.3246 - val_loss: 3.1862 - val_accuracy: 0.2894\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 2.8362 - accuracy: 0.3326 - val_loss: 2.9628 - val_accuracy: 0.3205\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 248s 199ms/step - loss: 2.7861 - accuracy: 0.3417 - val_loss: 3.3441 - val_accuracy: 0.2724\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 247s 197ms/step - loss: 2.7354 - accuracy: 0.3513 - val_loss: 3.1139 - val_accuracy: 0.2993\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.6954 - accuracy: 0.3597 - val_loss: 3.3492 - val_accuracy: 0.2761\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 247s 197ms/step - loss: 2.6532 - accuracy: 0.3661 - val_loss: 3.0584 - val_accuracy: 0.3134\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.6550 - accuracy: 0.3663 - val_loss: 2.9307 - val_accuracy: 0.3359\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.5705 - accuracy: 0.3841 - val_loss: 3.2671 - val_accuracy: 0.2871\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 247s 197ms/step - loss: 2.5348 - accuracy: 0.3919 - val_loss: 3.3327 - val_accuracy: 0.2823\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.5004 - accuracy: 0.3971 - val_loss: 2.9401 - val_accuracy: 0.3412\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.4649 - accuracy: 0.4042 - val_loss: 2.9821 - val_accuracy: 0.3329\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 247s 197ms/step - loss: 2.4257 - accuracy: 0.4096 - val_loss: 3.3498 - val_accuracy: 0.2851\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 247s 197ms/step - loss: 2.3954 - accuracy: 0.4176 - val_loss: 3.2442 - val_accuracy: 0.3026\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.3657 - accuracy: 0.4216 - val_loss: 3.4759 - val_accuracy: 0.2710\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 246s 197ms/step - loss: 2.3355 - accuracy: 0.4302 - val_loss: 3.1359 - val_accuracy: 0.3181\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.2973 - accuracy: 0.4373 - val_loss: 3.3404 - val_accuracy: 0.2925\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 248s 198ms/step - loss: 2.2639 - accuracy: 0.4420 - val_loss: 3.0348 - val_accuracy: 0.3286\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1922676-7bb5-4e1e-b9da-9ab9ba7ddfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 64, 64, 128)       3584      \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               4194560   \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,524,552\n",
      "Trainable params: 35,520,200\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 248s 197ms/step - loss: 5.4756 - accuracy: 0.0117 - val_loss: 5.5637 - val_accuracy: 0.0180\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 5.1028 - accuracy: 0.0245 - val_loss: 5.3155 - val_accuracy: 0.0196\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 4.7687 - accuracy: 0.0467 - val_loss: 4.6350 - val_accuracy: 0.0645\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 4.5442 - accuracy: 0.0696 - val_loss: 4.4975 - val_accuracy: 0.0794\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 4.3386 - accuracy: 0.0943 - val_loss: 4.7653 - val_accuracy: 0.0787\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 4.1365 - accuracy: 0.1196 - val_loss: 4.2852 - val_accuracy: 0.1117\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.9618 - accuracy: 0.1440 - val_loss: 4.1598 - val_accuracy: 0.1279\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.8141 - accuracy: 0.1663 - val_loss: 4.2436 - val_accuracy: 0.1174\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 3.6710 - accuracy: 0.1871 - val_loss: 3.8419 - val_accuracy: 0.1764\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.5372 - accuracy: 0.2087 - val_loss: 3.8558 - val_accuracy: 0.1788\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.4277 - accuracy: 0.2281 - val_loss: 3.6283 - val_accuracy: 0.2127\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 3.3160 - accuracy: 0.2466 - val_loss: 3.6453 - val_accuracy: 0.2087\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.2331 - accuracy: 0.2614 - val_loss: 3.5996 - val_accuracy: 0.2167\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 3.1538 - accuracy: 0.2789 - val_loss: 3.5688 - val_accuracy: 0.2177\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 3.0482 - accuracy: 0.2937 - val_loss: 3.2856 - val_accuracy: 0.2645\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.9732 - accuracy: 0.3093 - val_loss: 3.5713 - val_accuracy: 0.2342\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.8999 - accuracy: 0.3224 - val_loss: 3.5618 - val_accuracy: 0.2325\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.8278 - accuracy: 0.3361 - val_loss: 3.0511 - val_accuracy: 0.3116\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.7546 - accuracy: 0.3486 - val_loss: 2.9999 - val_accuracy: 0.3142\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.6990 - accuracy: 0.3604 - val_loss: 3.1155 - val_accuracy: 0.2993\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.6346 - accuracy: 0.3731 - val_loss: 3.1331 - val_accuracy: 0.3041\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.5716 - accuracy: 0.3857 - val_loss: 2.9640 - val_accuracy: 0.3320\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.5207 - accuracy: 0.3948 - val_loss: 3.0332 - val_accuracy: 0.3196\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.4646 - accuracy: 0.4070 - val_loss: 3.0784 - val_accuracy: 0.3130\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.4183 - accuracy: 0.4172 - val_loss: 2.8666 - val_accuracy: 0.3528\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.3676 - accuracy: 0.4251 - val_loss: 2.8634 - val_accuracy: 0.3493\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.3097 - accuracy: 0.4377 - val_loss: 2.9527 - val_accuracy: 0.3415\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.2620 - accuracy: 0.4448 - val_loss: 2.9627 - val_accuracy: 0.3399\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.2110 - accuracy: 0.4572 - val_loss: 2.7605 - val_accuracy: 0.3770\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.1662 - accuracy: 0.4658 - val_loss: 3.0138 - val_accuracy: 0.3401\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.1184 - accuracy: 0.4766 - val_loss: 2.9861 - val_accuracy: 0.3501\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 2.0745 - accuracy: 0.4845 - val_loss: 2.7808 - val_accuracy: 0.3803\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 2.0298 - accuracy: 0.4925 - val_loss: 2.9380 - val_accuracy: 0.3632\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 1.9945 - accuracy: 0.5026 - val_loss: 2.9590 - val_accuracy: 0.3581\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.9463 - accuracy: 0.5116 - val_loss: 3.0833 - val_accuracy: 0.3456\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.9128 - accuracy: 0.5191 - val_loss: 2.6281 - val_accuracy: 0.4121\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 1.8735 - accuracy: 0.5257 - val_loss: 2.8370 - val_accuracy: 0.3828\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.8263 - accuracy: 0.5372 - val_loss: 2.8501 - val_accuracy: 0.3828\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.8016 - accuracy: 0.5417 - val_loss: 3.0172 - val_accuracy: 0.3679\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 1.7565 - accuracy: 0.5504 - val_loss: 2.9024 - val_accuracy: 0.3819\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.7172 - accuracy: 0.5563 - val_loss: 2.8221 - val_accuracy: 0.3951\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 1.6857 - accuracy: 0.5659 - val_loss: 2.9571 - val_accuracy: 0.3781\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.6472 - accuracy: 0.5735 - val_loss: 2.9057 - val_accuracy: 0.3859\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.6244 - accuracy: 0.5784 - val_loss: 2.8644 - val_accuracy: 0.3909\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 246s 196ms/step - loss: 1.5802 - accuracy: 0.5865 - val_loss: 2.9987 - val_accuracy: 0.3779\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 245s 196ms/step - loss: 1.5568 - accuracy: 0.5926 - val_loss: 2.8825 - val_accuracy: 0.3965\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "932e141b-1f8f-43b6-81e7-23f3f8381bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,868,040\n",
      "Trainable params: 6,863,496\n",
      "Non-trainable params: 4,544\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 48s 36ms/step - loss: 5.4405 - accuracy: 0.0114 - val_loss: 5.1910 - val_accuracy: 0.0140\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.0383 - accuracy: 0.0224 - val_loss: 5.0098 - val_accuracy: 0.0283\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.8038 - accuracy: 0.0379 - val_loss: 4.6032 - val_accuracy: 0.0557\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.5907 - accuracy: 0.0578 - val_loss: 4.5608 - val_accuracy: 0.0622\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.4280 - accuracy: 0.0753 - val_loss: 4.4466 - val_accuracy: 0.0822\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.3035 - accuracy: 0.0888 - val_loss: 4.3915 - val_accuracy: 0.0839\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.2080 - accuracy: 0.1000 - val_loss: 4.1450 - val_accuracy: 0.1116\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.1187 - accuracy: 0.1104 - val_loss: 4.2044 - val_accuracy: 0.1091\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.0343 - accuracy: 0.1223 - val_loss: 4.1179 - val_accuracy: 0.1226\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.9569 - accuracy: 0.1324 - val_loss: 4.2026 - val_accuracy: 0.1167\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.8855 - accuracy: 0.1444 - val_loss: 4.0182 - val_accuracy: 0.1363\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.8198 - accuracy: 0.1537 - val_loss: 4.1001 - val_accuracy: 0.1291\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.7589 - accuracy: 0.1635 - val_loss: 4.0740 - val_accuracy: 0.1351\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.6977 - accuracy: 0.1743 - val_loss: 3.7784 - val_accuracy: 0.1711\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.6512 - accuracy: 0.1819 - val_loss: 3.8547 - val_accuracy: 0.1650\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5959 - accuracy: 0.1933 - val_loss: 3.5404 - val_accuracy: 0.2035\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5476 - accuracy: 0.2008 - val_loss: 3.5546 - val_accuracy: 0.2048\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5089 - accuracy: 0.2050 - val_loss: 3.7053 - val_accuracy: 0.1818\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.4665 - accuracy: 0.2134 - val_loss: 3.5746 - val_accuracy: 0.2013\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.4261 - accuracy: 0.2215 - val_loss: 3.5677 - val_accuracy: 0.2112\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3868 - accuracy: 0.2264 - val_loss: 3.3960 - val_accuracy: 0.2286\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3522 - accuracy: 0.2337 - val_loss: 3.5531 - val_accuracy: 0.2118\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3222 - accuracy: 0.2402 - val_loss: 3.6435 - val_accuracy: 0.2036\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.2915 - accuracy: 0.2448 - val_loss: 3.4106 - val_accuracy: 0.2350\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.2638 - accuracy: 0.2508 - val_loss: 3.5205 - val_accuracy: 0.2205\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.2324 - accuracy: 0.2572 - val_loss: 3.5489 - val_accuracy: 0.2209\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1990 - accuracy: 0.2620 - val_loss: 3.4133 - val_accuracy: 0.2378\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1723 - accuracy: 0.2671 - val_loss: 3.2998 - val_accuracy: 0.2557\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1487 - accuracy: 0.2717 - val_loss: 3.3942 - val_accuracy: 0.2413\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1228 - accuracy: 0.2779 - val_loss: 3.5230 - val_accuracy: 0.2282\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1032 - accuracy: 0.2801 - val_loss: 3.3602 - val_accuracy: 0.2448\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0795 - accuracy: 0.2850 - val_loss: 3.4028 - val_accuracy: 0.2431\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0592 - accuracy: 0.2887 - val_loss: 3.4746 - val_accuracy: 0.2349\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0303 - accuracy: 0.2923 - val_loss: 3.3401 - val_accuracy: 0.2555\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0115 - accuracy: 0.2993 - val_loss: 3.2564 - val_accuracy: 0.2691\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9937 - accuracy: 0.3026 - val_loss: 3.3095 - val_accuracy: 0.2601\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9789 - accuracy: 0.3044 - val_loss: 3.1653 - val_accuracy: 0.2826\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9510 - accuracy: 0.3086 - val_loss: 3.3070 - val_accuracy: 0.2675\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9393 - accuracy: 0.3118 - val_loss: 3.4430 - val_accuracy: 0.2469\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9229 - accuracy: 0.3152 - val_loss: 3.3401 - val_accuracy: 0.2580\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9065 - accuracy: 0.3203 - val_loss: 3.1155 - val_accuracy: 0.2917\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8900 - accuracy: 0.3215 - val_loss: 3.2906 - val_accuracy: 0.2730\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8731 - accuracy: 0.3256 - val_loss: 3.2472 - val_accuracy: 0.2714\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8575 - accuracy: 0.3298 - val_loss: 3.2258 - val_accuracy: 0.2734\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8447 - accuracy: 0.3308 - val_loss: 3.2554 - val_accuracy: 0.2792\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8223 - accuracy: 0.3355 - val_loss: 3.1829 - val_accuracy: 0.2891\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8206 - accuracy: 0.3364 - val_loss: 3.1586 - val_accuracy: 0.2921\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8002 - accuracy: 0.3391 - val_loss: 3.2004 - val_accuracy: 0.2914\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7827 - accuracy: 0.3444 - val_loss: 2.9878 - val_accuracy: 0.3167\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7656 - accuracy: 0.3466 - val_loss: 3.0951 - val_accuracy: 0.3025\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7506 - accuracy: 0.3501 - val_loss: 3.2891 - val_accuracy: 0.2826\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7484 - accuracy: 0.3517 - val_loss: 3.0537 - val_accuracy: 0.3058\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7337 - accuracy: 0.3528 - val_loss: 3.1612 - val_accuracy: 0.2930\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7233 - accuracy: 0.3567 - val_loss: 3.0368 - val_accuracy: 0.3092\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7043 - accuracy: 0.3583 - val_loss: 3.1040 - val_accuracy: 0.3040\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6961 - accuracy: 0.3616 - val_loss: 3.0986 - val_accuracy: 0.3033\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6855 - accuracy: 0.3633 - val_loss: 3.1069 - val_accuracy: 0.3002\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6738 - accuracy: 0.3662 - val_loss: 3.2972 - val_accuracy: 0.2803\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6563 - accuracy: 0.3697 - val_loss: 2.9530 - val_accuracy: 0.3263\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6447 - accuracy: 0.3719 - val_loss: 3.0601 - val_accuracy: 0.3096\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6427 - accuracy: 0.3719 - val_loss: 3.1990 - val_accuracy: 0.2952\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6318 - accuracy: 0.3733 - val_loss: 3.1830 - val_accuracy: 0.2943\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6311 - accuracy: 0.3757 - val_loss: 3.1296 - val_accuracy: 0.3111\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6039 - accuracy: 0.3802 - val_loss: 3.0004 - val_accuracy: 0.3273\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5969 - accuracy: 0.3814 - val_loss: 3.0962 - val_accuracy: 0.3097\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5898 - accuracy: 0.3821 - val_loss: 3.0971 - val_accuracy: 0.3108\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5805 - accuracy: 0.3847 - val_loss: 3.0484 - val_accuracy: 0.3144\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5696 - accuracy: 0.3863 - val_loss: 3.0666 - val_accuracy: 0.3174\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.5586 - accuracy: 0.3893 - val_loss: 3.3222 - val_accuracy: 0.2861\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c550da7-291b-4a17-ad4c-03164ce5f039",
   "metadata": {},
   "source": [
    "# NIGHT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9990ee97-ca4a-4a3c-827a-b54075fd281c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 64, 64, 128)       3584      \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               4194560   \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,524,552\n",
      "Trainable params: 35,520,200\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 251s 200ms/step - loss: 5.9300 - accuracy: 0.0087 - val_loss: 5.6053 - val_accuracy: 0.0095\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 5.5015 - accuracy: 0.0152 - val_loss: 5.3376 - val_accuracy: 0.0153\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 248s 199ms/step - loss: 5.3275 - accuracy: 0.0235 - val_loss: 5.1177 - val_accuracy: 0.0248\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 5.2006 - accuracy: 0.0319 - val_loss: 5.0389 - val_accuracy: 0.0378\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 5.0863 - accuracy: 0.0390 - val_loss: 4.9996 - val_accuracy: 0.0414\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 4.9838 - accuracy: 0.0465 - val_loss: 5.0474 - val_accuracy: 0.0410\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 248s 199ms/step - loss: 4.8797 - accuracy: 0.0573 - val_loss: 5.2048 - val_accuracy: 0.0380\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 249s 199ms/step - loss: 4.7744 - accuracy: 0.0675 - val_loss: 5.4355 - val_accuracy: 0.0301\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 248s 199ms/step - loss: 4.6907 - accuracy: 0.0753 - val_loss: 5.2598 - val_accuracy: 0.0363\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 251s 201ms/step - loss: 4.6166 - accuracy: 0.0820 - val_loss: 5.3163 - val_accuracy: 0.0380\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 253s 202ms/step - loss: 4.5426 - accuracy: 0.0906 - val_loss: 5.4232 - val_accuracy: 0.0334\n",
      "Epoch 12/200\n",
      "  57/1250 [>.............................] - ETA: 3:44 - loss: 4.4916 - accuracy: 0.0976"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 55\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(conv_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     51\u001b[0m conv_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m),\n\u001b[0;32m     52\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     53\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 55\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc04ee-14cd-4fe4-bdf2-51fa60fef41e",
   "metadata": {},
   "source": [
    "# COMPARE WITH NOT BAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6926b610-08c7-49d7-a50d-836cbdffddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 64, 64, 3)    0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 64, 64, 32)   896         ['sequential[6][0]']             \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 64, 64, 32)   9248        ['conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64, 64, 32)   0           ['conv2d_62[0][0]',              \n",
      "                                                                  'conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 64, 64, 32)   9248        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 64, 64, 32)   0           ['conv2d_63[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 64, 64, 32)  128         ['add_1[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 32, 32, 32)  0           ['batch_normalization_28[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 32, 32, 32)   0           ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 32, 32, 64)   18496       ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 32, 32, 64)   36928       ['conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 64)   0           ['conv2d_65[0][0]',              \n",
      "                                                                  'conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 32, 32, 64)   36928       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 64)   0           ['conv2d_66[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 32, 32, 64)  256         ['add_3[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 16, 16, 64)  0           ['batch_normalization_29[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 16, 16, 64)   0           ['max_pooling2d_21[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 16, 16, 128)  73856       ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 16, 16, 128)  147584      ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 128)  0           ['conv2d_68[0][0]',              \n",
      "                                                                  'conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 16, 16, 128)  147584      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 128)  0           ['conv2d_69[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 16, 16, 128)  512        ['add_5[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 8, 8, 128)   0           ['batch_normalization_30[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 8, 8, 128)    0           ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 8, 8, 256)    295168      ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 256)    590080      ['conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 256)    0           ['conv2d_71[0][0]',              \n",
      "                                                                  'conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 8, 8, 256)    590080      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 256)    0           ['conv2d_72[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 8, 8, 256)   1024        ['add_7[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_31[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 4, 4, 256)    0           ['max_pooling2d_23[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 4096)         0           ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 512)          2097664     ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 512)         2048        ['dense_13[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 512)          0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 200)          102600      ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,160,328\n",
      "Trainable params: 4,158,344\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 5.7124 - accuracy: 0.0159 - val_loss: 5.3748 - val_accuracy: 0.0194\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.2163 - accuracy: 0.0341 - val_loss: 5.3128 - val_accuracy: 0.0295\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.9416 - accuracy: 0.0542 - val_loss: 5.4594 - val_accuracy: 0.0421\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.6980 - accuracy: 0.0764 - val_loss: 5.6519 - val_accuracy: 0.0391\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.5050 - accuracy: 0.0942 - val_loss: 5.3794 - val_accuracy: 0.0567\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.3374 - accuracy: 0.1116 - val_loss: 5.3255 - val_accuracy: 0.0578\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.1919 - accuracy: 0.1276 - val_loss: 4.9757 - val_accuracy: 0.0794\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.0506 - accuracy: 0.1435 - val_loss: 4.8227 - val_accuracy: 0.1024\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.9415 - accuracy: 0.1574 - val_loss: 4.5428 - val_accuracy: 0.1080\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.8292 - accuracy: 0.1744 - val_loss: 4.4077 - val_accuracy: 0.1253\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.7324 - accuracy: 0.1863 - val_loss: 4.1536 - val_accuracy: 0.1596\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.6480 - accuracy: 0.1981 - val_loss: 3.9620 - val_accuracy: 0.1718\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5681 - accuracy: 0.2113 - val_loss: 4.2425 - val_accuracy: 0.1354\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.5051 - accuracy: 0.2216 - val_loss: 4.0974 - val_accuracy: 0.1584\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.4290 - accuracy: 0.2335 - val_loss: 3.7664 - val_accuracy: 0.1973\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3676 - accuracy: 0.2441 - val_loss: 3.6724 - val_accuracy: 0.2155\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3114 - accuracy: 0.2523 - val_loss: 3.8290 - val_accuracy: 0.1884\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.2584 - accuracy: 0.2607 - val_loss: 3.6070 - val_accuracy: 0.2182\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.2097 - accuracy: 0.2679 - val_loss: 3.6859 - val_accuracy: 0.2095\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1703 - accuracy: 0.2769 - val_loss: 3.8591 - val_accuracy: 0.1835\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.1177 - accuracy: 0.2855 - val_loss: 3.6894 - val_accuracy: 0.2093\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0804 - accuracy: 0.2925 - val_loss: 3.4446 - val_accuracy: 0.2474\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0439 - accuracy: 0.2978 - val_loss: 3.7143 - val_accuracy: 0.2120\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9957 - accuracy: 0.3074 - val_loss: 3.6458 - val_accuracy: 0.2208\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9686 - accuracy: 0.3123 - val_loss: 3.5422 - val_accuracy: 0.2361\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9352 - accuracy: 0.3179 - val_loss: 3.3923 - val_accuracy: 0.2524\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8955 - accuracy: 0.3268 - val_loss: 3.5365 - val_accuracy: 0.2371\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8728 - accuracy: 0.3288 - val_loss: 3.3990 - val_accuracy: 0.2561\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8393 - accuracy: 0.3354 - val_loss: 3.3994 - val_accuracy: 0.2546\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8204 - accuracy: 0.3382 - val_loss: 3.3437 - val_accuracy: 0.2637\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7897 - accuracy: 0.3444 - val_loss: 3.3814 - val_accuracy: 0.2645\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.7657 - accuracy: 0.3488 - val_loss: 3.2297 - val_accuracy: 0.2815\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7392 - accuracy: 0.3541 - val_loss: 3.2383 - val_accuracy: 0.2801\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.7138 - accuracy: 0.3593 - val_loss: 3.3077 - val_accuracy: 0.2727\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.6898 - accuracy: 0.3638 - val_loss: 3.3777 - val_accuracy: 0.2616\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.6667 - accuracy: 0.3668 - val_loss: 3.3201 - val_accuracy: 0.2707\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6493 - accuracy: 0.3708 - val_loss: 3.1797 - val_accuracy: 0.2944\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.6308 - accuracy: 0.3724 - val_loss: 3.2789 - val_accuracy: 0.2854\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.6061 - accuracy: 0.3789 - val_loss: 3.2551 - val_accuracy: 0.2833\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5906 - accuracy: 0.3799 - val_loss: 3.2115 - val_accuracy: 0.2911\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5672 - accuracy: 0.3866 - val_loss: 3.2105 - val_accuracy: 0.2895\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.5549 - accuracy: 0.3888 - val_loss: 3.2121 - val_accuracy: 0.2887\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5323 - accuracy: 0.3922 - val_loss: 3.1132 - val_accuracy: 0.3061\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.5176 - accuracy: 0.3950 - val_loss: 3.2661 - val_accuracy: 0.2868\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.4960 - accuracy: 0.3992 - val_loss: 3.1896 - val_accuracy: 0.2988\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4803 - accuracy: 0.4025 - val_loss: 3.2614 - val_accuracy: 0.2913\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4629 - accuracy: 0.4027 - val_loss: 3.1437 - val_accuracy: 0.3040\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.4563 - accuracy: 0.4067 - val_loss: 3.1722 - val_accuracy: 0.3000\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4372 - accuracy: 0.4114 - val_loss: 3.2399 - val_accuracy: 0.2891\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.4233 - accuracy: 0.4121 - val_loss: 3.1466 - val_accuracy: 0.3045\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.4032 - accuracy: 0.4176 - val_loss: 3.1138 - val_accuracy: 0.3089\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3897 - accuracy: 0.4185 - val_loss: 3.1219 - val_accuracy: 0.3117\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.3793 - accuracy: 0.4207 - val_loss: 2.9966 - val_accuracy: 0.3277\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.3622 - accuracy: 0.4233 - val_loss: 3.2549 - val_accuracy: 0.2948\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.3473 - accuracy: 0.4255 - val_loss: 3.1572 - val_accuracy: 0.3054\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.3333 - accuracy: 0.4296 - val_loss: 3.1854 - val_accuracy: 0.3040\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.3316 - accuracy: 0.4302 - val_loss: 3.3138 - val_accuracy: 0.2873\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.3165 - accuracy: 0.4348 - val_loss: 3.0561 - val_accuracy: 0.3230\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.2959 - accuracy: 0.4376 - val_loss: 3.1686 - val_accuracy: 0.3038\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.2847 - accuracy: 0.4385 - val_loss: 3.2363 - val_accuracy: 0.2968\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.2722 - accuracy: 0.4432 - val_loss: 3.2523 - val_accuracy: 0.2975\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.2567 - accuracy: 0.4458 - val_loss: 3.2322 - val_accuracy: 0.3033\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.2517 - accuracy: 0.4462 - val_loss: 3.1549 - val_accuracy: 0.3119\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    # X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c53cde1e-80bb-47bb-b3f9-6c9d25854b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b863e58e-1144-4cee-9453-1cd818128266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 64, 64, 3)    0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 64, 64, 32)   896         ['sequential[7][0]']             \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 64, 64, 32)   9248        ['conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 64, 64, 32)   0           ['conv2d_74[0][0]',              \n",
      "                                                                  'conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 64, 64, 32)   9248        ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 64, 64, 32)   0           ['conv2d_75[0][0]',              \n",
      "                                                                  'conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 64, 64, 32)  128         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 32, 32, 32)  0           ['batch_normalization_33[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 32, 32, 32)   0           ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 32, 32, 64)   18496       ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 32, 32, 64)   36928       ['conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 32, 32, 64)   0           ['conv2d_77[0][0]',              \n",
      "                                                                  'conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 32, 32, 64)   36928       ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 32, 32, 64)   0           ['conv2d_78[0][0]',              \n",
      "                                                                  'conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 32, 32, 64)  256         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooling2D  (None, 16, 16, 64)  0           ['batch_normalization_34[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 16, 16, 64)   0           ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 16, 16, 128)  73856       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 16, 16, 128)  147584      ['conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 16, 16, 128)  0           ['conv2d_80[0][0]',              \n",
      "                                                                  'conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 16, 16, 128)  147584      ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 16, 16, 128)  0           ['conv2d_81[0][0]',              \n",
      "                                                                  'conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 16, 128)  512        ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 8, 8, 128)   0           ['batch_normalization_35[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 8, 8, 128)    0           ['max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 256)    295168      ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 256)    590080      ['conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 8, 8, 256)    0           ['conv2d_83[0][0]',              \n",
      "                                                                  'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 256)    590080      ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 8, 8, 256)    0           ['conv2d_84[0][0]',              \n",
      "                                                                  'conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 8, 8, 256)   1024        ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_36[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 4, 4, 256)    0           ['max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 4096)         0           ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 512)          2097664     ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 512)         2048        ['dense_15[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 512)          0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 200)          102600      ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,160,328\n",
      "Trainable params: 4,158,344\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.7250 - accuracy: 0.0179 - val_loss: 5.4490 - val_accuracy: 0.0310\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1758 - accuracy: 0.0383 - val_loss: 5.4675 - val_accuracy: 0.0276\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8979 - accuracy: 0.0580 - val_loss: 5.7615 - val_accuracy: 0.0319\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6705 - accuracy: 0.0781 - val_loss: 5.4027 - val_accuracy: 0.0479\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.4783 - accuracy: 0.0938 - val_loss: 5.2048 - val_accuracy: 0.0591\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.3147 - accuracy: 0.1128 - val_loss: 5.1707 - val_accuracy: 0.0671\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1656 - accuracy: 0.1292 - val_loss: 4.8978 - val_accuracy: 0.0796\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0403 - accuracy: 0.1448 - val_loss: 4.7495 - val_accuracy: 0.0913\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9194 - accuracy: 0.1586 - val_loss: 4.4486 - val_accuracy: 0.1130\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8199 - accuracy: 0.1727 - val_loss: 4.4709 - val_accuracy: 0.1104\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7244 - accuracy: 0.1858 - val_loss: 4.3892 - val_accuracy: 0.1211\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6414 - accuracy: 0.1989 - val_loss: 4.3354 - val_accuracy: 0.1295\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5596 - accuracy: 0.2115 - val_loss: 4.2177 - val_accuracy: 0.1399\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.4831 - accuracy: 0.2236 - val_loss: 4.1461 - val_accuracy: 0.1458\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.4233 - accuracy: 0.2342 - val_loss: 3.9465 - val_accuracy: 0.1736\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.3623 - accuracy: 0.2413 - val_loss: 4.0004 - val_accuracy: 0.1657\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.3020 - accuracy: 0.2530 - val_loss: 3.8582 - val_accuracy: 0.1804\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.2494 - accuracy: 0.2611 - val_loss: 3.7994 - val_accuracy: 0.1872\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1959 - accuracy: 0.2716 - val_loss: 4.0543 - val_accuracy: 0.1597\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.1556 - accuracy: 0.2788 - val_loss: 3.8496 - val_accuracy: 0.1846\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.1143 - accuracy: 0.2841 - val_loss: 3.8075 - val_accuracy: 0.1894\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0712 - accuracy: 0.2950 - val_loss: 3.5492 - val_accuracy: 0.2204\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 3.0287 - accuracy: 0.2998 - val_loss: 3.8369 - val_accuracy: 0.1856\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.9943 - accuracy: 0.3084 - val_loss: 3.5923 - val_accuracy: 0.2223\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9640 - accuracy: 0.3140 - val_loss: 3.7893 - val_accuracy: 0.1953\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.9341 - accuracy: 0.3173 - val_loss: 3.7309 - val_accuracy: 0.2061\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8974 - accuracy: 0.3235 - val_loss: 3.5360 - val_accuracy: 0.2278\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.8694 - accuracy: 0.3286 - val_loss: 3.6402 - val_accuracy: 0.2177\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.8425 - accuracy: 0.3354 - val_loss: 3.7110 - val_accuracy: 0.2113\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.8131 - accuracy: 0.3392 - val_loss: 3.7219 - val_accuracy: 0.2104\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7942 - accuracy: 0.3425 - val_loss: 3.5761 - val_accuracy: 0.2269\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7706 - accuracy: 0.3500 - val_loss: 3.5284 - val_accuracy: 0.2344\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7415 - accuracy: 0.3516 - val_loss: 3.6498 - val_accuracy: 0.2153\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.7201 - accuracy: 0.3585 - val_loss: 3.5059 - val_accuracy: 0.2412\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6941 - accuracy: 0.3603 - val_loss: 3.3436 - val_accuracy: 0.2613\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6746 - accuracy: 0.3653 - val_loss: 3.6335 - val_accuracy: 0.2295\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6530 - accuracy: 0.3690 - val_loss: 3.6207 - val_accuracy: 0.2311\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6356 - accuracy: 0.3725 - val_loss: 3.5268 - val_accuracy: 0.2396\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.6169 - accuracy: 0.3759 - val_loss: 3.4309 - val_accuracy: 0.2541\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5948 - accuracy: 0.3819 - val_loss: 3.5607 - val_accuracy: 0.2405\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5744 - accuracy: 0.3838 - val_loss: 3.3542 - val_accuracy: 0.2680\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5569 - accuracy: 0.3871 - val_loss: 3.3021 - val_accuracy: 0.2749\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5456 - accuracy: 0.3886 - val_loss: 3.2072 - val_accuracy: 0.2891\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.5250 - accuracy: 0.3918 - val_loss: 3.2804 - val_accuracy: 0.2805\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.5092 - accuracy: 0.3956 - val_loss: 3.3265 - val_accuracy: 0.2763\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4869 - accuracy: 0.4007 - val_loss: 3.3254 - val_accuracy: 0.2758\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4727 - accuracy: 0.4041 - val_loss: 3.2673 - val_accuracy: 0.2831\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4575 - accuracy: 0.4067 - val_loss: 3.4148 - val_accuracy: 0.2653\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4465 - accuracy: 0.4080 - val_loss: 3.2739 - val_accuracy: 0.2841\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4307 - accuracy: 0.4112 - val_loss: 3.1829 - val_accuracy: 0.2984\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.4177 - accuracy: 0.4147 - val_loss: 3.2858 - val_accuracy: 0.2819\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3942 - accuracy: 0.4181 - val_loss: 3.2015 - val_accuracy: 0.2968\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3943 - accuracy: 0.4174 - val_loss: 3.1527 - val_accuracy: 0.3027\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3682 - accuracy: 0.4227 - val_loss: 3.2624 - val_accuracy: 0.2871\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3630 - accuracy: 0.4230 - val_loss: 3.2752 - val_accuracy: 0.2898\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3485 - accuracy: 0.4267 - val_loss: 3.2654 - val_accuracy: 0.2864\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3315 - accuracy: 0.4308 - val_loss: 3.3016 - val_accuracy: 0.2840\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3277 - accuracy: 0.4314 - val_loss: 3.1452 - val_accuracy: 0.3152\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.3087 - accuracy: 0.4343 - val_loss: 3.3876 - val_accuracy: 0.2756\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.3028 - accuracy: 0.4353 - val_loss: 3.2366 - val_accuracy: 0.2975\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2819 - accuracy: 0.4400 - val_loss: 3.0322 - val_accuracy: 0.3259\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2811 - accuracy: 0.4394 - val_loss: 3.1410 - val_accuracy: 0.3081\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 2.2586 - accuracy: 0.4444 - val_loss: 3.1587 - val_accuracy: 0.3059\n",
      "Epoch 64/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2560 - accuracy: 0.4443 - val_loss: 3.1956 - val_accuracy: 0.3034\n",
      "Epoch 65/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2414 - accuracy: 0.4460 - val_loss: 3.1011 - val_accuracy: 0.3182\n",
      "Epoch 66/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2297 - accuracy: 0.4500 - val_loss: 3.1468 - val_accuracy: 0.3056\n",
      "Epoch 67/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2191 - accuracy: 0.4517 - val_loss: 3.0790 - val_accuracy: 0.3223\n",
      "Epoch 68/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.2074 - accuracy: 0.4541 - val_loss: 3.1080 - val_accuracy: 0.3182\n",
      "Epoch 69/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.1986 - accuracy: 0.4575 - val_loss: 3.1092 - val_accuracy: 0.3203\n",
      "Epoch 70/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.1887 - accuracy: 0.4573 - val_loss: 3.1164 - val_accuracy: 0.3219\n",
      "Epoch 71/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 2.1771 - accuracy: 0.4587 - val_loss: 3.1586 - val_accuracy: 0.3124\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    # X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    # X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    # X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    # X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    # X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad8bb78b-59bf-439d-9d43-f876cb3b9d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 64, 64, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 64, 64, 32)   896         ['sequential[8][0]']             \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 64, 64, 32)   9248        ['conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 64, 64, 32)   0           ['conv2d_86[0][0]',              \n",
      "                                                                  'conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 64, 64, 32)   9248        ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 64, 64, 32)   0           ['conv2d_87[0][0]',              \n",
      "                                                                  'conv2d_85[0][0]',              \n",
      "                                                                  'add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 64, 32)  128         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 32, 32, 32)  0           ['batch_normalization_38[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 32, 32, 32)   0           ['max_pooling2d_28[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 32, 32, 64)   18496       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 32, 32, 64)   36928       ['conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 32, 32, 64)   0           ['conv2d_89[0][0]',              \n",
      "                                                                  'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 32, 32, 64)   36928       ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 32, 32, 64)   0           ['conv2d_90[0][0]',              \n",
      "                                                                  'conv2d_88[0][0]',              \n",
      "                                                                  'add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 32, 32, 64)  256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 16, 16, 64)  0           ['batch_normalization_39[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 16, 16, 64)   0           ['max_pooling2d_29[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 16, 16, 128)  73856       ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 16, 16, 128)  147584      ['conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 16, 16, 128)  0           ['conv2d_92[0][0]',              \n",
      "                                                                  'conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 16, 16, 128)  147584      ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 16, 16, 128)  0           ['conv2d_93[0][0]',              \n",
      "                                                                  'conv2d_91[0][0]',              \n",
      "                                                                  'add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 16, 16, 128)  512        ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 8, 8, 128)   0           ['batch_normalization_40[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 8, 8, 128)    0           ['max_pooling2d_30[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 8, 8, 256)    295168      ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 8, 8, 256)    590080      ['conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 8, 8, 256)    0           ['conv2d_95[0][0]',              \n",
      "                                                                  'conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 8, 8, 256)    590080      ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 8, 8, 256)    0           ['conv2d_96[0][0]',              \n",
      "                                                                  'conv2d_94[0][0]',              \n",
      "                                                                  'add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 8, 8, 256)   1024        ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_41[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 4, 4, 256)    0           ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 4096)         0           ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          2097664     ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 512)         2048        ['dense_17[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 512)          0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 200)          102600      ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,160,328\n",
      "Trainable params: 4,158,344\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 5.7527 - accuracy: 0.0167 - val_loss: 5.5106 - val_accuracy: 0.0228\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 5.1798 - accuracy: 0.0388 - val_loss: 5.6986 - val_accuracy: 0.0246\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 4.9047 - accuracy: 0.0569 - val_loss: 5.4002 - val_accuracy: 0.0409\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 4.6617 - accuracy: 0.0756 - val_loss: 5.4589 - val_accuracy: 0.0481\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 4.4682 - accuracy: 0.0942 - val_loss: 5.2843 - val_accuracy: 0.0612\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 4.3076 - accuracy: 0.1124 - val_loss: 4.9644 - val_accuracy: 0.0793\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 4.1625 - accuracy: 0.1297 - val_loss: 4.9513 - val_accuracy: 0.0847\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 4.0350 - accuracy: 0.1453 - val_loss: 4.7199 - val_accuracy: 0.0933\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.9242 - accuracy: 0.1594 - val_loss: 4.5616 - val_accuracy: 0.1058\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.8200 - accuracy: 0.1727 - val_loss: 4.3203 - val_accuracy: 0.1339\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.7263 - accuracy: 0.1877 - val_loss: 4.3896 - val_accuracy: 0.1193\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.6395 - accuracy: 0.2020 - val_loss: 4.2295 - val_accuracy: 0.1397\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.5676 - accuracy: 0.2118 - val_loss: 4.0475 - val_accuracy: 0.1576\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.4936 - accuracy: 0.2238 - val_loss: 4.0254 - val_accuracy: 0.1618\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.4263 - accuracy: 0.2318 - val_loss: 3.9970 - val_accuracy: 0.1678\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 3.3689 - accuracy: 0.2429 - val_loss: 3.8748 - val_accuracy: 0.1803\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.3102 - accuracy: 0.2537 - val_loss: 3.7457 - val_accuracy: 0.1988\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.2567 - accuracy: 0.2619 - val_loss: 3.7322 - val_accuracy: 0.2014\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.2138 - accuracy: 0.2693 - val_loss: 3.6593 - val_accuracy: 0.2113\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.1611 - accuracy: 0.2796 - val_loss: 3.6348 - val_accuracy: 0.2178\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.1232 - accuracy: 0.2846 - val_loss: 3.6354 - val_accuracy: 0.2157\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.0843 - accuracy: 0.2910 - val_loss: 3.5664 - val_accuracy: 0.2228\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.0445 - accuracy: 0.2980 - val_loss: 3.6643 - val_accuracy: 0.2150\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 3.0102 - accuracy: 0.3052 - val_loss: 3.5415 - val_accuracy: 0.2289\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.9789 - accuracy: 0.3105 - val_loss: 3.7177 - val_accuracy: 0.2065\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.9492 - accuracy: 0.3145 - val_loss: 3.3472 - val_accuracy: 0.2589\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.9171 - accuracy: 0.3210 - val_loss: 3.4371 - val_accuracy: 0.2463\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8846 - accuracy: 0.3262 - val_loss: 3.5045 - val_accuracy: 0.2323\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8621 - accuracy: 0.3314 - val_loss: 3.4903 - val_accuracy: 0.2361\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8305 - accuracy: 0.3369 - val_loss: 3.4351 - val_accuracy: 0.2491\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.8067 - accuracy: 0.3399 - val_loss: 3.2938 - val_accuracy: 0.2697\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.7808 - accuracy: 0.3451 - val_loss: 3.3675 - val_accuracy: 0.2554\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 2.7587 - accuracy: 0.3498 - val_loss: 3.3237 - val_accuracy: 0.2654\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.7418 - accuracy: 0.3540 - val_loss: 3.4406 - val_accuracy: 0.2487\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.7142 - accuracy: 0.3583 - val_loss: 3.3002 - val_accuracy: 0.2713\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6972 - accuracy: 0.3610 - val_loss: 3.2881 - val_accuracy: 0.2708\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.6695 - accuracy: 0.3658 - val_loss: 3.3602 - val_accuracy: 0.2650\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6548 - accuracy: 0.3706 - val_loss: 3.2361 - val_accuracy: 0.2828\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 48s 38ms/step - loss: 2.6303 - accuracy: 0.3739 - val_loss: 3.2743 - val_accuracy: 0.2745\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 2.6118 - accuracy: 0.3774 - val_loss: 3.2380 - val_accuracy: 0.2846\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.6044 - accuracy: 0.3794 - val_loss: 3.2066 - val_accuracy: 0.2910\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.5778 - accuracy: 0.3827 - val_loss: 3.1757 - val_accuracy: 0.2925\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.5588 - accuracy: 0.3893 - val_loss: 3.2370 - val_accuracy: 0.2848\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.5446 - accuracy: 0.3888 - val_loss: 3.1189 - val_accuracy: 0.3031\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.5222 - accuracy: 0.3935 - val_loss: 3.2504 - val_accuracy: 0.2825\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.5083 - accuracy: 0.3962 - val_loss: 3.2378 - val_accuracy: 0.2835\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.4929 - accuracy: 0.4007 - val_loss: 3.1090 - val_accuracy: 0.3040\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.4714 - accuracy: 0.4026 - val_loss: 3.1297 - val_accuracy: 0.3011\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4595 - accuracy: 0.4062 - val_loss: 3.1205 - val_accuracy: 0.3049\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4505 - accuracy: 0.4087 - val_loss: 3.0557 - val_accuracy: 0.3140\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4354 - accuracy: 0.4091 - val_loss: 3.2157 - val_accuracy: 0.2924\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4208 - accuracy: 0.4145 - val_loss: 3.2015 - val_accuracy: 0.2976\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.4040 - accuracy: 0.4147 - val_loss: 3.0089 - val_accuracy: 0.3265\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 2.3929 - accuracy: 0.4176 - val_loss: 3.1468 - val_accuracy: 0.3043\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3809 - accuracy: 0.4213 - val_loss: 3.1352 - val_accuracy: 0.3047\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.3708 - accuracy: 0.4229 - val_loss: 3.1103 - val_accuracy: 0.3124\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3529 - accuracy: 0.4275 - val_loss: 3.1532 - val_accuracy: 0.3045\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3380 - accuracy: 0.4315 - val_loss: 3.1161 - val_accuracy: 0.3092\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 2.3274 - accuracy: 0.4303 - val_loss: 3.0559 - val_accuracy: 0.3202\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 48s 38ms/step - loss: 2.3134 - accuracy: 0.4325 - val_loss: 3.0724 - val_accuracy: 0.3210\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.2998 - accuracy: 0.4371 - val_loss: 3.0150 - val_accuracy: 0.3282\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 48s 38ms/step - loss: 2.2887 - accuracy: 0.4376 - val_loss: 3.1397 - val_accuracy: 0.3108\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 2.2811 - accuracy: 0.4412 - val_loss: 3.0606 - val_accuracy: 0.3187\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    # X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b982da3a-c569-4da5-bd5e-ab14c37c6853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_10 (Sequential)     (None, 64, 64, 3)    0           ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 64, 64, 32)   896         ['sequential_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 64, 64, 32)   9248        ['conv2d_121[0][0]']             \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 64, 64, 32)   0           ['conv2d_122[0][0]',             \n",
      "                                                                  'conv2d_121[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 64, 64, 32)   9248        ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 64, 64, 32)   0           ['conv2d_123[0][0]',             \n",
      "                                                                  'conv2d_121[0][0]',             \n",
      "                                                                  'add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 64, 64, 32)  128         ['add_41[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_40 (MaxPooling2D  (None, 32, 32, 32)  0           ['batch_normalization_53[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 32, 32, 32)   0           ['max_pooling2d_40[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 32, 32, 64)   18496       ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 32, 32, 64)   36928       ['conv2d_124[0][0]']             \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 32, 32, 64)   0           ['conv2d_125[0][0]',             \n",
      "                                                                  'conv2d_124[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 32, 32, 64)   36928       ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 32, 32, 64)   0           ['conv2d_126[0][0]',             \n",
      "                                                                  'conv2d_124[0][0]',             \n",
      "                                                                  'add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 32, 32, 64)  256         ['add_43[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_41 (MaxPooling2D  (None, 16, 16, 64)  0           ['batch_normalization_54[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 16, 16, 64)   0           ['max_pooling2d_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 16, 16, 128)  73856       ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 16, 16, 128)  147584      ['conv2d_127[0][0]']             \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 16, 16, 128)  0           ['conv2d_128[0][0]',             \n",
      "                                                                  'conv2d_127[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 16, 16, 128)  147584      ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 16, 16, 128)  0           ['conv2d_129[0][0]',             \n",
      "                                                                  'conv2d_127[0][0]',             \n",
      "                                                                  'add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 16, 16, 128)  512        ['add_45[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooling2D  (None, 8, 8, 128)   0           ['batch_normalization_55[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 8, 8, 128)    0           ['max_pooling2d_42[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 8, 8, 256)    295168      ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 8, 8, 256)    590080      ['conv2d_130[0][0]']             \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 8, 8, 256)    0           ['conv2d_131[0][0]',             \n",
      "                                                                  'conv2d_130[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 8, 8, 256)    590080      ['add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 8, 256)    0           ['conv2d_132[0][0]',             \n",
      "                                                                  'conv2d_130[0][0]',             \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 8, 8, 256)   1024        ['add_47[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_56[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 4, 4, 256)    0           ['max_pooling2d_43[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 4096)         0           ['dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 256)          1048832     ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 256)         1024        ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 256)          0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 200)          51400       ['dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 51s 40ms/step - loss: 5.1702 - accuracy: 0.0182 - val_loss: 5.0497 - val_accuracy: 0.0264\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 48s 38ms/step - loss: 4.8050 - accuracy: 0.0438 - val_loss: 4.7025 - val_accuracy: 0.0549\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 54s 43ms/step - loss: 4.6553 - accuracy: 0.0601 - val_loss: 4.4112 - val_accuracy: 0.0916\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 61s 49ms/step - loss: 4.5327 - accuracy: 0.0759 - val_loss: 4.3936 - val_accuracy: 0.0943\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 4.4313 - accuracy: 0.0862 - val_loss: 4.2900 - val_accuracy: 0.1047\n",
      "Epoch 6/200\n",
      " 461/1250 [==========>...................] - ETA: 29s - loss: 4.3742 - accuracy: 0.0913"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    # X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=20,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da6f46ab-a779-4169-b105-b64bd83e5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 64, 64, 3)    0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 64, 64, 32)   896         ['sequential[9][0]']             \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 64, 64, 32)   9248        ['conv2d_97[0][0]']              \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 64, 64, 32)   0           ['conv2d_98[0][0]',              \n",
      "                                                                  'conv2d_97[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 64, 64, 32)   9248        ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 64, 64, 32)   0           ['conv2d_99[0][0]',              \n",
      "                                                                  'add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 64, 64, 32)  128         ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 32, 32, 32)  0           ['batch_normalization_43[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 32, 32, 32)   0           ['max_pooling2d_32[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 32, 32, 64)   18496       ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 32, 32, 64)   36928       ['conv2d_100[0][0]']             \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 32, 32, 64)   0           ['conv2d_101[0][0]',             \n",
      "                                                                  'conv2d_100[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 32, 32, 64)   36928       ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 32, 32, 64)   0           ['conv2d_102[0][0]',             \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 32, 32, 64)  256         ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 16, 16, 64)  0           ['batch_normalization_44[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 16, 16, 64)   0           ['max_pooling2d_33[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 16, 128)  73856       ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 16, 128)  147584      ['conv2d_103[0][0]']             \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 16, 16, 128)  0           ['conv2d_104[0][0]',             \n",
      "                                                                  'conv2d_103[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 16, 16, 128)  147584      ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 16, 16, 128)  0           ['conv2d_105[0][0]',             \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 16, 16, 128)  512        ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooling2D  (None, 8, 8, 128)   0           ['batch_normalization_45[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 8, 8, 128)    0           ['max_pooling2d_34[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 8, 8, 256)    295168      ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 8, 8, 256)    590080      ['conv2d_106[0][0]']             \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 8, 8, 256)    0           ['conv2d_107[0][0]',             \n",
      "                                                                  'conv2d_106[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 8, 8, 256)    590080      ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 8, 8, 256)    0           ['conv2d_108[0][0]',             \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 8, 8, 256)   1024        ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_46[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 4, 4, 256)    0           ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 4096)         0           ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 512)          2097664     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          65664       ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 128)         512         ['dense_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 128)          0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 200)          25800       ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,147,656\n",
      "Trainable params: 4,146,440\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 5.2228 - accuracy: 0.0181 - val_loss: 5.4207 - val_accuracy: 0.0120\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 4.7984 - accuracy: 0.0500 - val_loss: 5.6300 - val_accuracy: 0.0210\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 4.5034 - accuracy: 0.0829 - val_loss: 5.3313 - val_accuracy: 0.0317\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 47s 38ms/step - loss: 4.2973 - accuracy: 0.1081 - val_loss: 5.1812 - val_accuracy: 0.0437\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 4.1325 - accuracy: 0.1295 - val_loss: 5.0072 - val_accuracy: 0.0514\n",
      "Epoch 6/200\n",
      " 237/1250 [====>.........................] - ETA: 34s - loss: 4.0560 - accuracy: 0.1372"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 76\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(conv_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     72\u001b[0m conv_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m),\n\u001b[0;32m     73\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     74\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 76\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.2)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ef7999-62de-4a56-8047-90b3171aa59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 64, 64, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 32)   896         ['sequential[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 32)   9248        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64, 64, 32)   0           ['conv2d_1[0][0]',               \n",
      "                                                                  'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 32)   9248        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 64, 64, 32)   0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d[0][0]',                 \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['add_1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 32, 32, 32)   0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 64)   18496       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 64)   36928       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 64)   0           ['conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   36928       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 32, 64)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]',               \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16, 16, 64)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 128)  73856       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  147584      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 128)  0           ['conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 128)  147584      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 128)  0           ['conv2d_8[0][0]',               \n",
      "                                                                  'conv2d_6[0][0]',               \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 8, 8, 128)    0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    295168      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 256)    590080      ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 256)    0           ['conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 256)    590080      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 256)    0           ['conv2d_11[0][0]',              \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 256)   1024        ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 256)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4, 4, 256)    0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          2097664     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 512)         2048        ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 512)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 200)          102600      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,160,328\n",
      "Trainable params: 4,158,344\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "1250/1250 [==============================] - 55s 39ms/step - loss: 5.2984 - accuracy: 0.0157 - val_loss: 5.3942 - val_accuracy: 0.0110\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 64, kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X_shortcut = X \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut])\n",
    "    X_shortcut_2 = X  \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.Add()([X, X_shortcut, X_shortcut_2])\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    # X = tf.keras.layers.Dense(units=128, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=64, epochs=1,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=20,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5d763f8-1fe7-4a82-a0b7-5fb91be66ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [5.2983598709106445],\n",
       " 'accuracy': [0.015699999406933784],\n",
       " 'val_loss': [5.394212245941162],\n",
       " 'val_accuracy': [0.010950000025331974]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bc3bf-7587-4210-9934-874d6d0ff38a",
   "metadata": {},
   "source": [
    "# MAX train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55230d76-4f4b-4abf-9a47-ab776987ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "   \n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "    \n",
    "history_list_3 = []\n",
    "for lr in [0.001, 0.0001, 0.00001, 0.000001]:\n",
    "    for bs in [64,128,256,512,1024]:\n",
    "        print(f'Learning rate: {lr}\\n Batch size: {bs}')\n",
    "        conv_model = convolutional_model((64, 64, 3))\n",
    "        print(conv_model.summary())\n",
    "        \n",
    "        conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "        history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=bs, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience=10,\n",
    "                verbose=0,\n",
    "                mode='auto',\n",
    "                baseline=None,\n",
    "                restore_best_weights=False\n",
    "            )])\n",
    "        history_list_3.append({lr: history.history})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a2e311-0f85-4c86-8a7a-56d68cb4edbc",
   "metadata": {},
   "source": [
    "# REPLAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "860894b6-86b8-4d68-85b1-79b6fdc6b03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      " Batch size: 64\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 52s 35ms/step - loss: 5.3810 - accuracy: 0.0141 - val_loss: 4.9981 - val_accuracy: 0.0260\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.8829 - accuracy: 0.0356 - val_loss: 4.6265 - val_accuracy: 0.0597\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.5905 - accuracy: 0.0620 - val_loss: 4.6851 - val_accuracy: 0.0576\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.4023 - accuracy: 0.0832 - val_loss: 4.4698 - val_accuracy: 0.0802\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.2706 - accuracy: 0.0995 - val_loss: 4.6035 - val_accuracy: 0.0771\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.1616 - accuracy: 0.1137 - val_loss: 4.5694 - val_accuracy: 0.0784\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.0692 - accuracy: 0.1270 - val_loss: 4.4601 - val_accuracy: 0.1019\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 10844s 9s/step - loss: 3.9811 - accuracy: 0.1393 - val_loss: 4.4912 - val_accuracy: 0.0949\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.9025 - accuracy: 0.1509 - val_loss: 4.2382 - val_accuracy: 0.1195\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 3.8189 - accuracy: 0.1636 - val_loss: 4.5223 - val_accuracy: 0.1081\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 3.7532 - accuracy: 0.1735 - val_loss: 4.3045 - val_accuracy: 0.1198\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 3.6910 - accuracy: 0.1828 - val_loss: 3.9552 - val_accuracy: 0.1536\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.6313 - accuracy: 0.1933 - val_loss: 4.2925 - val_accuracy: 0.1262\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 3.5823 - accuracy: 0.2007 - val_loss: 4.2204 - val_accuracy: 0.1353\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.5368 - accuracy: 0.2091 - val_loss: 4.3141 - val_accuracy: 0.1296\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 42s 34ms/step - loss: 3.4822 - accuracy: 0.2172 - val_loss: 3.7116 - val_accuracy: 0.1902\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.4457 - accuracy: 0.2226 - val_loss: 4.0924 - val_accuracy: 0.1450\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.3980 - accuracy: 0.2307 - val_loss: 3.7310 - val_accuracy: 0.1935\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3657 - accuracy: 0.2376 - val_loss: 3.7967 - val_accuracy: 0.1786\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.3375 - accuracy: 0.2419 - val_loss: 3.5147 - val_accuracy: 0.2199\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.3049 - accuracy: 0.2462 - val_loss: 3.6227 - val_accuracy: 0.2010\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2743 - accuracy: 0.2549 - val_loss: 3.6616 - val_accuracy: 0.2008\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2438 - accuracy: 0.2577 - val_loss: 3.6466 - val_accuracy: 0.2054\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2164 - accuracy: 0.2643 - val_loss: 3.6889 - val_accuracy: 0.2049\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1948 - accuracy: 0.2664 - val_loss: 3.9122 - val_accuracy: 0.1721\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1664 - accuracy: 0.2723 - val_loss: 3.5724 - val_accuracy: 0.2139\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1440 - accuracy: 0.2767 - val_loss: 3.5969 - val_accuracy: 0.2135\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1204 - accuracy: 0.2811 - val_loss: 3.9702 - val_accuracy: 0.1680\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1023 - accuracy: 0.2842 - val_loss: 3.4958 - val_accuracy: 0.2301\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0847 - accuracy: 0.2878 - val_loss: 3.5954 - val_accuracy: 0.2154\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0619 - accuracy: 0.2925 - val_loss: 3.8550 - val_accuracy: 0.1891\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0421 - accuracy: 0.2947 - val_loss: 3.9467 - val_accuracy: 0.1770\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0261 - accuracy: 0.2975 - val_loss: 3.7497 - val_accuracy: 0.1984\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0134 - accuracy: 0.3002 - val_loss: 3.5356 - val_accuracy: 0.2221\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9940 - accuracy: 0.3014 - val_loss: 3.5787 - val_accuracy: 0.2139\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9787 - accuracy: 0.3070 - val_loss: 3.6152 - val_accuracy: 0.2149\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9626 - accuracy: 0.3095 - val_loss: 3.6806 - val_accuracy: 0.2102\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9525 - accuracy: 0.3136 - val_loss: 3.4543 - val_accuracy: 0.2420\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9333 - accuracy: 0.3162 - val_loss: 3.3812 - val_accuracy: 0.2480\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9217 - accuracy: 0.3155 - val_loss: 3.5761 - val_accuracy: 0.2224\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.9037 - accuracy: 0.3221 - val_loss: 3.2997 - val_accuracy: 0.2596\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8881 - accuracy: 0.3228 - val_loss: 3.5419 - val_accuracy: 0.2210\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8794 - accuracy: 0.3249 - val_loss: 3.4775 - val_accuracy: 0.2339\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8699 - accuracy: 0.3268 - val_loss: 3.7465 - val_accuracy: 0.2060\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8450 - accuracy: 0.3329 - val_loss: 3.5895 - val_accuracy: 0.2277\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8432 - accuracy: 0.3300 - val_loss: 3.3279 - val_accuracy: 0.2577\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8290 - accuracy: 0.3341 - val_loss: 3.4535 - val_accuracy: 0.2437\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8191 - accuracy: 0.3365 - val_loss: 3.4637 - val_accuracy: 0.2386\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.8135 - accuracy: 0.3371 - val_loss: 3.5795 - val_accuracy: 0.2294\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.8007 - accuracy: 0.3401 - val_loss: 3.5245 - val_accuracy: 0.2361\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 2.7863 - accuracy: 0.3444 - val_loss: 3.3892 - val_accuracy: 0.2468\n",
      "Learning rate: 0.001\n",
      " Batch size: 128\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 8, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.3982 - accuracy: 0.0137 - val_loss: 5.3365 - val_accuracy: 0.0236\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.9291 - accuracy: 0.0354 - val_loss: 5.1854 - val_accuracy: 0.0374\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.6658 - accuracy: 0.0581 - val_loss: 4.7773 - val_accuracy: 0.0534\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.4580 - accuracy: 0.0799 - val_loss: 4.3832 - val_accuracy: 0.0956\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.2797 - accuracy: 0.1031 - val_loss: 4.2945 - val_accuracy: 0.1007\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.1497 - accuracy: 0.1206 - val_loss: 4.1854 - val_accuracy: 0.1177\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.0405 - accuracy: 0.1337 - val_loss: 4.1317 - val_accuracy: 0.1262\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.9445 - accuracy: 0.1477 - val_loss: 4.0678 - val_accuracy: 0.1373\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.8555 - accuracy: 0.1599 - val_loss: 3.7312 - val_accuracy: 0.1822\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.7789 - accuracy: 0.1733 - val_loss: 3.9122 - val_accuracy: 0.1630\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.7031 - accuracy: 0.1846 - val_loss: 3.7390 - val_accuracy: 0.1834\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6434 - accuracy: 0.1919 - val_loss: 3.5440 - val_accuracy: 0.2113\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5917 - accuracy: 0.2024 - val_loss: 3.7979 - val_accuracy: 0.1751\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5410 - accuracy: 0.2107 - val_loss: 3.6555 - val_accuracy: 0.1953\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4998 - accuracy: 0.2161 - val_loss: 3.7372 - val_accuracy: 0.1870\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4564 - accuracy: 0.2238 - val_loss: 3.8949 - val_accuracy: 0.1685\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4180 - accuracy: 0.2296 - val_loss: 3.7449 - val_accuracy: 0.1891\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3846 - accuracy: 0.2348 - val_loss: 3.5024 - val_accuracy: 0.2204\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3581 - accuracy: 0.2395 - val_loss: 3.6016 - val_accuracy: 0.2102\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3260 - accuracy: 0.2468 - val_loss: 3.7564 - val_accuracy: 0.1872\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2980 - accuracy: 0.2499 - val_loss: 3.5595 - val_accuracy: 0.2121\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2698 - accuracy: 0.2565 - val_loss: 4.0848 - val_accuracy: 0.1593\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2454 - accuracy: 0.2605 - val_loss: 3.6439 - val_accuracy: 0.2028\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2211 - accuracy: 0.2637 - val_loss: 3.5622 - val_accuracy: 0.2119\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2094 - accuracy: 0.2662 - val_loss: 3.6317 - val_accuracy: 0.2048\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1761 - accuracy: 0.2711 - val_loss: 3.3641 - val_accuracy: 0.2403\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1605 - accuracy: 0.2741 - val_loss: 3.4835 - val_accuracy: 0.2276\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1363 - accuracy: 0.2800 - val_loss: 3.4190 - val_accuracy: 0.2356\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1217 - accuracy: 0.2831 - val_loss: 3.5626 - val_accuracy: 0.2184\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1028 - accuracy: 0.2868 - val_loss: 3.6389 - val_accuracy: 0.2047\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0830 - accuracy: 0.2892 - val_loss: 3.3570 - val_accuracy: 0.2480\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0703 - accuracy: 0.2898 - val_loss: 3.3841 - val_accuracy: 0.2409\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0542 - accuracy: 0.2943 - val_loss: 3.6034 - val_accuracy: 0.2167\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0367 - accuracy: 0.2968 - val_loss: 3.5824 - val_accuracy: 0.2206\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0257 - accuracy: 0.2968 - val_loss: 3.3887 - val_accuracy: 0.2441\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9994 - accuracy: 0.3039 - val_loss: 3.6875 - val_accuracy: 0.2092\n",
      "Learning rate: 0.001\n",
      " Batch size: 256\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.4165 - accuracy: 0.0122 - val_loss: 5.1673 - val_accuracy: 0.0215\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.9655 - accuracy: 0.0306 - val_loss: 4.8617 - val_accuracy: 0.0457\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.6819 - accuracy: 0.0551 - val_loss: 4.6176 - val_accuracy: 0.0668\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.4459 - accuracy: 0.0803 - val_loss: 4.7444 - val_accuracy: 0.0658\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.2803 - accuracy: 0.1026 - val_loss: 4.7862 - val_accuracy: 0.0698\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.1644 - accuracy: 0.1175 - val_loss: 4.4655 - val_accuracy: 0.0958\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 4.0704 - accuracy: 0.1304 - val_loss: 4.5211 - val_accuracy: 0.0944\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.9798 - accuracy: 0.1436 - val_loss: 4.2203 - val_accuracy: 0.1225\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.9033 - accuracy: 0.1530 - val_loss: 4.3760 - val_accuracy: 0.1129\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.8317 - accuracy: 0.1638 - val_loss: 4.5543 - val_accuracy: 0.1034\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.7660 - accuracy: 0.1728 - val_loss: 3.9686 - val_accuracy: 0.1514\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.6988 - accuracy: 0.1845 - val_loss: 4.1112 - val_accuracy: 0.1396\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6401 - accuracy: 0.1921 - val_loss: 4.0594 - val_accuracy: 0.1470\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.5882 - accuracy: 0.2026 - val_loss: 3.9071 - val_accuracy: 0.1610\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.5458 - accuracy: 0.2070 - val_loss: 3.7641 - val_accuracy: 0.1830\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5032 - accuracy: 0.2132 - val_loss: 4.3506 - val_accuracy: 0.1277\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.4601 - accuracy: 0.2234 - val_loss: 3.9265 - val_accuracy: 0.1666\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4162 - accuracy: 0.2302 - val_loss: 4.0736 - val_accuracy: 0.1544\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3857 - accuracy: 0.2328 - val_loss: 3.8039 - val_accuracy: 0.1792\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3524 - accuracy: 0.2407 - val_loss: 3.9237 - val_accuracy: 0.1697\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3214 - accuracy: 0.2459 - val_loss: 3.9273 - val_accuracy: 0.1813\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2916 - accuracy: 0.2527 - val_loss: 3.6219 - val_accuracy: 0.2069\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2644 - accuracy: 0.2573 - val_loss: 3.8099 - val_accuracy: 0.1858\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2380 - accuracy: 0.2615 - val_loss: 3.7892 - val_accuracy: 0.1868\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2138 - accuracy: 0.2668 - val_loss: 3.6890 - val_accuracy: 0.2049\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1893 - accuracy: 0.2705 - val_loss: 3.8284 - val_accuracy: 0.1900\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1725 - accuracy: 0.2724 - val_loss: 3.6347 - val_accuracy: 0.2063\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.1481 - accuracy: 0.2767 - val_loss: 3.8870 - val_accuracy: 0.1814\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1219 - accuracy: 0.2813 - val_loss: 3.6741 - val_accuracy: 0.2109\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1050 - accuracy: 0.2833 - val_loss: 3.6878 - val_accuracy: 0.2048\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.0852 - accuracy: 0.2869 - val_loss: 3.6345 - val_accuracy: 0.2120\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0679 - accuracy: 0.2939 - val_loss: 3.8971 - val_accuracy: 0.1799\n",
      "Learning rate: 0.001\n",
      " Batch size: 512\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.4255 - accuracy: 0.0126 - val_loss: 5.1042 - val_accuracy: 0.0217\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.9728 - accuracy: 0.0281 - val_loss: 4.9172 - val_accuracy: 0.0347\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.7475 - accuracy: 0.0472 - val_loss: 4.6058 - val_accuracy: 0.0674\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.5917 - accuracy: 0.0665 - val_loss: 4.5609 - val_accuracy: 0.0716\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.4210 - accuracy: 0.0861 - val_loss: 4.3853 - val_accuracy: 0.0985\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.2527 - accuracy: 0.1070 - val_loss: 4.4329 - val_accuracy: 0.0972\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.1424 - accuracy: 0.1222 - val_loss: 4.4018 - val_accuracy: 0.1054\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.0375 - accuracy: 0.1353 - val_loss: 4.1765 - val_accuracy: 0.1264\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.9515 - accuracy: 0.1451 - val_loss: 4.1465 - val_accuracy: 0.1298\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.8666 - accuracy: 0.1585 - val_loss: 4.1356 - val_accuracy: 0.1332\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.7965 - accuracy: 0.1689 - val_loss: 4.0883 - val_accuracy: 0.1366\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.7341 - accuracy: 0.1780 - val_loss: 4.1294 - val_accuracy: 0.1374\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6655 - accuracy: 0.1882 - val_loss: 4.0202 - val_accuracy: 0.1500\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6112 - accuracy: 0.1982 - val_loss: 3.9311 - val_accuracy: 0.1621\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5617 - accuracy: 0.2053 - val_loss: 3.8754 - val_accuracy: 0.1662\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5162 - accuracy: 0.2122 - val_loss: 3.9119 - val_accuracy: 0.1666\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4726 - accuracy: 0.2207 - val_loss: 3.8822 - val_accuracy: 0.1664\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4431 - accuracy: 0.2256 - val_loss: 3.6205 - val_accuracy: 0.1987\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4038 - accuracy: 0.2338 - val_loss: 3.7780 - val_accuracy: 0.1864\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3674 - accuracy: 0.2385 - val_loss: 4.1910 - val_accuracy: 0.1437\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3402 - accuracy: 0.2435 - val_loss: 3.8559 - val_accuracy: 0.1769\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3071 - accuracy: 0.2479 - val_loss: 3.7248 - val_accuracy: 0.1940\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2812 - accuracy: 0.2527 - val_loss: 3.8397 - val_accuracy: 0.1764\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2634 - accuracy: 0.2564 - val_loss: 3.9697 - val_accuracy: 0.1682\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2378 - accuracy: 0.2607 - val_loss: 3.9031 - val_accuracy: 0.1802\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2085 - accuracy: 0.2666 - val_loss: 3.5868 - val_accuracy: 0.2162\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1910 - accuracy: 0.2690 - val_loss: 3.6395 - val_accuracy: 0.2077\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1678 - accuracy: 0.2733 - val_loss: 4.1040 - val_accuracy: 0.1618\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1480 - accuracy: 0.2758 - val_loss: 3.8207 - val_accuracy: 0.1854\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1305 - accuracy: 0.2761 - val_loss: 3.5763 - val_accuracy: 0.2181\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1091 - accuracy: 0.2820 - val_loss: 3.8619 - val_accuracy: 0.1856\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0922 - accuracy: 0.2860 - val_loss: 4.0710 - val_accuracy: 0.1646\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0802 - accuracy: 0.2892 - val_loss: 3.7340 - val_accuracy: 0.1972\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0619 - accuracy: 0.2916 - val_loss: 3.9646 - val_accuracy: 0.1841\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0447 - accuracy: 0.2952 - val_loss: 3.7978 - val_accuracy: 0.1876\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0251 - accuracy: 0.2981 - val_loss: 3.6458 - val_accuracy: 0.2170\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0141 - accuracy: 0.3015 - val_loss: 3.8787 - val_accuracy: 0.1893\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9970 - accuracy: 0.3044 - val_loss: 3.9133 - val_accuracy: 0.1821\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9907 - accuracy: 0.3054 - val_loss: 3.8260 - val_accuracy: 0.1951\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9699 - accuracy: 0.3096 - val_loss: 3.9831 - val_accuracy: 0.1793\n",
      "Learning rate: 0.001\n",
      " Batch size: 1024\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.4176 - accuracy: 0.0119 - val_loss: 4.9970 - val_accuracy: 0.0302\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.9653 - accuracy: 0.0297 - val_loss: 4.8095 - val_accuracy: 0.0450\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.7500 - accuracy: 0.0481 - val_loss: 4.6463 - val_accuracy: 0.0651\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.5740 - accuracy: 0.0672 - val_loss: 4.5132 - val_accuracy: 0.0799\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.3719 - accuracy: 0.0918 - val_loss: 4.2499 - val_accuracy: 0.1098\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.2338 - accuracy: 0.1070 - val_loss: 4.5321 - val_accuracy: 0.0917\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1332 - accuracy: 0.1218 - val_loss: 4.3664 - val_accuracy: 0.1015\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.0383 - accuracy: 0.1339 - val_loss: 4.6031 - val_accuracy: 0.0873\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.9549 - accuracy: 0.1459 - val_loss: 4.1455 - val_accuracy: 0.1269\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.8773 - accuracy: 0.1567 - val_loss: 4.0472 - val_accuracy: 0.1395\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8131 - accuracy: 0.1658 - val_loss: 3.7812 - val_accuracy: 0.1718\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.7536 - accuracy: 0.1732 - val_loss: 3.9760 - val_accuracy: 0.1503\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6907 - accuracy: 0.1858 - val_loss: 4.0237 - val_accuracy: 0.1448\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.6381 - accuracy: 0.1938 - val_loss: 4.2285 - val_accuracy: 0.1279\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5864 - accuracy: 0.2019 - val_loss: 3.8535 - val_accuracy: 0.1634\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5468 - accuracy: 0.2097 - val_loss: 3.8553 - val_accuracy: 0.1638\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.5070 - accuracy: 0.2156 - val_loss: 3.7198 - val_accuracy: 0.1880\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4629 - accuracy: 0.2218 - val_loss: 3.8385 - val_accuracy: 0.1763\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.4232 - accuracy: 0.2280 - val_loss: 3.7486 - val_accuracy: 0.1873\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3935 - accuracy: 0.2357 - val_loss: 4.1271 - val_accuracy: 0.1444\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3593 - accuracy: 0.2395 - val_loss: 3.8043 - val_accuracy: 0.1787\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.3267 - accuracy: 0.2450 - val_loss: 3.8525 - val_accuracy: 0.1758\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2959 - accuracy: 0.2492 - val_loss: 3.7019 - val_accuracy: 0.1941\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 43s 34ms/step - loss: 3.2754 - accuracy: 0.2537 - val_loss: 3.6807 - val_accuracy: 0.1968\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2495 - accuracy: 0.2594 - val_loss: 3.6834 - val_accuracy: 0.1981\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2247 - accuracy: 0.2620 - val_loss: 3.9748 - val_accuracy: 0.1720\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.2025 - accuracy: 0.2661 - val_loss: 3.7512 - val_accuracy: 0.1930\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1792 - accuracy: 0.2720 - val_loss: 3.6555 - val_accuracy: 0.2053\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1572 - accuracy: 0.2764 - val_loss: 3.5167 - val_accuracy: 0.2201\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1373 - accuracy: 0.2786 - val_loss: 3.8648 - val_accuracy: 0.1853\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1151 - accuracy: 0.2838 - val_loss: 3.4832 - val_accuracy: 0.2323\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.1050 - accuracy: 0.2851 - val_loss: 3.8909 - val_accuracy: 0.1817\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0779 - accuracy: 0.2892 - val_loss: 3.6427 - val_accuracy: 0.2096\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0615 - accuracy: 0.2902 - val_loss: 3.6531 - val_accuracy: 0.2113\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0452 - accuracy: 0.2943 - val_loss: 3.6276 - val_accuracy: 0.2134\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0254 - accuracy: 0.2986 - val_loss: 3.6782 - val_accuracy: 0.2134\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 3.0141 - accuracy: 0.3015 - val_loss: 3.6848 - val_accuracy: 0.2020\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9999 - accuracy: 0.3034 - val_loss: 3.6161 - val_accuracy: 0.2192\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9886 - accuracy: 0.3058 - val_loss: 3.3635 - val_accuracy: 0.2506\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9712 - accuracy: 0.3084 - val_loss: 3.4491 - val_accuracy: 0.2396\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9606 - accuracy: 0.3113 - val_loss: 3.7122 - val_accuracy: 0.2069\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9425 - accuracy: 0.3146 - val_loss: 3.7546 - val_accuracy: 0.1994\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9295 - accuracy: 0.3168 - val_loss: 3.4330 - val_accuracy: 0.2439\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9173 - accuracy: 0.3190 - val_loss: 3.6195 - val_accuracy: 0.2215\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.9076 - accuracy: 0.3208 - val_loss: 3.4735 - val_accuracy: 0.2406\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.8913 - accuracy: 0.3228 - val_loss: 3.7955 - val_accuracy: 0.2038\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.8839 - accuracy: 0.3237 - val_loss: 3.7407 - val_accuracy: 0.2057\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.8723 - accuracy: 0.3279 - val_loss: 3.5188 - val_accuracy: 0.2345\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 2.8573 - accuracy: 0.3294 - val_loss: 3.3811 - val_accuracy: 0.2505\n",
      "Learning rate: 0.0001\n",
      " Batch size: 64\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.6756 - accuracy: 0.0108 - val_loss: 5.4245 - val_accuracy: 0.0121\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 5.2652 - accuracy: 0.0225 - val_loss: 5.1155 - val_accuracy: 0.0240\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 5.0246 - accuracy: 0.0342 - val_loss: 5.1068 - val_accuracy: 0.0326\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.8296 - accuracy: 0.0503 - val_loss: 5.5559 - val_accuracy: 0.0239\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.6455 - accuracy: 0.0651 - val_loss: 5.4898 - val_accuracy: 0.0295\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.4949 - accuracy: 0.0804 - val_loss: 5.5496 - val_accuracy: 0.0302\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 4.3730 - accuracy: 0.0944 - val_loss: 5.0741 - val_accuracy: 0.0411\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2520 - accuracy: 0.1076 - val_loss: 4.8805 - val_accuracy: 0.0595\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1576 - accuracy: 0.1202 - val_loss: 4.6638 - val_accuracy: 0.0748\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0736 - accuracy: 0.1341 - val_loss: 4.3425 - val_accuracy: 0.1017\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9936 - accuracy: 0.1428 - val_loss: 4.6154 - val_accuracy: 0.0794\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9171 - accuracy: 0.1532 - val_loss: 4.5517 - val_accuracy: 0.0872\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8665 - accuracy: 0.1612 - val_loss: 4.2384 - val_accuracy: 0.1154\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8050 - accuracy: 0.1714 - val_loss: 4.5034 - val_accuracy: 0.0940\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7533 - accuracy: 0.1785 - val_loss: 4.2628 - val_accuracy: 0.1111\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7018 - accuracy: 0.1864 - val_loss: 4.1881 - val_accuracy: 0.1197\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6563 - accuracy: 0.1920 - val_loss: 4.3090 - val_accuracy: 0.1095\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6210 - accuracy: 0.1993 - val_loss: 4.2381 - val_accuracy: 0.1230\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5795 - accuracy: 0.2054 - val_loss: 3.9927 - val_accuracy: 0.1464\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5299 - accuracy: 0.2127 - val_loss: 4.2332 - val_accuracy: 0.1191\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4986 - accuracy: 0.2191 - val_loss: 4.0632 - val_accuracy: 0.1425\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4681 - accuracy: 0.2232 - val_loss: 4.0079 - val_accuracy: 0.1491\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4218 - accuracy: 0.2322 - val_loss: 4.1678 - val_accuracy: 0.1330\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3970 - accuracy: 0.2344 - val_loss: 4.2174 - val_accuracy: 0.1257\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3680 - accuracy: 0.2409 - val_loss: 4.1076 - val_accuracy: 0.1414\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3389 - accuracy: 0.2464 - val_loss: 3.8878 - val_accuracy: 0.1647\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3086 - accuracy: 0.2524 - val_loss: 4.1805 - val_accuracy: 0.1330\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2845 - accuracy: 0.2549 - val_loss: 3.8143 - val_accuracy: 0.1767\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2590 - accuracy: 0.2597 - val_loss: 4.0969 - val_accuracy: 0.1417\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2343 - accuracy: 0.2638 - val_loss: 3.9780 - val_accuracy: 0.1600\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2098 - accuracy: 0.2664 - val_loss: 4.0794 - val_accuracy: 0.1474\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1895 - accuracy: 0.2713 - val_loss: 3.7510 - val_accuracy: 0.1880\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1672 - accuracy: 0.2762 - val_loss: 3.9907 - val_accuracy: 0.1608\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1452 - accuracy: 0.2798 - val_loss: 3.9422 - val_accuracy: 0.1613\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1237 - accuracy: 0.2835 - val_loss: 3.8513 - val_accuracy: 0.1769\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1047 - accuracy: 0.2865 - val_loss: 3.8651 - val_accuracy: 0.1736\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0885 - accuracy: 0.2880 - val_loss: 3.8575 - val_accuracy: 0.1785\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0714 - accuracy: 0.2916 - val_loss: 4.0800 - val_accuracy: 0.1553\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0493 - accuracy: 0.2968 - val_loss: 3.8952 - val_accuracy: 0.1804\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0347 - accuracy: 0.3015 - val_loss: 3.7645 - val_accuracy: 0.1908\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0198 - accuracy: 0.3026 - val_loss: 3.9899 - val_accuracy: 0.1665\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0041 - accuracy: 0.3063 - val_loss: 3.9140 - val_accuracy: 0.1854\n",
      "Learning rate: 0.0001\n",
      " Batch size: 128\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 5.6522 - accuracy: 0.0114 - val_loss: 5.4115 - val_accuracy: 0.0124\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2535 - accuracy: 0.0218 - val_loss: 5.2509 - val_accuracy: 0.0222\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0339 - accuracy: 0.0356 - val_loss: 5.5291 - val_accuracy: 0.0185\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8239 - accuracy: 0.0502 - val_loss: 5.4045 - val_accuracy: 0.0367\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6487 - accuracy: 0.0642 - val_loss: 5.2418 - val_accuracy: 0.0373\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.5030 - accuracy: 0.0795 - val_loss: 4.9074 - val_accuracy: 0.0553\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.3750 - accuracy: 0.0932 - val_loss: 5.0563 - val_accuracy: 0.0575\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2588 - accuracy: 0.1068 - val_loss: 4.9115 - val_accuracy: 0.0567\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1678 - accuracy: 0.1191 - val_loss: 5.0231 - val_accuracy: 0.0582\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0858 - accuracy: 0.1308 - val_loss: 4.6320 - val_accuracy: 0.0856\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0001 - accuracy: 0.1430 - val_loss: 4.8064 - val_accuracy: 0.0701\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9346 - accuracy: 0.1517 - val_loss: 4.5013 - val_accuracy: 0.0918\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8618 - accuracy: 0.1638 - val_loss: 4.3464 - val_accuracy: 0.1110\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8127 - accuracy: 0.1687 - val_loss: 4.4522 - val_accuracy: 0.0976\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7539 - accuracy: 0.1785 - val_loss: 4.3848 - val_accuracy: 0.1097\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7092 - accuracy: 0.1866 - val_loss: 4.1620 - val_accuracy: 0.1273\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6577 - accuracy: 0.1941 - val_loss: 4.1657 - val_accuracy: 0.1285\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6141 - accuracy: 0.2006 - val_loss: 4.1969 - val_accuracy: 0.1251\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5718 - accuracy: 0.2053 - val_loss: 4.3014 - val_accuracy: 0.1195\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5346 - accuracy: 0.2137 - val_loss: 4.0922 - val_accuracy: 0.1406\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4975 - accuracy: 0.2183 - val_loss: 4.1098 - val_accuracy: 0.1356\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4623 - accuracy: 0.2255 - val_loss: 4.2778 - val_accuracy: 0.1164\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4122 - accuracy: 0.2333 - val_loss: 3.8309 - val_accuracy: 0.1709\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3943 - accuracy: 0.2376 - val_loss: 3.9375 - val_accuracy: 0.1550\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3601 - accuracy: 0.2410 - val_loss: 4.0674 - val_accuracy: 0.1497\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3279 - accuracy: 0.2481 - val_loss: 4.0353 - val_accuracy: 0.1476\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3027 - accuracy: 0.2515 - val_loss: 3.8365 - val_accuracy: 0.1737\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2810 - accuracy: 0.2540 - val_loss: 4.0382 - val_accuracy: 0.1513\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2527 - accuracy: 0.2597 - val_loss: 3.9795 - val_accuracy: 0.1568\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2261 - accuracy: 0.2637 - val_loss: 3.8844 - val_accuracy: 0.1716\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2066 - accuracy: 0.2676 - val_loss: 3.8586 - val_accuracy: 0.1744\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1817 - accuracy: 0.2729 - val_loss: 4.0599 - val_accuracy: 0.1573\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1636 - accuracy: 0.2763 - val_loss: 4.0278 - val_accuracy: 0.1556\n",
      "Learning rate: 0.0001\n",
      " Batch size: 256\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 5.6353 - accuracy: 0.0110 - val_loss: 5.5930 - val_accuracy: 0.0125\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2357 - accuracy: 0.0218 - val_loss: 6.2456 - val_accuracy: 0.0136\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0265 - accuracy: 0.0331 - val_loss: 5.3646 - val_accuracy: 0.0232\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8275 - accuracy: 0.0489 - val_loss: 5.5940 - val_accuracy: 0.0208\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6589 - accuracy: 0.0643 - val_loss: 5.2952 - val_accuracy: 0.0360\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.5211 - accuracy: 0.0764 - val_loss: 4.6162 - val_accuracy: 0.0716\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.3912 - accuracy: 0.0921 - val_loss: 4.9178 - val_accuracy: 0.0550\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2749 - accuracy: 0.1056 - val_loss: 4.8339 - val_accuracy: 0.0605\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1843 - accuracy: 0.1169 - val_loss: 4.4807 - val_accuracy: 0.0849\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0973 - accuracy: 0.1275 - val_loss: 4.5326 - val_accuracy: 0.0858\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0216 - accuracy: 0.1394 - val_loss: 4.4669 - val_accuracy: 0.0879\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9509 - accuracy: 0.1483 - val_loss: 4.5109 - val_accuracy: 0.0914\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8878 - accuracy: 0.1581 - val_loss: 4.2779 - val_accuracy: 0.1136\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8294 - accuracy: 0.1668 - val_loss: 4.3722 - val_accuracy: 0.1074\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7816 - accuracy: 0.1732 - val_loss: 4.2339 - val_accuracy: 0.1179\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7262 - accuracy: 0.1813 - val_loss: 4.2035 - val_accuracy: 0.1238\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6763 - accuracy: 0.1895 - val_loss: 4.1146 - val_accuracy: 0.1327\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6327 - accuracy: 0.1956 - val_loss: 4.2475 - val_accuracy: 0.1206\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5907 - accuracy: 0.2029 - val_loss: 4.3190 - val_accuracy: 0.1157\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5491 - accuracy: 0.2090 - val_loss: 4.0250 - val_accuracy: 0.1408\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5119 - accuracy: 0.2163 - val_loss: 4.0669 - val_accuracy: 0.1432\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4767 - accuracy: 0.2230 - val_loss: 3.9243 - val_accuracy: 0.1608\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4430 - accuracy: 0.2281 - val_loss: 3.8199 - val_accuracy: 0.1765\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4068 - accuracy: 0.2338 - val_loss: 4.3659 - val_accuracy: 0.1168\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3731 - accuracy: 0.2373 - val_loss: 3.9031 - val_accuracy: 0.1654\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3571 - accuracy: 0.2419 - val_loss: 3.9058 - val_accuracy: 0.1645\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3255 - accuracy: 0.2476 - val_loss: 3.8969 - val_accuracy: 0.1631\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3001 - accuracy: 0.2495 - val_loss: 3.8612 - val_accuracy: 0.1738\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2741 - accuracy: 0.2574 - val_loss: 3.8847 - val_accuracy: 0.1715\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2446 - accuracy: 0.2608 - val_loss: 3.7560 - val_accuracy: 0.1857\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2202 - accuracy: 0.2661 - val_loss: 3.9347 - val_accuracy: 0.1669\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2019 - accuracy: 0.2682 - val_loss: 3.7501 - val_accuracy: 0.1840\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1839 - accuracy: 0.2729 - val_loss: 3.7643 - val_accuracy: 0.1901\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1616 - accuracy: 0.2762 - val_loss: 3.7234 - val_accuracy: 0.1905\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1441 - accuracy: 0.2822 - val_loss: 3.6881 - val_accuracy: 0.1968\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1262 - accuracy: 0.2842 - val_loss: 3.8138 - val_accuracy: 0.1802\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1077 - accuracy: 0.2879 - val_loss: 3.8387 - val_accuracy: 0.1832\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0911 - accuracy: 0.2886 - val_loss: 3.6628 - val_accuracy: 0.2027\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0731 - accuracy: 0.2924 - val_loss: 3.7271 - val_accuracy: 0.1996\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0565 - accuracy: 0.2961 - val_loss: 3.7273 - val_accuracy: 0.1892\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0460 - accuracy: 0.2975 - val_loss: 3.6321 - val_accuracy: 0.2076\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0179 - accuracy: 0.3029 - val_loss: 3.6035 - val_accuracy: 0.2174\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0129 - accuracy: 0.3032 - val_loss: 3.7332 - val_accuracy: 0.1975\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9994 - accuracy: 0.3054 - val_loss: 3.8159 - val_accuracy: 0.1902\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9853 - accuracy: 0.3100 - val_loss: 3.7718 - val_accuracy: 0.1967\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9677 - accuracy: 0.3118 - val_loss: 3.7327 - val_accuracy: 0.1963\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9573 - accuracy: 0.3125 - val_loss: 3.5931 - val_accuracy: 0.2180\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9445 - accuracy: 0.3183 - val_loss: 3.5992 - val_accuracy: 0.2154\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9335 - accuracy: 0.3180 - val_loss: 3.7859 - val_accuracy: 0.1952\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9232 - accuracy: 0.3199 - val_loss: 3.8326 - val_accuracy: 0.1929\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.9094 - accuracy: 0.3227 - val_loss: 3.4765 - val_accuracy: 0.2324\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8942 - accuracy: 0.3277 - val_loss: 3.6740 - val_accuracy: 0.2155\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8823 - accuracy: 0.3279 - val_loss: 3.6671 - val_accuracy: 0.2104\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8688 - accuracy: 0.3315 - val_loss: 3.7756 - val_accuracy: 0.1927\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8580 - accuracy: 0.3322 - val_loss: 3.6693 - val_accuracy: 0.2089\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8450 - accuracy: 0.3350 - val_loss: 3.4507 - val_accuracy: 0.2392\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8386 - accuracy: 0.3353 - val_loss: 3.5075 - val_accuracy: 0.2341\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8292 - accuracy: 0.3385 - val_loss: 3.6707 - val_accuracy: 0.2137\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8253 - accuracy: 0.3406 - val_loss: 3.3661 - val_accuracy: 0.2544\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8137 - accuracy: 0.3416 - val_loss: 3.6223 - val_accuracy: 0.2225\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.8032 - accuracy: 0.3452 - val_loss: 3.6199 - val_accuracy: 0.2209\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7932 - accuracy: 0.3432 - val_loss: 3.6572 - val_accuracy: 0.2168\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7875 - accuracy: 0.3447 - val_loss: 3.6210 - val_accuracy: 0.2187\n",
      "Epoch 64/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7715 - accuracy: 0.3480 - val_loss: 3.6780 - val_accuracy: 0.2134\n",
      "Epoch 65/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7607 - accuracy: 0.3533 - val_loss: 3.9117 - val_accuracy: 0.1908\n",
      "Epoch 66/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7515 - accuracy: 0.3544 - val_loss: 3.4693 - val_accuracy: 0.2459\n",
      "Epoch 67/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7442 - accuracy: 0.3551 - val_loss: 3.6707 - val_accuracy: 0.2180\n",
      "Epoch 68/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7315 - accuracy: 0.3558 - val_loss: 3.4614 - val_accuracy: 0.2494\n",
      "Epoch 69/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 2.7236 - accuracy: 0.3576 - val_loss: 3.3618 - val_accuracy: 0.2580\n",
      "Learning rate: 0.0001\n",
      " Batch size: 512\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 5.5994 - accuracy: 0.0147 - val_loss: 5.0885 - val_accuracy: 0.0233\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2080 - accuracy: 0.0249 - val_loss: 4.9494 - val_accuracy: 0.0360\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0255 - accuracy: 0.0352 - val_loss: 5.1668 - val_accuracy: 0.0243\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8176 - accuracy: 0.0511 - val_loss: 5.0648 - val_accuracy: 0.0391\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6367 - accuracy: 0.0677 - val_loss: 4.9205 - val_accuracy: 0.0520\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.4904 - accuracy: 0.0804 - val_loss: 5.1893 - val_accuracy: 0.0468\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.3631 - accuracy: 0.0951 - val_loss: 5.1264 - val_accuracy: 0.0466\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2558 - accuracy: 0.1081 - val_loss: 5.2061 - val_accuracy: 0.0466\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1618 - accuracy: 0.1201 - val_loss: 4.7467 - val_accuracy: 0.0611\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0838 - accuracy: 0.1302 - val_loss: 4.7029 - val_accuracy: 0.0768\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0100 - accuracy: 0.1423 - val_loss: 4.7513 - val_accuracy: 0.0725\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9404 - accuracy: 0.1511 - val_loss: 4.7920 - val_accuracy: 0.0737\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8774 - accuracy: 0.1595 - val_loss: 4.3972 - val_accuracy: 0.0987\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8221 - accuracy: 0.1681 - val_loss: 4.1666 - val_accuracy: 0.1300\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7704 - accuracy: 0.1751 - val_loss: 4.1070 - val_accuracy: 0.1320\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7156 - accuracy: 0.1832 - val_loss: 4.1402 - val_accuracy: 0.1296\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6738 - accuracy: 0.1900 - val_loss: 4.1986 - val_accuracy: 0.1294\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6245 - accuracy: 0.1982 - val_loss: 4.1741 - val_accuracy: 0.1307\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5857 - accuracy: 0.2051 - val_loss: 4.0939 - val_accuracy: 0.1371\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5541 - accuracy: 0.2104 - val_loss: 3.9498 - val_accuracy: 0.1525\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5210 - accuracy: 0.2158 - val_loss: 4.0641 - val_accuracy: 0.1456\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4786 - accuracy: 0.2227 - val_loss: 3.8051 - val_accuracy: 0.1732\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4412 - accuracy: 0.2283 - val_loss: 4.0477 - val_accuracy: 0.1511\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4146 - accuracy: 0.2326 - val_loss: 3.8977 - val_accuracy: 0.1629\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3854 - accuracy: 0.2379 - val_loss: 4.1509 - val_accuracy: 0.1366\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3512 - accuracy: 0.2425 - val_loss: 3.8247 - val_accuracy: 0.1754\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3255 - accuracy: 0.2474 - val_loss: 3.9056 - val_accuracy: 0.1663\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3004 - accuracy: 0.2512 - val_loss: 3.9794 - val_accuracy: 0.1586\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2817 - accuracy: 0.2544 - val_loss: 4.0742 - val_accuracy: 0.1493\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2492 - accuracy: 0.2631 - val_loss: 3.8632 - val_accuracy: 0.1717\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2188 - accuracy: 0.2657 - val_loss: 3.6514 - val_accuracy: 0.2004\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2005 - accuracy: 0.2708 - val_loss: 3.9816 - val_accuracy: 0.1649\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1768 - accuracy: 0.2762 - val_loss: 3.6886 - val_accuracy: 0.1984\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1557 - accuracy: 0.2764 - val_loss: 4.0649 - val_accuracy: 0.1519\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1390 - accuracy: 0.2807 - val_loss: 3.8101 - val_accuracy: 0.1820\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1171 - accuracy: 0.2841 - val_loss: 3.7469 - val_accuracy: 0.1903\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0969 - accuracy: 0.2901 - val_loss: 3.8620 - val_accuracy: 0.1795\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0821 - accuracy: 0.2912 - val_loss: 3.8397 - val_accuracy: 0.1804\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0658 - accuracy: 0.2934 - val_loss: 3.7929 - val_accuracy: 0.1884\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0433 - accuracy: 0.2970 - val_loss: 3.7462 - val_accuracy: 0.1929\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0307 - accuracy: 0.2987 - val_loss: 3.8780 - val_accuracy: 0.1754\n",
      "Learning rate: 0.0001\n",
      " Batch size: 1024\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 5.6732 - accuracy: 0.0113 - val_loss: 5.1384 - val_accuracy: 0.0214\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.2253 - accuracy: 0.0237 - val_loss: 5.1768 - val_accuracy: 0.0221\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0012 - accuracy: 0.0380 - val_loss: 5.1153 - val_accuracy: 0.0355\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 4.7944 - accuracy: 0.0542 - val_loss: 5.2428 - val_accuracy: 0.0316\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.6291 - accuracy: 0.0666 - val_loss: 5.2795 - val_accuracy: 0.0378\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.4864 - accuracy: 0.0825 - val_loss: 4.8929 - val_accuracy: 0.0574\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.3633 - accuracy: 0.0969 - val_loss: 4.9691 - val_accuracy: 0.0506\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.2487 - accuracy: 0.1103 - val_loss: 4.8757 - val_accuracy: 0.0518\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.1653 - accuracy: 0.1194 - val_loss: 4.7034 - val_accuracy: 0.0661\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0797 - accuracy: 0.1315 - val_loss: 4.6720 - val_accuracy: 0.0720\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.0012 - accuracy: 0.1414 - val_loss: 4.5147 - val_accuracy: 0.0891\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.9359 - accuracy: 0.1500 - val_loss: 4.3249 - val_accuracy: 0.1074\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8669 - accuracy: 0.1617 - val_loss: 4.4701 - val_accuracy: 0.0891\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.8104 - accuracy: 0.1685 - val_loss: 4.3716 - val_accuracy: 0.0972\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7636 - accuracy: 0.1760 - val_loss: 4.1894 - val_accuracy: 0.1187\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.7077 - accuracy: 0.1859 - val_loss: 4.4408 - val_accuracy: 0.0978\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6691 - accuracy: 0.1896 - val_loss: 4.1504 - val_accuracy: 0.1261\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.6255 - accuracy: 0.1965 - val_loss: 4.3672 - val_accuracy: 0.1051\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5729 - accuracy: 0.2055 - val_loss: 4.0949 - val_accuracy: 0.1327\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5389 - accuracy: 0.2117 - val_loss: 4.0031 - val_accuracy: 0.1462\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.5003 - accuracy: 0.2177 - val_loss: 4.1787 - val_accuracy: 0.1277\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4655 - accuracy: 0.2254 - val_loss: 4.2373 - val_accuracy: 0.1226\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.4288 - accuracy: 0.2287 - val_loss: 4.3380 - val_accuracy: 0.1198\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3927 - accuracy: 0.2362 - val_loss: 4.4679 - val_accuracy: 0.1041\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3642 - accuracy: 0.2419 - val_loss: 3.9945 - val_accuracy: 0.1488\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 3.3400 - accuracy: 0.2453 - val_loss: 4.1563 - val_accuracy: 0.1341\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.3097 - accuracy: 0.2505 - val_loss: 3.7422 - val_accuracy: 0.1865\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2831 - accuracy: 0.2566 - val_loss: 3.9816 - val_accuracy: 0.1556\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2566 - accuracy: 0.2598 - val_loss: 3.9796 - val_accuracy: 0.1582\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2331 - accuracy: 0.2639 - val_loss: 3.9760 - val_accuracy: 0.1585\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.2059 - accuracy: 0.2694 - val_loss: 3.9677 - val_accuracy: 0.1589\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1900 - accuracy: 0.2703 - val_loss: 4.0584 - val_accuracy: 0.1534\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1684 - accuracy: 0.2744 - val_loss: 4.5087 - val_accuracy: 0.1144\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1424 - accuracy: 0.2804 - val_loss: 3.9485 - val_accuracy: 0.1662\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1286 - accuracy: 0.2822 - val_loss: 4.0272 - val_accuracy: 0.1579\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.1063 - accuracy: 0.2886 - val_loss: 3.8871 - val_accuracy: 0.1740\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 3.0896 - accuracy: 0.2897 - val_loss: 3.8628 - val_accuracy: 0.1734\n",
      "Learning rate: 1e-05\n",
      " Batch size: 64\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_52 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.2676 - accuracy: 0.0059 - val_loss: 5.4791 - val_accuracy: 0.0074\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0172 - accuracy: 0.0085 - val_loss: 5.4829 - val_accuracy: 0.0116\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.7959 - accuracy: 0.0104 - val_loss: 5.4803 - val_accuracy: 0.0126\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6598 - accuracy: 0.0121 - val_loss: 5.4336 - val_accuracy: 0.0117\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5541 - accuracy: 0.0130 - val_loss: 5.3745 - val_accuracy: 0.0120\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4854 - accuracy: 0.0144 - val_loss: 5.3131 - val_accuracy: 0.0137\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4188 - accuracy: 0.0167 - val_loss: 5.3034 - val_accuracy: 0.0162\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3529 - accuracy: 0.0197 - val_loss: 5.3534 - val_accuracy: 0.0170\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2994 - accuracy: 0.0222 - val_loss: 5.4075 - val_accuracy: 0.0185\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2485 - accuracy: 0.0255 - val_loss: 5.3915 - val_accuracy: 0.0206\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1901 - accuracy: 0.0282 - val_loss: 5.5467 - val_accuracy: 0.0223\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1523 - accuracy: 0.0308 - val_loss: 5.4266 - val_accuracy: 0.0232\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1115 - accuracy: 0.0341 - val_loss: 5.5114 - val_accuracy: 0.0267\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0756 - accuracy: 0.0358 - val_loss: 5.5100 - val_accuracy: 0.0246\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0337 - accuracy: 0.0395 - val_loss: 5.6270 - val_accuracy: 0.0239\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 4.9903 - accuracy: 0.0404 - val_loss: 5.5818 - val_accuracy: 0.0223\n",
      "Learning rate: 1e-05\n",
      " Batch size: 128\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_140 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_142 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 6.2608 - accuracy: 0.0058 - val_loss: 5.5727 - val_accuracy: 0.0061\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0688 - accuracy: 0.0076 - val_loss: 5.7076 - val_accuracy: 0.0082\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.8575 - accuracy: 0.0099 - val_loss: 5.6444 - val_accuracy: 0.0098\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6916 - accuracy: 0.0119 - val_loss: 5.4029 - val_accuracy: 0.0124\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5784 - accuracy: 0.0127 - val_loss: 5.3011 - val_accuracy: 0.0163\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4972 - accuracy: 0.0148 - val_loss: 5.2660 - val_accuracy: 0.0177\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4272 - accuracy: 0.0166 - val_loss: 5.2284 - val_accuracy: 0.0179\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3678 - accuracy: 0.0184 - val_loss: 5.2237 - val_accuracy: 0.0204\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2987 - accuracy: 0.0220 - val_loss: 5.2340 - val_accuracy: 0.0227\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.2392 - accuracy: 0.0251 - val_loss: 5.2405 - val_accuracy: 0.0229\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1878 - accuracy: 0.0287 - val_loss: 5.2313 - val_accuracy: 0.0247\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.1423 - accuracy: 0.0308 - val_loss: 5.2844 - val_accuracy: 0.0221\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1069 - accuracy: 0.0344 - val_loss: 5.3527 - val_accuracy: 0.0205\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0647 - accuracy: 0.0366 - val_loss: 5.3030 - val_accuracy: 0.0218\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0214 - accuracy: 0.0393 - val_loss: 5.4080 - val_accuracy: 0.0211\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9922 - accuracy: 0.0413 - val_loss: 5.3921 - val_accuracy: 0.0222\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9522 - accuracy: 0.0452 - val_loss: 5.4655 - val_accuracy: 0.0234\n",
      "Learning rate: 1e-05\n",
      " Batch size: 256\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_150 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_62 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_154 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_155 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_63 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_64 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.2734 - accuracy: 0.0055 - val_loss: 5.4758 - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.0792 - accuracy: 0.0060 - val_loss: 5.4909 - val_accuracy: 0.0066\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.8942 - accuracy: 0.0079 - val_loss: 5.4459 - val_accuracy: 0.0077\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.7560 - accuracy: 0.0093 - val_loss: 5.3684 - val_accuracy: 0.0103\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.6328 - accuracy: 0.0108 - val_loss: 5.2367 - val_accuracy: 0.0159\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.5255 - accuracy: 0.0137 - val_loss: 5.1611 - val_accuracy: 0.0206\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4604 - accuracy: 0.0155 - val_loss: 5.1185 - val_accuracy: 0.0265\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3917 - accuracy: 0.0191 - val_loss: 5.0560 - val_accuracy: 0.0308\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 5.3332 - accuracy: 0.0216 - val_loss: 5.0348 - val_accuracy: 0.0316\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.2926 - accuracy: 0.0232 - val_loss: 5.0028 - val_accuracy: 0.0357\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2477 - accuracy: 0.0256 - val_loss: 4.9590 - val_accuracy: 0.0388\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.2093 - accuracy: 0.0267 - val_loss: 4.9835 - val_accuracy: 0.0371\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.1687 - accuracy: 0.0297 - val_loss: 4.9789 - val_accuracy: 0.0380\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.1269 - accuracy: 0.0326 - val_loss: 4.9684 - val_accuracy: 0.0397\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.0818 - accuracy: 0.0351 - val_loss: 4.9898 - val_accuracy: 0.0369\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.0449 - accuracy: 0.0381 - val_loss: 5.0406 - val_accuracy: 0.0346\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0018 - accuracy: 0.0423 - val_loss: 5.0690 - val_accuracy: 0.0353\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9635 - accuracy: 0.0434 - val_loss: 5.2159 - val_accuracy: 0.0303\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.9271 - accuracy: 0.0475 - val_loss: 5.2449 - val_accuracy: 0.0283\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 4.8868 - accuracy: 0.0495 - val_loss: 5.2460 - val_accuracy: 0.0297\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8534 - accuracy: 0.0518 - val_loss: 5.4030 - val_accuracy: 0.0270\n",
      "Learning rate: 1e-05\n",
      " Batch size: 512\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_156 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_157 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_65 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_160 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_66 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_162 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_67 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_165 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_68 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_69 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.2667 - accuracy: 0.0057 - val_loss: 5.6146 - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0371 - accuracy: 0.0077 - val_loss: 5.8153 - val_accuracy: 0.0082\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.8088 - accuracy: 0.0101 - val_loss: 5.8885 - val_accuracy: 0.0103\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.6512 - accuracy: 0.0122 - val_loss: 5.6786 - val_accuracy: 0.0131\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5512 - accuracy: 0.0137 - val_loss: 5.4981 - val_accuracy: 0.0152\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4825 - accuracy: 0.0149 - val_loss: 5.4610 - val_accuracy: 0.0181\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4059 - accuracy: 0.0171 - val_loss: 5.5060 - val_accuracy: 0.0189\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3484 - accuracy: 0.0195 - val_loss: 5.3293 - val_accuracy: 0.0203\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3000 - accuracy: 0.0220 - val_loss: 5.2415 - val_accuracy: 0.0230\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2505 - accuracy: 0.0247 - val_loss: 5.3040 - val_accuracy: 0.0211\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2146 - accuracy: 0.0265 - val_loss: 5.2491 - val_accuracy: 0.0254\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1642 - accuracy: 0.0297 - val_loss: 5.3441 - val_accuracy: 0.0260\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.1262 - accuracy: 0.0326 - val_loss: 6.0250 - val_accuracy: 0.0204\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0818 - accuracy: 0.0345 - val_loss: 6.0483 - val_accuracy: 0.0196\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0354 - accuracy: 0.0382 - val_loss: 6.1555 - val_accuracy: 0.0189\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9972 - accuracy: 0.0411 - val_loss: 5.7951 - val_accuracy: 0.0205\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9624 - accuracy: 0.0427 - val_loss: 5.6872 - val_accuracy: 0.0213\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9342 - accuracy: 0.0450 - val_loss: 5.6490 - val_accuracy: 0.0201\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.8923 - accuracy: 0.0484 - val_loss: 5.4653 - val_accuracy: 0.0202\n",
      "Learning rate: 1e-05\n",
      " Batch size: 1024\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_172 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 6.2575 - accuracy: 0.0058 - val_loss: 5.6748 - val_accuracy: 0.0066\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0378 - accuracy: 0.0080 - val_loss: 5.6594 - val_accuracy: 0.0105\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.7886 - accuracy: 0.0108 - val_loss: 5.5784 - val_accuracy: 0.0137\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6357 - accuracy: 0.0118 - val_loss: 5.4533 - val_accuracy: 0.0138\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5328 - accuracy: 0.0134 - val_loss: 5.3637 - val_accuracy: 0.0167\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4640 - accuracy: 0.0148 - val_loss: 5.3506 - val_accuracy: 0.0166\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4046 - accuracy: 0.0174 - val_loss: 5.3725 - val_accuracy: 0.0161\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3499 - accuracy: 0.0187 - val_loss: 5.2769 - val_accuracy: 0.0179\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2874 - accuracy: 0.0222 - val_loss: 5.3093 - val_accuracy: 0.0188\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.2331 - accuracy: 0.0248 - val_loss: 5.3048 - val_accuracy: 0.0208\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1864 - accuracy: 0.0284 - val_loss: 5.3130 - val_accuracy: 0.0211\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1403 - accuracy: 0.0306 - val_loss: 5.4558 - val_accuracy: 0.0189\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.1004 - accuracy: 0.0331 - val_loss: 5.4141 - val_accuracy: 0.0188\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0537 - accuracy: 0.0370 - val_loss: 5.4314 - val_accuracy: 0.0185\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.0172 - accuracy: 0.0378 - val_loss: 5.4477 - val_accuracy: 0.0189\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9818 - accuracy: 0.0409 - val_loss: 5.4809 - val_accuracy: 0.0196\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9366 - accuracy: 0.0440 - val_loss: 5.5425 - val_accuracy: 0.0209\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 4.9119 - accuracy: 0.0469 - val_loss: 5.5591 - val_accuracy: 0.0207\n",
      "Learning rate: 1e-06\n",
      " Batch size: 64\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_180 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.3747 - accuracy: 0.0052 - val_loss: 5.5463 - val_accuracy: 0.0049\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.3522 - accuracy: 0.0051 - val_loss: 5.5316 - val_accuracy: 0.0050\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.3463 - accuracy: 0.0050 - val_loss: 5.5214 - val_accuracy: 0.0047\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.3169 - accuracy: 0.0048 - val_loss: 5.5196 - val_accuracy: 0.0052\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2981 - accuracy: 0.0056 - val_loss: 5.5231 - val_accuracy: 0.0050\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2829 - accuracy: 0.0052 - val_loss: 5.5323 - val_accuracy: 0.0058\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2686 - accuracy: 0.0061 - val_loss: 5.5387 - val_accuracy: 0.0063\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2382 - accuracy: 0.0063 - val_loss: 5.5405 - val_accuracy: 0.0058\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2209 - accuracy: 0.0062 - val_loss: 5.5539 - val_accuracy: 0.0069\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1984 - accuracy: 0.0059 - val_loss: 5.5780 - val_accuracy: 0.0061\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1773 - accuracy: 0.0067 - val_loss: 5.5989 - val_accuracy: 0.0061\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1527 - accuracy: 0.0067 - val_loss: 5.6057 - val_accuracy: 0.0063\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1456 - accuracy: 0.0066 - val_loss: 5.6228 - val_accuracy: 0.0070\n",
      "Learning rate: 1e-06\n",
      " Batch size: 128\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_80 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_197 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_81 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_198 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_199 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_200 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_82 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_201 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_202 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_203 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_83 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_84 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 35ms/step - loss: 6.3577 - accuracy: 0.0049 - val_loss: 5.5724 - val_accuracy: 0.0058\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3209 - accuracy: 0.0058 - val_loss: 5.5589 - val_accuracy: 0.0058\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2910 - accuracy: 0.0056 - val_loss: 5.5530 - val_accuracy: 0.0055\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2554 - accuracy: 0.0055 - val_loss: 5.5507 - val_accuracy: 0.0061\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2297 - accuracy: 0.0057 - val_loss: 5.5515 - val_accuracy: 0.0059\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.2061 - accuracy: 0.0058 - val_loss: 5.5450 - val_accuracy: 0.0069\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1701 - accuracy: 0.0068 - val_loss: 5.5551 - val_accuracy: 0.0066\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1478 - accuracy: 0.0061 - val_loss: 5.5316 - val_accuracy: 0.0071\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1081 - accuracy: 0.0065 - val_loss: 5.5356 - val_accuracy: 0.0064\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0796 - accuracy: 0.0073 - val_loss: 5.5320 - val_accuracy: 0.0071\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0500 - accuracy: 0.0075 - val_loss: 5.5297 - val_accuracy: 0.0071\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.0183 - accuracy: 0.0071 - val_loss: 5.5335 - val_accuracy: 0.0077\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.9950 - accuracy: 0.0074 - val_loss: 5.5146 - val_accuracy: 0.0077\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.9742 - accuracy: 0.0079 - val_loss: 5.5080 - val_accuracy: 0.0087\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.9441 - accuracy: 0.0087 - val_loss: 5.4946 - val_accuracy: 0.0093\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.9118 - accuracy: 0.0090 - val_loss: 5.4821 - val_accuracy: 0.0090\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.8882 - accuracy: 0.0086 - val_loss: 5.4670 - val_accuracy: 0.0089\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.8631 - accuracy: 0.0091 - val_loss: 5.4535 - val_accuracy: 0.0093\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.8310 - accuracy: 0.0097 - val_loss: 5.4420 - val_accuracy: 0.0100\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.8158 - accuracy: 0.0097 - val_loss: 5.4488 - val_accuracy: 0.0106\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.8002 - accuracy: 0.0099 - val_loss: 5.4576 - val_accuracy: 0.0098\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.7665 - accuracy: 0.0103 - val_loss: 5.4421 - val_accuracy: 0.0106\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.7543 - accuracy: 0.0099 - val_loss: 5.4559 - val_accuracy: 0.0111\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.7309 - accuracy: 0.0103 - val_loss: 5.4476 - val_accuracy: 0.0115\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.7075 - accuracy: 0.0109 - val_loss: 5.4452 - val_accuracy: 0.0113\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6969 - accuracy: 0.0107 - val_loss: 5.4146 - val_accuracy: 0.0118\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6858 - accuracy: 0.0106 - val_loss: 5.4130 - val_accuracy: 0.0121\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6611 - accuracy: 0.0115 - val_loss: 5.3802 - val_accuracy: 0.0126\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6482 - accuracy: 0.0126 - val_loss: 5.3767 - val_accuracy: 0.0127\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.6359 - accuracy: 0.0122 - val_loss: 5.3625 - val_accuracy: 0.0130\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6260 - accuracy: 0.0117 - val_loss: 5.3361 - val_accuracy: 0.0138\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6162 - accuracy: 0.0123 - val_loss: 5.3210 - val_accuracy: 0.0137\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.6020 - accuracy: 0.0134 - val_loss: 5.3156 - val_accuracy: 0.0142\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.5848 - accuracy: 0.0135 - val_loss: 5.2991 - val_accuracy: 0.0144\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.5782 - accuracy: 0.0134 - val_loss: 5.2835 - val_accuracy: 0.0148\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5693 - accuracy: 0.0130 - val_loss: 5.2783 - val_accuracy: 0.0158\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5521 - accuracy: 0.0136 - val_loss: 5.2609 - val_accuracy: 0.0154\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.5498 - accuracy: 0.0138 - val_loss: 5.2484 - val_accuracy: 0.0165\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5307 - accuracy: 0.0145 - val_loss: 5.2405 - val_accuracy: 0.0166\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.5257 - accuracy: 0.0147 - val_loss: 5.2249 - val_accuracy: 0.0176\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.5134 - accuracy: 0.0144 - val_loss: 5.2200 - val_accuracy: 0.0179\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.5035 - accuracy: 0.0160 - val_loss: 5.2122 - val_accuracy: 0.0188\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4977 - accuracy: 0.0155 - val_loss: 5.2054 - val_accuracy: 0.0187\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.4857 - accuracy: 0.0158 - val_loss: 5.1999 - val_accuracy: 0.0192\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4736 - accuracy: 0.0166 - val_loss: 5.1876 - val_accuracy: 0.0201\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.4713 - accuracy: 0.0165 - val_loss: 5.1737 - val_accuracy: 0.0207\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4602 - accuracy: 0.0169 - val_loss: 5.1757 - val_accuracy: 0.0203\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4522 - accuracy: 0.0172 - val_loss: 5.1724 - val_accuracy: 0.0212\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.4399 - accuracy: 0.0173 - val_loss: 5.1632 - val_accuracy: 0.0216\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4336 - accuracy: 0.0174 - val_loss: 5.1574 - val_accuracy: 0.0226\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.4281 - accuracy: 0.0180 - val_loss: 5.1527 - val_accuracy: 0.0230\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.4107 - accuracy: 0.0175 - val_loss: 5.1492 - val_accuracy: 0.0236\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.4043 - accuracy: 0.0194 - val_loss: 5.1424 - val_accuracy: 0.0236\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.3988 - accuracy: 0.0196 - val_loss: 5.1409 - val_accuracy: 0.0239\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3945 - accuracy: 0.0199 - val_loss: 5.1414 - val_accuracy: 0.0238\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3867 - accuracy: 0.0191 - val_loss: 5.1369 - val_accuracy: 0.0239\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.3799 - accuracy: 0.0212 - val_loss: 5.1280 - val_accuracy: 0.0251\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.3750 - accuracy: 0.0208 - val_loss: 5.1285 - val_accuracy: 0.0248\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.3651 - accuracy: 0.0203 - val_loss: 5.1236 - val_accuracy: 0.0261\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 5.3581 - accuracy: 0.0205 - val_loss: 5.1250 - val_accuracy: 0.0269\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3491 - accuracy: 0.0210 - val_loss: 5.1255 - val_accuracy: 0.0268\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3436 - accuracy: 0.0224 - val_loss: 5.1277 - val_accuracy: 0.0266\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3389 - accuracy: 0.0209 - val_loss: 5.1243 - val_accuracy: 0.0272\n",
      "Epoch 64/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3365 - accuracy: 0.0222 - val_loss: 5.1229 - val_accuracy: 0.0272\n",
      "Epoch 65/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3247 - accuracy: 0.0226 - val_loss: 5.1274 - val_accuracy: 0.0270\n",
      "Epoch 66/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 5.3201 - accuracy: 0.0235 - val_loss: 5.1309 - val_accuracy: 0.0269\n",
      "Epoch 67/200\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 5.3115 - accuracy: 0.0237 - val_loss: 5.1295 - val_accuracy: 0.0270\n",
      "Learning rate: 1e-06\n",
      " Batch size: 256\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_204 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_205 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_206 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_207 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_208 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_86 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_210 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_87 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_70 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_213 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_215 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_88 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_89 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.3573 - accuracy: 0.0047 - val_loss: 5.5654 - val_accuracy: 0.0048\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.3433 - accuracy: 0.0054 - val_loss: 5.5684 - val_accuracy: 0.0047\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3227 - accuracy: 0.0049 - val_loss: 5.5784 - val_accuracy: 0.0053\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2895 - accuracy: 0.0056 - val_loss: 5.5916 - val_accuracy: 0.0050\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2799 - accuracy: 0.0058 - val_loss: 5.6147 - val_accuracy: 0.0049\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2605 - accuracy: 0.0052 - val_loss: 5.6298 - val_accuracy: 0.0053\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2318 - accuracy: 0.0057 - val_loss: 5.6650 - val_accuracy: 0.0053\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2213 - accuracy: 0.0058 - val_loss: 5.6920 - val_accuracy: 0.0060\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2016 - accuracy: 0.0057 - val_loss: 5.7089 - val_accuracy: 0.0063\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1800 - accuracy: 0.0061 - val_loss: 5.7095 - val_accuracy: 0.0052\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 6.1576 - accuracy: 0.0066 - val_loss: 5.7703 - val_accuracy: 0.0058\n",
      "Learning rate: 1e-06\n",
      " Batch size: 512\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_216 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_90 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_91 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_222 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_223 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_92 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_225 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_226 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_227 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_93 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_94 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.3508 - accuracy: 0.0051 - val_loss: 5.5765 - val_accuracy: 0.0055\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3401 - accuracy: 0.0052 - val_loss: 5.5775 - val_accuracy: 0.0061\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3107 - accuracy: 0.0053 - val_loss: 5.5671 - val_accuracy: 0.0064\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2844 - accuracy: 0.0057 - val_loss: 5.5726 - val_accuracy: 0.0064\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2628 - accuracy: 0.0054 - val_loss: 5.5811 - val_accuracy: 0.0068\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 6.2397 - accuracy: 0.0058 - val_loss: 5.5976 - val_accuracy: 0.0069\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2170 - accuracy: 0.0060 - val_loss: 5.6228 - val_accuracy: 0.0068\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 6.1916 - accuracy: 0.0063 - val_loss: 5.6125 - val_accuracy: 0.0074\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1639 - accuracy: 0.0059 - val_loss: 5.6437 - val_accuracy: 0.0074\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 6.1585 - accuracy: 0.0064 - val_loss: 5.6504 - val_accuracy: 0.0067\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1404 - accuracy: 0.0058 - val_loss: 5.6597 - val_accuracy: 0.0068\n",
      "Learning rate: 1e-06\n",
      " Batch size: 1024\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_228 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_229 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_230 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_95 (Bat  (None, 64, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_231 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_234 (Conv2D)         (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_97 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_98 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " batch_normalization_99 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,059,272\n",
      "Trainable params: 3,057,800\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.3860 - accuracy: 0.0050 - val_loss: 5.5356 - val_accuracy: 0.0051\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3649 - accuracy: 0.0051 - val_loss: 5.5250 - val_accuracy: 0.0048\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3362 - accuracy: 0.0056 - val_loss: 5.5169 - val_accuracy: 0.0055\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.3134 - accuracy: 0.0057 - val_loss: 5.5124 - val_accuracy: 0.0055\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2938 - accuracy: 0.0051 - val_loss: 5.5097 - val_accuracy: 0.0057\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.2685 - accuracy: 0.0059 - val_loss: 5.5185 - val_accuracy: 0.0058\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 46s 36ms/step - loss: 6.2353 - accuracy: 0.0061 - val_loss: 5.5188 - val_accuracy: 0.0060\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 46s 37ms/step - loss: 6.2102 - accuracy: 0.0062 - val_loss: 5.5278 - val_accuracy: 0.0062\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1946 - accuracy: 0.0061 - val_loss: 5.5201 - val_accuracy: 0.0060\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1702 - accuracy: 0.0057 - val_loss: 5.5228 - val_accuracy: 0.0057\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1454 - accuracy: 0.0063 - val_loss: 5.5249 - val_accuracy: 0.0058\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.1218 - accuracy: 0.0062 - val_loss: 5.5241 - val_accuracy: 0.0059\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 6.0957 - accuracy: 0.0066 - val_loss: 5.5312 - val_accuracy: 0.0060\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 45s 35ms/step - loss: 6.0733 - accuracy: 0.0069 - val_loss: 5.5243 - val_accuracy: 0.0069\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "   \n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "    \n",
    "history_list_3 = []\n",
    "for lr in [0.001, 0.0001, 0.00001, 0.000001]:\n",
    "    for bs in [64,128,256,512,1024]:\n",
    "        print(f'Learning rate: {lr}\\n Batch size: {bs}')\n",
    "        conv_model = convolutional_model((64, 64, 3))\n",
    "        print(conv_model.summary())\n",
    "        \n",
    "        conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "        \n",
    "        history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=bs, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.01,\n",
    "                patience=10,\n",
    "                verbose=0,\n",
    "                mode='auto',\n",
    "                baseline=None,\n",
    "                restore_best_weights=False\n",
    "            )])\n",
    "        history_list_3.append({f'{lr} {bs}': history.history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991a6bea-36a8-499d-ab6f-5fb7bdb6356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 64 [('loss', 5.380972862243652), ('accuracy', 0.34437501430511475), ('val_loss', 4.998109340667725), ('val_accuracy', 0.25964999198913574)]\n",
      "0.001 128 [('loss', 5.398235321044922), ('accuracy', 0.303912490606308), ('val_loss', 5.336450576782227), ('val_accuracy', 0.2479500025510788)]\n",
      "0.001 256 [('loss', 5.41646671295166), ('accuracy', 0.29391250014305115), ('val_loss', 5.167325973510742), ('val_accuracy', 0.21199999749660492)]\n",
      "0.001 512 [('loss', 5.425540447235107), ('accuracy', 0.30959999561309814), ('val_loss', 5.104207992553711), ('val_accuracy', 0.21809999644756317)]\n",
      "0.001 1024 [('loss', 5.4175848960876465), ('accuracy', 0.32942500710487366), ('val_loss', 4.997028350830078), ('val_accuracy', 0.2505500018596649)]\n",
      "0.0001 64 [('loss', 5.6755571365356445), ('accuracy', 0.3063249886035919), ('val_loss', 5.555928707122803), ('val_accuracy', 0.19075000286102295)]\n",
      "0.0001 128 [('loss', 5.6521897315979), ('accuracy', 0.27627500891685486), ('val_loss', 5.529110431671143), ('val_accuracy', 0.17444999516010284)]\n",
      "0.0001 256 [('loss', 5.635287284851074), ('accuracy', 0.35756251215934753), ('val_loss', 6.245638847351074), ('val_accuracy', 0.2579500079154968)]\n",
      "0.0001 512 [('loss', 5.599355697631836), ('accuracy', 0.298675000667572), ('val_loss', 5.206149578094482), ('val_accuracy', 0.20035000145435333)]\n",
      "0.0001 1024 [('loss', 5.673172950744629), ('accuracy', 0.28968751430511475), ('val_loss', 5.279496669769287), ('val_accuracy', 0.18645000457763672)]\n",
      "1e-05 64 [('loss', 6.267604351043701), ('accuracy', 0.04036249965429306), ('val_loss', 5.626955032348633), ('val_accuracy', 0.02669999934732914)]\n",
      "1e-05 128 [('loss', 6.260848045349121), ('accuracy', 0.045249998569488525), ('val_loss', 5.707645416259766), ('val_accuracy', 0.02474999986588955)]\n",
      "1e-05 256 [('loss', 6.2733869552612305), ('accuracy', 0.05178749933838844), ('val_loss', 5.490946292877197), ('val_accuracy', 0.039650000631809235)]\n",
      "1e-05 512 [('loss', 6.266663074493408), ('accuracy', 0.0484125018119812), ('val_loss', 6.155496120452881), ('val_accuracy', 0.026000000536441803)]\n",
      "1e-05 1024 [('loss', 6.257532596588135), ('accuracy', 0.04691249877214432), ('val_loss', 5.674829006195068), ('val_accuracy', 0.021050000563263893)]\n",
      "1e-06 64 [('loss', 6.374655723571777), ('accuracy', 0.0067125000059604645), ('val_loss', 5.622829437255859), ('val_accuracy', 0.007000000216066837)]\n",
      "1e-06 128 [('loss', 6.357712745666504), ('accuracy', 0.02367500029504299), ('val_loss', 5.572366714477539), ('val_accuracy', 0.027249999344348907)]\n",
      "1e-06 256 [('loss', 6.357344150543213), ('accuracy', 0.006599999964237213), ('val_loss', 5.770325183868408), ('val_accuracy', 0.00634999992325902)]\n",
      "1e-06 512 [('loss', 6.350846767425537), ('accuracy', 0.006387500092387199), ('val_loss', 5.659717559814453), ('val_accuracy', 0.007400000002235174)]\n",
      "1e-06 1024 [('loss', 6.386002063751221), ('accuracy', 0.006887500174343586), ('val_loss', 5.535607814788818), ('val_accuracy', 0.006949999835342169)]\n"
     ]
    }
   ],
   "source": [
    "for log in history_list_3:\n",
    "    for setting, history in log.items():\n",
    "        print(setting, [(metric, max(values)) for metric, values in history.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10039725-774d-4da6-9845-9e4c20991233",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list_3 = [{'0.001 64': {'loss': [5.380972862243652,\n",
    "    4.88289213180542,\n",
    "    4.59045934677124,\n",
    "    4.402263641357422,\n",
    "    4.270577907562256,\n",
    "    4.161617755889893,\n",
    "    4.0691728591918945,\n",
    "    3.9810867309570312,\n",
    "    3.9025256633758545,\n",
    "    3.818938732147217,\n",
    "    3.753160238265991,\n",
    "    3.69100284576416,\n",
    "    3.631304979324341,\n",
    "    3.5823192596435547,\n",
    "    3.5368168354034424,\n",
    "    3.482234477996826,\n",
    "    3.4457242488861084,\n",
    "    3.398023843765259,\n",
    "    3.3656530380249023,\n",
    "    3.337454319000244,\n",
    "    3.3048651218414307,\n",
    "    3.274305820465088,\n",
    "    3.243847131729126,\n",
    "    3.2164480686187744,\n",
    "    3.194758892059326,\n",
    "    3.1663668155670166,\n",
    "    3.1440253257751465,\n",
    "    3.120410919189453,\n",
    "    3.1022531986236572,\n",
    "    3.084674835205078,\n",
    "    3.0618607997894287,\n",
    "    3.0420565605163574,\n",
    "    3.026094436645508,\n",
    "    3.013417959213257,\n",
    "    2.9940083026885986,\n",
    "    2.978736639022827,\n",
    "    2.962615489959717,\n",
    "    2.9524595737457275,\n",
    "    2.933278799057007,\n",
    "    2.921670913696289,\n",
    "    2.9037067890167236,\n",
    "    2.8881051540374756,\n",
    "    2.8793790340423584,\n",
    "    2.869946241378784,\n",
    "    2.8450393676757812,\n",
    "    2.84320330619812,\n",
    "    2.8290092945098877,\n",
    "    2.819101095199585,\n",
    "    2.8135299682617188,\n",
    "    2.800690174102783,\n",
    "    2.786313772201538],\n",
    "   'accuracy': [0.014050000347197056,\n",
    "    0.0356375016272068,\n",
    "    0.06199999898672104,\n",
    "    0.08322499692440033,\n",
    "    0.09948749840259552,\n",
    "    0.11368750035762787,\n",
    "    0.1269875019788742,\n",
    "    0.13932499289512634,\n",
    "    0.1509000062942505,\n",
    "    0.16362500190734863,\n",
    "    0.1735374927520752,\n",
    "    0.18277500569820404,\n",
    "    0.1933249980211258,\n",
    "    0.20071250200271606,\n",
    "    0.20909999310970306,\n",
    "    0.21722500026226044,\n",
    "    0.2225874960422516,\n",
    "    0.23074999451637268,\n",
    "    0.2375749945640564,\n",
    "    0.24185000360012054,\n",
    "    0.2462249994277954,\n",
    "    0.25485000014305115,\n",
    "    0.2577250003814697,\n",
    "    0.2642875015735626,\n",
    "    0.26643750071525574,\n",
    "    0.27227500081062317,\n",
    "    0.27668750286102295,\n",
    "    0.28107500076293945,\n",
    "    0.28417500853538513,\n",
    "    0.2877500057220459,\n",
    "    0.2925125062465668,\n",
    "    0.2947250008583069,\n",
    "    0.2974500060081482,\n",
    "    0.30018749833106995,\n",
    "    0.3014124929904938,\n",
    "    0.3070499897003174,\n",
    "    0.3094500005245209,\n",
    "    0.31363749504089355,\n",
    "    0.3161875009536743,\n",
    "    0.3155125081539154,\n",
    "    0.3220750093460083,\n",
    "    0.32276248931884766,\n",
    "    0.3248875141143799,\n",
    "    0.3268125057220459,\n",
    "    0.3328624963760376,\n",
    "    0.33003750443458557,\n",
    "    0.3340874910354614,\n",
    "    0.3365125060081482,\n",
    "    0.3371250033378601,\n",
    "    0.34007498621940613,\n",
    "    0.34437501430511475],\n",
    "   'val_loss': [4.998109340667725,\n",
    "    4.626512050628662,\n",
    "    4.685070514678955,\n",
    "    4.469832420349121,\n",
    "    4.603459358215332,\n",
    "    4.5693840980529785,\n",
    "    4.4600830078125,\n",
    "    4.491162300109863,\n",
    "    4.238203525543213,\n",
    "    4.522250175476074,\n",
    "    4.304540157318115,\n",
    "    3.955239772796631,\n",
    "    4.292548656463623,\n",
    "    4.220411777496338,\n",
    "    4.31406831741333,\n",
    "    3.7115683555603027,\n",
    "    4.092424392700195,\n",
    "    3.7309703826904297,\n",
    "    3.7967007160186768,\n",
    "    3.5147335529327393,\n",
    "    3.6226963996887207,\n",
    "    3.6616389751434326,\n",
    "    3.64664888381958,\n",
    "    3.688899517059326,\n",
    "    3.912198543548584,\n",
    "    3.57243013381958,\n",
    "    3.596893072128296,\n",
    "    3.970215320587158,\n",
    "    3.4958086013793945,\n",
    "    3.5953707695007324,\n",
    "    3.855001926422119,\n",
    "    3.9466819763183594,\n",
    "    3.749704599380493,\n",
    "    3.5355544090270996,\n",
    "    3.5787007808685303,\n",
    "    3.6151959896087646,\n",
    "    3.6805686950683594,\n",
    "    3.4542672634124756,\n",
    "    3.3811960220336914,\n",
    "    3.5760698318481445,\n",
    "    3.299720287322998,\n",
    "    3.5418739318847656,\n",
    "    3.4775071144104004,\n",
    "    3.746504783630371,\n",
    "    3.589543342590332,\n",
    "    3.327893018722534,\n",
    "    3.4535012245178223,\n",
    "    3.4636528491973877,\n",
    "    3.57951283454895,\n",
    "    3.524543285369873,\n",
    "    3.389202833175659],\n",
    "   'val_accuracy': [0.02604999952018261,\n",
    "    0.05974999815225601,\n",
    "    0.05764999985694885,\n",
    "    0.08015000075101852,\n",
    "    0.07705000042915344,\n",
    "    0.07840000092983246,\n",
    "    0.10189999639987946,\n",
    "    0.09489999711513519,\n",
    "    0.11954999715089798,\n",
    "    0.10814999788999557,\n",
    "    0.11980000138282776,\n",
    "    0.15360000729560852,\n",
    "    0.12620000541210175,\n",
    "    0.13529999554157257,\n",
    "    0.12964999675750732,\n",
    "    0.1902499943971634,\n",
    "    0.1449500024318695,\n",
    "    0.19345000386238098,\n",
    "    0.1785999983549118,\n",
    "    0.2198999971151352,\n",
    "    0.20100000500679016,\n",
    "    0.20080000162124634,\n",
    "    0.2054000049829483,\n",
    "    0.20489999651908875,\n",
    "    0.1720999926328659,\n",
    "    0.21389999985694885,\n",
    "    0.2134999930858612,\n",
    "    0.1679999977350235,\n",
    "    0.2301499992609024,\n",
    "    0.21539999544620514,\n",
    "    0.1890999972820282,\n",
    "    0.17704999446868896,\n",
    "    0.19840000569820404,\n",
    "    0.22210000455379486,\n",
    "    0.2138500064611435,\n",
    "    0.21490000188350677,\n",
    "    0.2101999968290329,\n",
    "    0.24199999868869781,\n",
    "    0.2479500025510788,\n",
    "    0.22235000133514404,\n",
    "    0.25964999198913574,\n",
    "    0.22095000743865967,\n",
    "    0.23389999568462372,\n",
    "    0.20595000684261322,\n",
    "    0.22769999504089355,\n",
    "    0.25769999623298645,\n",
    "    0.24365000426769257,\n",
    "    0.23855000734329224,\n",
    "    0.22939999401569366,\n",
    "    0.23614999651908875,\n",
    "    0.2468000054359436]}},\n",
    " {'0.001 128': {'loss': [5.398235321044922,\n",
    "    4.929057598114014,\n",
    "    4.665840148925781,\n",
    "    4.4579572677612305,\n",
    "    4.279703140258789,\n",
    "    4.1497368812561035,\n",
    "    4.040450572967529,\n",
    "    3.9445407390594482,\n",
    "    3.8555238246917725,\n",
    "    3.7789437770843506,\n",
    "    3.7030932903289795,\n",
    "    3.643432378768921,\n",
    "    3.5916762351989746,\n",
    "    3.5409820079803467,\n",
    "    3.4997975826263428,\n",
    "    3.456397771835327,\n",
    "    3.4179797172546387,\n",
    "    3.384612798690796,\n",
    "    3.3581230640411377,\n",
    "    3.325962543487549,\n",
    "    3.2980382442474365,\n",
    "    3.2698280811309814,\n",
    "    3.2454450130462646,\n",
    "    3.221140146255493,\n",
    "    3.209409475326538,\n",
    "    3.1760811805725098,\n",
    "    3.1604702472686768,\n",
    "    3.1363110542297363,\n",
    "    3.121663808822632,\n",
    "    3.1028053760528564,\n",
    "    3.0830276012420654,\n",
    "    3.0703465938568115,\n",
    "    3.054239273071289,\n",
    "    3.036747932434082,\n",
    "    3.0256943702697754,\n",
    "    2.999448776245117],\n",
    "   'accuracy': [0.013650000095367432,\n",
    "    0.035374999046325684,\n",
    "    0.05810000002384186,\n",
    "    0.07986249774694443,\n",
    "    0.10311249643564224,\n",
    "    0.12060000002384186,\n",
    "    0.1336749941110611,\n",
    "    0.14765000343322754,\n",
    "    0.15992499887943268,\n",
    "    0.17326250672340393,\n",
    "    0.1845874935388565,\n",
    "    0.19189999997615814,\n",
    "    0.20237499475479126,\n",
    "    0.21074999868869781,\n",
    "    0.21613749861717224,\n",
    "    0.22378750145435333,\n",
    "    0.2296375036239624,\n",
    "    0.23483750224113464,\n",
    "    0.23951250314712524,\n",
    "    0.24683749675750732,\n",
    "    0.24992500245571136,\n",
    "    0.2565250098705292,\n",
    "    0.26054999232292175,\n",
    "    0.26368749141693115,\n",
    "    0.26618748903274536,\n",
    "    0.27111250162124634,\n",
    "    0.27408748865127563,\n",
    "    0.28001248836517334,\n",
    "    0.283112496137619,\n",
    "    0.2867625057697296,\n",
    "    0.28923749923706055,\n",
    "    0.28975000977516174,\n",
    "    0.2943499982357025,\n",
    "    0.2967750132083893,\n",
    "    0.2968375086784363,\n",
    "    0.303912490606308],\n",
    "   'val_loss': [5.336450576782227,\n",
    "    5.185443878173828,\n",
    "    4.77726411819458,\n",
    "    4.383225917816162,\n",
    "    4.294454097747803,\n",
    "    4.185427188873291,\n",
    "    4.131650924682617,\n",
    "    4.0677924156188965,\n",
    "    3.7311596870422363,\n",
    "    3.9122190475463867,\n",
    "    3.7389543056488037,\n",
    "    3.5440473556518555,\n",
    "    3.7979061603546143,\n",
    "    3.6554551124572754,\n",
    "    3.7371511459350586,\n",
    "    3.8949050903320312,\n",
    "    3.744931936264038,\n",
    "    3.5023820400238037,\n",
    "    3.601569175720215,\n",
    "    3.7563929557800293,\n",
    "    3.559474229812622,\n",
    "    4.084846019744873,\n",
    "    3.6438913345336914,\n",
    "    3.562164783477783,\n",
    "    3.631662607192993,\n",
    "    3.364089012145996,\n",
    "    3.4835281372070312,\n",
    "    3.419027328491211,\n",
    "    3.5625598430633545,\n",
    "    3.6389360427856445,\n",
    "    3.3570010662078857,\n",
    "    3.3840508460998535,\n",
    "    3.603421449661255,\n",
    "    3.5824172496795654,\n",
    "    3.3887062072753906,\n",
    "    3.687533140182495],\n",
    "   'val_accuracy': [0.023649999871850014,\n",
    "    0.03739999979734421,\n",
    "    0.05339999869465828,\n",
    "    0.09560000151395798,\n",
    "    0.1006999984383583,\n",
    "    0.1177000030875206,\n",
    "    0.1262499988079071,\n",
    "    0.13725000619888306,\n",
    "    0.1821500062942505,\n",
    "    0.16304999589920044,\n",
    "    0.1834000051021576,\n",
    "    0.21130000054836273,\n",
    "    0.17509999871253967,\n",
    "    0.195250004529953,\n",
    "    0.187049999833107,\n",
    "    0.16854999959468842,\n",
    "    0.1890999972820282,\n",
    "    0.22040000557899475,\n",
    "    0.2101999968290329,\n",
    "    0.18719999492168427,\n",
    "    0.21205000579357147,\n",
    "    0.15925000607967377,\n",
    "    0.20284999907016754,\n",
    "    0.21185000240802765,\n",
    "    0.20479999482631683,\n",
    "    0.24025000631809235,\n",
    "    0.22759999334812164,\n",
    "    0.23559999465942383,\n",
    "    0.2184000015258789,\n",
    "    0.20469999313354492,\n",
    "    0.2479500025510788,\n",
    "    0.24089999496936798,\n",
    "    0.2167000025510788,\n",
    "    0.22059999406337738,\n",
    "    0.24410000443458557,\n",
    "    0.20915000140666962]}},\n",
    " {'0.001 256': {'loss': [5.41646671295166,\n",
    "    4.965508937835693,\n",
    "    4.681892395019531,\n",
    "    4.445862770080566,\n",
    "    4.280278205871582,\n",
    "    4.164406776428223,\n",
    "    4.070413589477539,\n",
    "    3.979759454727173,\n",
    "    3.9032516479492188,\n",
    "    3.8317174911499023,\n",
    "    3.7660350799560547,\n",
    "    3.6987922191619873,\n",
    "    3.640148162841797,\n",
    "    3.588186740875244,\n",
    "    3.545795202255249,\n",
    "    3.503152847290039,\n",
    "    3.4601101875305176,\n",
    "    3.416248321533203,\n",
    "    3.3857405185699463,\n",
    "    3.3523733615875244,\n",
    "    3.3214097023010254,\n",
    "    3.2915585041046143,\n",
    "    3.2643768787384033,\n",
    "    3.23797869682312,\n",
    "    3.213845729827881,\n",
    "    3.1892921924591064,\n",
    "    3.172537326812744,\n",
    "    3.1481356620788574,\n",
    "    3.1219472885131836,\n",
    "    3.1049628257751465,\n",
    "    3.0851800441741943,\n",
    "    3.0678939819335938],\n",
    "   'accuracy': [0.012199999764561653,\n",
    "    0.030637500807642937,\n",
    "    0.05511249974370003,\n",
    "    0.08034999668598175,\n",
    "    0.10257499665021896,\n",
    "    0.1174750030040741,\n",
    "    0.13042500615119934,\n",
    "    0.14362500607967377,\n",
    "    0.1529500037431717,\n",
    "    0.16382500529289246,\n",
    "    0.1728000044822693,\n",
    "    0.1844875067472458,\n",
    "    0.19212499260902405,\n",
    "    0.20257499814033508,\n",
    "    0.20698750019073486,\n",
    "    0.21318750083446503,\n",
    "    0.22338749468326569,\n",
    "    0.23016250133514404,\n",
    "    0.23276250064373016,\n",
    "    0.24070000648498535,\n",
    "    0.2459374964237213,\n",
    "    0.2526625096797943,\n",
    "    0.25731250643730164,\n",
    "    0.2614625096321106,\n",
    "    0.26676249504089355,\n",
    "    0.2705000042915344,\n",
    "    0.272350013256073,\n",
    "    0.2767125070095062,\n",
    "    0.28126248717308044,\n",
    "    0.2832624912261963,\n",
    "    0.28692498803138733,\n",
    "    0.29391250014305115],\n",
    "   'val_loss': [5.167325973510742,\n",
    "    4.861729621887207,\n",
    "    4.617612838745117,\n",
    "    4.744391918182373,\n",
    "    4.786172389984131,\n",
    "    4.465488910675049,\n",
    "    4.521059513092041,\n",
    "    4.220287322998047,\n",
    "    4.375972747802734,\n",
    "    4.5542707443237305,\n",
    "    3.968606948852539,\n",
    "    4.111158847808838,\n",
    "    4.059375762939453,\n",
    "    3.9070608615875244,\n",
    "    3.764113187789917,\n",
    "    4.350565433502197,\n",
    "    3.9265449047088623,\n",
    "    4.073580741882324,\n",
    "    3.8039441108703613,\n",
    "    3.923696517944336,\n",
    "    3.927260637283325,\n",
    "    3.621936798095703,\n",
    "    3.8098859786987305,\n",
    "    3.7892098426818848,\n",
    "    3.6890077590942383,\n",
    "    3.828418016433716,\n",
    "    3.634707450866699,\n",
    "    3.886996030807495,\n",
    "    3.674081325531006,\n",
    "    3.687849998474121,\n",
    "    3.6345415115356445,\n",
    "    3.89713978767395],\n",
    "   'val_accuracy': [0.021549999713897705,\n",
    "    0.04565000161528587,\n",
    "    0.06679999828338623,\n",
    "    0.06584999710321426,\n",
    "    0.0697999969124794,\n",
    "    0.0957999974489212,\n",
    "    0.09440000355243683,\n",
    "    0.12250000238418579,\n",
    "    0.11294999718666077,\n",
    "    0.10339999943971634,\n",
    "    0.15139999985694885,\n",
    "    0.1395999938249588,\n",
    "    0.14695000648498535,\n",
    "    0.16095000505447388,\n",
    "    0.1829500049352646,\n",
    "    0.1277499943971634,\n",
    "    0.16664999723434448,\n",
    "    0.15444999933242798,\n",
    "    0.17919999361038208,\n",
    "    0.16965000331401825,\n",
    "    0.18129999935626984,\n",
    "    0.20685000717639923,\n",
    "    0.1858000010251999,\n",
    "    0.18684999644756317,\n",
    "    0.2048500031232834,\n",
    "    0.1899999976158142,\n",
    "    0.20634999871253967,\n",
    "    0.1814499944448471,\n",
    "    0.21085000038146973,\n",
    "    0.20479999482631683,\n",
    "    0.21199999749660492,\n",
    "    0.17990000545978546]}},\n",
    " {'0.001 512': {'loss': [5.425540447235107,\n",
    "    4.972785472869873,\n",
    "    4.747498035430908,\n",
    "    4.5916595458984375,\n",
    "    4.42104434967041,\n",
    "    4.252651691436768,\n",
    "    4.142390251159668,\n",
    "    4.037528991699219,\n",
    "    3.951474905014038,\n",
    "    3.866628885269165,\n",
    "    3.7965164184570312,\n",
    "    3.734131336212158,\n",
    "    3.6655397415161133,\n",
    "    3.6112301349639893,\n",
    "    3.561716079711914,\n",
    "    3.5161664485931396,\n",
    "    3.472609043121338,\n",
    "    3.4430930614471436,\n",
    "    3.4037833213806152,\n",
    "    3.367410182952881,\n",
    "    3.3401925563812256,\n",
    "    3.307070732116699,\n",
    "    3.2812395095825195,\n",
    "    3.2633724212646484,\n",
    "    3.2378435134887695,\n",
    "    3.2084810733795166,\n",
    "    3.191025733947754,\n",
    "    3.167804479598999,\n",
    "    3.147981882095337,\n",
    "    3.1305294036865234,\n",
    "    3.1090545654296875,\n",
    "    3.092212200164795,\n",
    "    3.080221652984619,\n",
    "    3.061870813369751,\n",
    "    3.0446791648864746,\n",
    "    3.025101900100708,\n",
    "    3.0141050815582275,\n",
    "    2.997021198272705,\n",
    "    2.9907093048095703,\n",
    "    2.9698522090911865],\n",
    "   'accuracy': [0.012612500227987766,\n",
    "    0.028075000271201134,\n",
    "    0.047212500125169754,\n",
    "    0.06651250272989273,\n",
    "    0.08612500131130219,\n",
    "    0.10700000077486038,\n",
    "    0.12222500145435333,\n",
    "    0.1353124976158142,\n",
    "    0.14506250619888306,\n",
    "    0.15853750705718994,\n",
    "    0.16893750429153442,\n",
    "    0.17803749442100525,\n",
    "    0.18816250562667847,\n",
    "    0.19821250438690186,\n",
    "    0.20526249706745148,\n",
    "    0.2122499942779541,\n",
    "    0.22072499990463257,\n",
    "    0.2256374955177307,\n",
    "    0.23383750021457672,\n",
    "    0.23852500319480896,\n",
    "    0.2434999942779541,\n",
    "    0.24793750047683716,\n",
    "    0.25270000100135803,\n",
    "    0.2563624978065491,\n",
    "    0.26071250438690186,\n",
    "    0.26656249165534973,\n",
    "    0.26903748512268066,\n",
    "    0.273312509059906,\n",
    "    0.27576249837875366,\n",
    "    0.27605000138282776,\n",
    "    0.2820124924182892,\n",
    "    0.2860499918460846,\n",
    "    0.2892250120639801,\n",
    "    0.2916249930858612,\n",
    "    0.2951749861240387,\n",
    "    0.29813748598098755,\n",
    "    0.3014875054359436,\n",
    "    0.3044374883174896,\n",
    "    0.30541250109672546,\n",
    "    0.30959999561309814],\n",
    "   'val_loss': [5.104207992553711,\n",
    "    4.9171953201293945,\n",
    "    4.605762004852295,\n",
    "    4.560888767242432,\n",
    "    4.385295867919922,\n",
    "    4.4329118728637695,\n",
    "    4.401804447174072,\n",
    "    4.1764631271362305,\n",
    "    4.1465277671813965,\n",
    "    4.135563850402832,\n",
    "    4.088298320770264,\n",
    "    4.12937593460083,\n",
    "    4.020236492156982,\n",
    "    3.9311118125915527,\n",
    "    3.8753793239593506,\n",
    "    3.911860466003418,\n",
    "    3.882169485092163,\n",
    "    3.6205499172210693,\n",
    "    3.7780096530914307,\n",
    "    4.190998554229736,\n",
    "    3.8558743000030518,\n",
    "    3.7247543334960938,\n",
    "    3.839735507965088,\n",
    "    3.969674587249756,\n",
    "    3.9030725955963135,\n",
    "    3.586792469024658,\n",
    "    3.6394999027252197,\n",
    "    4.1039605140686035,\n",
    "    3.8206582069396973,\n",
    "    3.5762953758239746,\n",
    "    3.861940622329712,\n",
    "    4.071001052856445,\n",
    "    3.7340426445007324,\n",
    "    3.964594841003418,\n",
    "    3.797785520553589,\n",
    "    3.645781993865967,\n",
    "    3.8786609172821045,\n",
    "    3.9132590293884277,\n",
    "    3.825976610183716,\n",
    "    3.9830949306488037],\n",
    "   'val_accuracy': [0.021700000390410423,\n",
    "    0.03465000167489052,\n",
    "    0.06735000014305115,\n",
    "    0.07164999842643738,\n",
    "    0.09849999845027924,\n",
    "    0.09719999879598618,\n",
    "    0.10540000349283218,\n",
    "    0.12635000050067902,\n",
    "    0.1298000067472458,\n",
    "    0.13324999809265137,\n",
    "    0.13660000264644623,\n",
    "    0.13740000128746033,\n",
    "    0.15000000596046448,\n",
    "    0.16214999556541443,\n",
    "    0.16619999706745148,\n",
    "    0.16664999723434448,\n",
    "    0.1664000004529953,\n",
    "    0.19869999587535858,\n",
    "    0.18639999628067017,\n",
    "    0.14374999701976776,\n",
    "    0.17685000598430634,\n",
    "    0.19404999911785126,\n",
    "    0.1764499992132187,\n",
    "    0.16824999451637268,\n",
    "    0.18019999563694,\n",
    "    0.21615000069141388,\n",
    "    0.20765000581741333,\n",
    "    0.16175000369548798,\n",
    "    0.18539999425411224,\n",
    "    0.21809999644756317,\n",
    "    0.18559999763965607,\n",
    "    0.16455000638961792,\n",
    "    0.1972000002861023,\n",
    "    0.18410000205039978,\n",
    "    0.18764999508857727,\n",
    "    0.21699999272823334,\n",
    "    0.18925000727176666,\n",
    "    0.18205000460147858,\n",
    "    0.19505000114440918,\n",
    "    0.17925000190734863]}},\n",
    " {'0.001 1024': {'loss': [5.4175848960876465,\n",
    "    4.965285778045654,\n",
    "    4.7500176429748535,\n",
    "    4.573967456817627,\n",
    "    4.371896266937256,\n",
    "    4.233785152435303,\n",
    "    4.13319206237793,\n",
    "    4.038333415985107,\n",
    "    3.9549448490142822,\n",
    "    3.8773012161254883,\n",
    "    3.8130812644958496,\n",
    "    3.7536051273345947,\n",
    "    3.690673828125,\n",
    "    3.6381359100341797,\n",
    "    3.5863616466522217,\n",
    "    3.5468008518218994,\n",
    "    3.5069851875305176,\n",
    "    3.4628617763519287,\n",
    "    3.423189401626587,\n",
    "    3.3934688568115234,\n",
    "    3.359309673309326,\n",
    "    3.326706647872925,\n",
    "    3.295933485031128,\n",
    "    3.2754404544830322,\n",
    "    3.249460458755493,\n",
    "    3.2246854305267334,\n",
    "    3.2024621963500977,\n",
    "    3.1792452335357666,\n",
    "    3.157184362411499,\n",
    "    3.1373322010040283,\n",
    "    3.115111827850342,\n",
    "    3.104977607727051,\n",
    "    3.077868938446045,\n",
    "    3.0615055561065674,\n",
    "    3.045233726501465,\n",
    "    3.025437593460083,\n",
    "    3.0141243934631348,\n",
    "    2.9999120235443115,\n",
    "    2.988591432571411,\n",
    "    2.97119402885437,\n",
    "    2.9606311321258545,\n",
    "    2.9425368309020996,\n",
    "    2.929497480392456,\n",
    "    2.9173474311828613,\n",
    "    2.9076476097106934,\n",
    "    2.8913228511810303,\n",
    "    2.883925199508667,\n",
    "    2.8723132610321045,\n",
    "    2.857321262359619],\n",
    "   'accuracy': [0.011887500062584877,\n",
    "    0.02968749962747097,\n",
    "    0.048112500458955765,\n",
    "    0.06724999845027924,\n",
    "    0.09184999763965607,\n",
    "    0.10696250200271606,\n",
    "    0.12177500128746033,\n",
    "    0.13394999504089355,\n",
    "    0.14591249823570251,\n",
    "    0.15672500431537628,\n",
    "    0.16584999859333038,\n",
    "    0.17317500710487366,\n",
    "    0.1858375072479248,\n",
    "    0.1938374936580658,\n",
    "    0.20194999873638153,\n",
    "    0.20971250534057617,\n",
    "    0.21559999883174896,\n",
    "    0.22175000607967377,\n",
    "    0.2280375063419342,\n",
    "    0.2356874942779541,\n",
    "    0.23951250314712524,\n",
    "    0.24504999816417694,\n",
    "    0.24921250343322754,\n",
    "    0.25373750925064087,\n",
    "    0.25942501425743103,\n",
    "    0.26202499866485596,\n",
    "    0.2661125063896179,\n",
    "    0.27201250195503235,\n",
    "    0.27639999985694885,\n",
    "    0.2786000072956085,\n",
    "    0.28380000591278076,\n",
    "    0.28511250019073486,\n",
    "    0.2891624867916107,\n",
    "    0.2902125120162964,\n",
    "    0.2942875027656555,\n",
    "    0.2986375093460083,\n",
    "    0.30149999260902405,\n",
    "    0.30344998836517334,\n",
    "    0.30576249957084656,\n",
    "    0.3084374964237213,\n",
    "    0.31126248836517334,\n",
    "    0.3146499991416931,\n",
    "    0.31683748960494995,\n",
    "    0.31898748874664307,\n",
    "    0.32077500224113464,\n",
    "    0.32276248931884766,\n",
    "    0.32374998927116394,\n",
    "    0.32788750529289246,\n",
    "    0.32942500710487366],\n",
    "   'val_loss': [4.997028350830078,\n",
    "    4.809463024139404,\n",
    "    4.646267414093018,\n",
    "    4.513217926025391,\n",
    "    4.249942779541016,\n",
    "    4.532133102416992,\n",
    "    4.366448879241943,\n",
    "    4.6031012535095215,\n",
    "    4.145541667938232,\n",
    "    4.047222137451172,\n",
    "    3.7811856269836426,\n",
    "    3.975999593734741,\n",
    "    4.023699760437012,\n",
    "    4.22852087020874,\n",
    "    3.853475332260132,\n",
    "    3.855295419692993,\n",
    "    3.719769239425659,\n",
    "    3.838487386703491,\n",
    "    3.7486038208007812,\n",
    "    4.127103328704834,\n",
    "    3.804311752319336,\n",
    "    3.852501630783081,\n",
    "    3.701923131942749,\n",
    "    3.6806910037994385,\n",
    "    3.6834464073181152,\n",
    "    3.974796772003174,\n",
    "    3.7511661052703857,\n",
    "    3.6554758548736572,\n",
    "    3.516702651977539,\n",
    "    3.864788770675659,\n",
    "    3.4832234382629395,\n",
    "    3.89087176322937,\n",
    "    3.64274263381958,\n",
    "    3.65311336517334,\n",
    "    3.6276304721832275,\n",
    "    3.678154230117798,\n",
    "    3.684835910797119,\n",
    "    3.616126537322998,\n",
    "    3.3634612560272217,\n",
    "    3.4490511417388916,\n",
    "    3.712157726287842,\n",
    "    3.754551649093628,\n",
    "    3.4329581260681152,\n",
    "    3.619537115097046,\n",
    "    3.4735429286956787,\n",
    "    3.795548439025879,\n",
    "    3.7407116889953613,\n",
    "    3.5187971591949463,\n",
    "    3.3811299800872803],\n",
    "   'val_accuracy': [0.030150000005960464,\n",
    "    0.045049998909235,\n",
    "    0.06509999930858612,\n",
    "    0.07989999651908875,\n",
    "    0.10980000346899033,\n",
    "    0.0917000025510788,\n",
    "    0.1014999970793724,\n",
    "    0.0872500017285347,\n",
    "    0.1269499957561493,\n",
    "    0.13950000703334808,\n",
    "    0.17180000245571136,\n",
    "    0.15029999613761902,\n",
    "    0.14480000734329224,\n",
    "    0.12794999778270721,\n",
    "    0.16335000097751617,\n",
    "    0.16384999454021454,\n",
    "    0.18799999356269836,\n",
    "    0.17634999752044678,\n",
    "    0.18725000321865082,\n",
    "    0.14444999396800995,\n",
    "    0.17865000665187836,\n",
    "    0.17579999566078186,\n",
    "    0.1941000074148178,\n",
    "    0.1967500001192093,\n",
    "    0.19814999401569366,\n",
    "    0.17204999923706055,\n",
    "    0.19300000369548798,\n",
    "    0.2053000032901764,\n",
    "    0.22014999389648438,\n",
    "    0.18529999256134033,\n",
    "    0.23229999840259552,\n",
    "    0.18170000612735748,\n",
    "    0.20960000157356262,\n",
    "    0.2113499939441681,\n",
    "    0.21344999969005585,\n",
    "    0.2134000062942505,\n",
    "    0.20200000703334808,\n",
    "    0.21915000677108765,\n",
    "    0.2505500018596649,\n",
    "    0.23964999616146088,\n",
    "    0.2069000005722046,\n",
    "    0.19939999282360077,\n",
    "    0.24390000104904175,\n",
    "    0.2214999943971634,\n",
    "    0.24060000479221344,\n",
    "    0.2037999927997589,\n",
    "    0.20569999516010284,\n",
    "    0.2345000058412552,\n",
    "    0.25049999356269836]}},\n",
    " {'0.0001 64': {'loss': [5.6755571365356445,\n",
    "    5.2651801109313965,\n",
    "    5.024635314941406,\n",
    "    4.8296380043029785,\n",
    "    4.645527362823486,\n",
    "    4.494906425476074,\n",
    "    4.372969627380371,\n",
    "    4.251951217651367,\n",
    "    4.1576151847839355,\n",
    "    4.0735883712768555,\n",
    "    3.993648052215576,\n",
    "    3.917069911956787,\n",
    "    3.8664674758911133,\n",
    "    3.8050196170806885,\n",
    "    3.7532925605773926,\n",
    "    3.7018120288848877,\n",
    "    3.656303882598877,\n",
    "    3.6209840774536133,\n",
    "    3.5795187950134277,\n",
    "    3.5299227237701416,\n",
    "    3.4985604286193848,\n",
    "    3.468120813369751,\n",
    "    3.4218266010284424,\n",
    "    3.397037982940674,\n",
    "    3.367960214614868,\n",
    "    3.338864803314209,\n",
    "    3.308605194091797,\n",
    "    3.284505844116211,\n",
    "    3.2590014934539795,\n",
    "    3.2342846393585205,\n",
    "    3.2097599506378174,\n",
    "    3.1895458698272705,\n",
    "    3.1672401428222656,\n",
    "    3.145247459411621,\n",
    "    3.123673439025879,\n",
    "    3.1046605110168457,\n",
    "    3.0885348320007324,\n",
    "    3.071380376815796,\n",
    "    3.04931902885437,\n",
    "    3.0347132682800293,\n",
    "    3.0198097229003906,\n",
    "    3.004102945327759],\n",
    "   'accuracy': [0.010824999772012234,\n",
    "    0.022462500259280205,\n",
    "    0.03421249985694885,\n",
    "    0.05034999921917915,\n",
    "    0.06511250138282776,\n",
    "    0.08043749630451202,\n",
    "    0.09438750147819519,\n",
    "    0.10757499933242798,\n",
    "    0.12018749862909317,\n",
    "    0.13407500088214874,\n",
    "    0.14281250536441803,\n",
    "    0.15324999392032623,\n",
    "    0.16118749976158142,\n",
    "    0.17135000228881836,\n",
    "    0.17848749458789825,\n",
    "    0.18643750250339508,\n",
    "    0.19203749299049377,\n",
    "    0.1992875039577484,\n",
    "    0.2054000049829483,\n",
    "    0.2126999944448471,\n",
    "    0.21906250715255737,\n",
    "    0.22317500412464142,\n",
    "    0.23223750293254852,\n",
    "    0.234375,\n",
    "    0.24086250364780426,\n",
    "    0.24638749659061432,\n",
    "    0.2524000108242035,\n",
    "    0.2548624873161316,\n",
    "    0.259737491607666,\n",
    "    0.2637999951839447,\n",
    "    0.26641249656677246,\n",
    "    0.27131250500679016,\n",
    "    0.27623748779296875,\n",
    "    0.27978751063346863,\n",
    "    0.28347501158714294,\n",
    "    0.28654998540878296,\n",
    "    0.2879999876022339,\n",
    "    0.29155001044273376,\n",
    "    0.29676249623298645,\n",
    "    0.30147498846054077,\n",
    "    0.3025999963283539,\n",
    "    0.3063249886035919],\n",
    "   'val_loss': [5.424478054046631,\n",
    "    5.115505695343018,\n",
    "    5.1067795753479,\n",
    "    5.555928707122803,\n",
    "    5.489780902862549,\n",
    "    5.5496416091918945,\n",
    "    5.074118137359619,\n",
    "    4.880539894104004,\n",
    "    4.663767337799072,\n",
    "    4.342531681060791,\n",
    "    4.615381240844727,\n",
    "    4.551671028137207,\n",
    "    4.238384246826172,\n",
    "    4.503440856933594,\n",
    "    4.26278829574585,\n",
    "    4.18805456161499,\n",
    "    4.3090338706970215,\n",
    "    4.238126754760742,\n",
    "    3.9927196502685547,\n",
    "    4.233205795288086,\n",
    "    4.063185691833496,\n",
    "    4.007913112640381,\n",
    "    4.167824745178223,\n",
    "    4.217369556427002,\n",
    "    4.107588291168213,\n",
    "    3.8877949714660645,\n",
    "    4.180495738983154,\n",
    "    3.8142757415771484,\n",
    "    4.096854209899902,\n",
    "    3.9780008792877197,\n",
    "    4.079400539398193,\n",
    "    3.7510159015655518,\n",
    "    3.990731716156006,\n",
    "    3.94224214553833,\n",
    "    3.8512632846832275,\n",
    "    3.8651280403137207,\n",
    "    3.8574628829956055,\n",
    "    4.080048084259033,\n",
    "    3.895232915878296,\n",
    "    3.764482021331787,\n",
    "    3.9898996353149414,\n",
    "    3.9140090942382812],\n",
    "   'val_accuracy': [0.01209999993443489,\n",
    "    0.024000000208616257,\n",
    "    0.032600000500679016,\n",
    "    0.0239499993622303,\n",
    "    0.029500000178813934,\n",
    "    0.03020000085234642,\n",
    "    0.04114999994635582,\n",
    "    0.059450000524520874,\n",
    "    0.07479999959468842,\n",
    "    0.10170000046491623,\n",
    "    0.07944999635219574,\n",
    "    0.08720000088214874,\n",
    "    0.11535000056028366,\n",
    "    0.09404999762773514,\n",
    "    0.11105000227689743,\n",
    "    0.11969999969005585,\n",
    "    0.10954999923706055,\n",
    "    0.12304999679327011,\n",
    "    0.14640000462532043,\n",
    "    0.11905000358819962,\n",
    "    0.1424500048160553,\n",
    "    0.14914999902248383,\n",
    "    0.13300000131130219,\n",
    "    0.1256999969482422,\n",
    "    0.14135000109672546,\n",
    "    0.16474999487400055,\n",
    "    0.13300000131130219,\n",
    "    0.1766500025987625,\n",
    "    0.14169999957084656,\n",
    "    0.15995000302791595,\n",
    "    0.14740000665187836,\n",
    "    0.187950000166893,\n",
    "    0.16075000166893005,\n",
    "    0.16130000352859497,\n",
    "    0.17685000598430634,\n",
    "    0.1736000031232834,\n",
    "    0.17845000326633453,\n",
    "    0.155349999666214,\n",
    "    0.18039999902248383,\n",
    "    0.19075000286102295,\n",
    "    0.16654999554157257,\n",
    "    0.18539999425411224]}},\n",
    " {'0.0001 128': {'loss': [5.6521897315979,\n",
    "    5.253465175628662,\n",
    "    5.033880233764648,\n",
    "    4.823861122131348,\n",
    "    4.648655891418457,\n",
    "    4.502961158752441,\n",
    "    4.37501859664917,\n",
    "    4.258752346038818,\n",
    "    4.167827129364014,\n",
    "    4.085801124572754,\n",
    "    4.00006103515625,\n",
    "    3.9345703125,\n",
    "    3.861755847930908,\n",
    "    3.812703847885132,\n",
    "    3.7539148330688477,\n",
    "    3.709221601486206,\n",
    "    3.6577417850494385,\n",
    "    3.6140847206115723,\n",
    "    3.571835994720459,\n",
    "    3.53460693359375,\n",
    "    3.497523784637451,\n",
    "    3.4623327255249023,\n",
    "    3.4122092723846436,\n",
    "    3.3942949771881104,\n",
    "    3.360109806060791,\n",
    "    3.327932834625244,\n",
    "    3.3026926517486572,\n",
    "    3.2809882164001465,\n",
    "    3.2527267932891846,\n",
    "    3.2260992527008057,\n",
    "    3.2066304683685303,\n",
    "    3.181710958480835,\n",
    "    3.1636369228363037],\n",
    "   'accuracy': [0.011412500403821468,\n",
    "    0.021774999797344208,\n",
    "    0.03564999997615814,\n",
    "    0.050187498331069946,\n",
    "    0.06424999982118607,\n",
    "    0.0794999971985817,\n",
    "    0.09324999898672104,\n",
    "    0.10679999738931656,\n",
    "    0.11906249821186066,\n",
    "    0.1308249980211258,\n",
    "    0.1429625004529953,\n",
    "    0.15171250700950623,\n",
    "    0.16380000114440918,\n",
    "    0.16865000128746033,\n",
    "    0.17848749458789825,\n",
    "    0.18656249344348907,\n",
    "    0.1941000074148178,\n",
    "    0.20055000483989716,\n",
    "    0.20527499914169312,\n",
    "    0.2136625051498413,\n",
    "    0.21826249361038208,\n",
    "    0.22552500665187836,\n",
    "    0.23325000703334808,\n",
    "    0.23759999871253967,\n",
    "    0.24102500081062317,\n",
    "    0.24808749556541443,\n",
    "    0.2515375018119812,\n",
    "    0.2540374994277954,\n",
    "    0.259737491607666,\n",
    "    0.2637374997138977,\n",
    "    0.26762500405311584,\n",
    "    0.2728624939918518,\n",
    "    0.27627500891685486],\n",
    "   'val_loss': [5.411470890045166,\n",
    "    5.250885963439941,\n",
    "    5.529110431671143,\n",
    "    5.404518127441406,\n",
    "    5.241802215576172,\n",
    "    4.9073686599731445,\n",
    "    5.056259632110596,\n",
    "    4.911518573760986,\n",
    "    5.023073673248291,\n",
    "    4.631990909576416,\n",
    "    4.806445598602295,\n",
    "    4.501296520233154,\n",
    "    4.346408367156982,\n",
    "    4.452198505401611,\n",
    "    4.384766101837158,\n",
    "    4.161999702453613,\n",
    "    4.16569185256958,\n",
    "    4.196908950805664,\n",
    "    4.3013505935668945,\n",
    "    4.092235565185547,\n",
    "    4.109773635864258,\n",
    "    4.277789115905762,\n",
    "    3.830918073654175,\n",
    "    3.937544822692871,\n",
    "    4.067415714263916,\n",
    "    4.035284042358398,\n",
    "    3.8364856243133545,\n",
    "    4.038198947906494,\n",
    "    3.9795258045196533,\n",
    "    3.88439679145813,\n",
    "    3.8586463928222656,\n",
    "    4.059926986694336,\n",
    "    4.027804851531982],\n",
    "   'val_accuracy': [0.012400000356137753,\n",
    "    0.02215000055730343,\n",
    "    0.01850000023841858,\n",
    "    0.03674999997019768,\n",
    "    0.037300001829862595,\n",
    "    0.05525000020861626,\n",
    "    0.05745000019669533,\n",
    "    0.056699998676776886,\n",
    "    0.058150000870227814,\n",
    "    0.08560000360012054,\n",
    "    0.07005000114440918,\n",
    "    0.09179999679327011,\n",
    "    0.11100000143051147,\n",
    "    0.09759999811649323,\n",
    "    0.10970000177621841,\n",
    "    0.12729999423027039,\n",
    "    0.1285499930381775,\n",
    "    0.12514999508857727,\n",
    "    0.11945000290870667,\n",
    "    0.14055000245571136,\n",
    "    0.13555000722408295,\n",
    "    0.11635000258684158,\n",
    "    0.17090000212192535,\n",
    "    0.1550000011920929,\n",
    "    0.14970000088214874,\n",
    "    0.147599995136261,\n",
    "    0.1737000048160553,\n",
    "    0.15125000476837158,\n",
    "    0.15680000185966492,\n",
    "    0.17155000567436218,\n",
    "    0.17444999516010284,\n",
    "    0.15729999542236328,\n",
    "    0.1555500030517578]}},\n",
    " {'0.0001 256': {'loss': [5.635287284851074,\n",
    "    5.23573112487793,\n",
    "    5.026516437530518,\n",
    "    4.827541828155518,\n",
    "    4.658937454223633,\n",
    "    4.521057605743408,\n",
    "    4.391213893890381,\n",
    "    4.274911403656006,\n",
    "    4.184296607971191,\n",
    "    4.097282409667969,\n",
    "    4.0216193199157715,\n",
    "    3.9508860111236572,\n",
    "    3.887836217880249,\n",
    "    3.8293561935424805,\n",
    "    3.7815821170806885,\n",
    "    3.726233959197998,\n",
    "    3.676273822784424,\n",
    "    3.6326887607574463,\n",
    "    3.5907082557678223,\n",
    "    3.5490801334381104,\n",
    "    3.5118660926818848,\n",
    "    3.476710557937622,\n",
    "    3.442990303039551,\n",
    "    3.4068446159362793,\n",
    "    3.3730928897857666,\n",
    "    3.3571019172668457,\n",
    "    3.325476884841919,\n",
    "    3.3001413345336914,\n",
    "    3.2740581035614014,\n",
    "    3.244558334350586,\n",
    "    3.2202296257019043,\n",
    "    3.201946973800659,\n",
    "    3.1838512420654297,\n",
    "    3.161637783050537,\n",
    "    3.1441078186035156,\n",
    "    3.126201629638672,\n",
    "    3.1077053546905518,\n",
    "    3.091050148010254,\n",
    "    3.073134660720825,\n",
    "    3.0564937591552734,\n",
    "    3.0459630489349365,\n",
    "    3.0179214477539062,\n",
    "    3.0129051208496094,\n",
    "    2.9994215965270996,\n",
    "    2.985323905944824,\n",
    "    2.9677135944366455,\n",
    "    2.9573278427124023,\n",
    "    2.9444737434387207,\n",
    "    2.9335110187530518,\n",
    "    2.923152446746826,\n",
    "    2.9093635082244873,\n",
    "    2.894211530685425,\n",
    "    2.8823437690734863,\n",
    "    2.868797540664673,\n",
    "    2.858016014099121,\n",
    "    2.845028877258301,\n",
    "    2.8386197090148926,\n",
    "    2.829180955886841,\n",
    "    2.825305938720703,\n",
    "    2.8137190341949463,\n",
    "    2.8031973838806152,\n",
    "    2.793246030807495,\n",
    "    2.7875375747680664,\n",
    "    2.771512269973755,\n",
    "    2.7607104778289795,\n",
    "    2.7514822483062744,\n",
    "    2.744201421737671,\n",
    "    2.731503486633301,\n",
    "    2.7236106395721436],\n",
    "   'accuracy': [0.010987499728798866,\n",
    "    0.021800000220537186,\n",
    "    0.03312499821186066,\n",
    "    0.0489250011742115,\n",
    "    0.06433749943971634,\n",
    "    0.07641249895095825,\n",
    "    0.09206250309944153,\n",
    "    0.10558749735355377,\n",
    "    0.1168999969959259,\n",
    "    0.12748749554157257,\n",
    "    0.1393750011920929,\n",
    "    0.1482750028371811,\n",
    "    0.1581375002861023,\n",
    "    0.16682499647140503,\n",
    "    0.17321249842643738,\n",
    "    0.18129999935626984,\n",
    "    0.1895499974489212,\n",
    "    0.19562500715255737,\n",
    "    0.20288750529289246,\n",
    "    0.2090124934911728,\n",
    "    0.21629999577999115,\n",
    "    0.2230374962091446,\n",
    "    0.22813749313354492,\n",
    "    0.23377500474452972,\n",
    "    0.23729999363422394,\n",
    "    0.24186250567436218,\n",
    "    0.2475624978542328,\n",
    "    0.24951249361038208,\n",
    "    0.2574000060558319,\n",
    "    0.2608124911785126,\n",
    "    0.26614999771118164,\n",
    "    0.26816248893737793,\n",
    "    0.2729249894618988,\n",
    "    0.27617499232292175,\n",
    "    0.28216248750686646,\n",
    "    0.2842000126838684,\n",
    "    0.2878875136375427,\n",
    "    0.2885875105857849,\n",
    "    0.2923625111579895,\n",
    "    0.2961125075817108,\n",
    "    0.2975125014781952,\n",
    "    0.3029249906539917,\n",
    "    0.30320000648498535,\n",
    "    0.305400013923645,\n",
    "    0.3100000023841858,\n",
    "    0.31183749437332153,\n",
    "    0.3125250041484833,\n",
    "    0.318325012922287,\n",
    "    0.31804999709129333,\n",
    "    0.31987500190734863,\n",
    "    0.32269999384880066,\n",
    "    0.3277375102043152,\n",
    "    0.32785001397132874,\n",
    "    0.33153748512268066,\n",
    "    0.33219999074935913,\n",
    "    0.335037499666214,\n",
    "    0.33533748984336853,\n",
    "    0.33845001459121704,\n",
    "    0.3405500054359436,\n",
    "    0.3416000008583069,\n",
    "    0.34521248936653137,\n",
    "    0.34318751096725464,\n",
    "    0.3447374999523163,\n",
    "    0.34796249866485596,\n",
    "    0.35333749651908875,\n",
    "    0.3543500006198883,\n",
    "    0.35507500171661377,\n",
    "    0.35583749413490295,\n",
    "    0.35756251215934753],\n",
    "   'val_loss': [5.59302282333374,\n",
    "    6.245638847351074,\n",
    "    5.364558219909668,\n",
    "    5.593954086303711,\n",
    "    5.2952351570129395,\n",
    "    4.616180896759033,\n",
    "    4.917805194854736,\n",
    "    4.8339128494262695,\n",
    "    4.480705261230469,\n",
    "    4.53255558013916,\n",
    "    4.466858386993408,\n",
    "    4.510854244232178,\n",
    "    4.277856826782227,\n",
    "    4.372178077697754,\n",
    "    4.23385763168335,\n",
    "    4.203474521636963,\n",
    "    4.1146321296691895,\n",
    "    4.2475175857543945,\n",
    "    4.318978786468506,\n",
    "    4.025015830993652,\n",
    "    4.066944599151611,\n",
    "    3.924344539642334,\n",
    "    3.8199424743652344,\n",
    "    4.365871429443359,\n",
    "    3.903102397918701,\n",
    "    3.9057796001434326,\n",
    "    3.8969101905822754,\n",
    "    3.8612473011016846,\n",
    "    3.8846774101257324,\n",
    "    3.7560160160064697,\n",
    "    3.9347152709960938,\n",
    "    3.7501065731048584,\n",
    "    3.7642714977264404,\n",
    "    3.723398447036743,\n",
    "    3.6881160736083984,\n",
    "    3.8137731552124023,\n",
    "    3.8387277126312256,\n",
    "    3.662757396697998,\n",
    "    3.72711443901062,\n",
    "    3.7273483276367188,\n",
    "    3.632136821746826,\n",
    "    3.603520631790161,\n",
    "    3.733233690261841,\n",
    "    3.815927743911743,\n",
    "    3.7718424797058105,\n",
    "    3.732658624649048,\n",
    "    3.593083143234253,\n",
    "    3.5991692543029785,\n",
    "    3.7858524322509766,\n",
    "    3.8326475620269775,\n",
    "    3.47650146484375,\n",
    "    3.6739680767059326,\n",
    "    3.6670515537261963,\n",
    "    3.7756073474884033,\n",
    "    3.669278860092163,\n",
    "    3.4506940841674805,\n",
    "    3.5075109004974365,\n",
    "    3.670701503753662,\n",
    "    3.366098165512085,\n",
    "    3.6222925186157227,\n",
    "    3.619891881942749,\n",
    "    3.657230854034424,\n",
    "    3.6209700107574463,\n",
    "    3.6779682636260986,\n",
    "    3.911665678024292,\n",
    "    3.4693241119384766,\n",
    "    3.670677661895752,\n",
    "    3.4613699913024902,\n",
    "    3.361825704574585],\n",
    "   'val_accuracy': [0.012450000271201134,\n",
    "    0.01360000018030405,\n",
    "    0.023150000721216202,\n",
    "    0.020800000056624413,\n",
    "    0.03595000132918358,\n",
    "    0.07159999758005142,\n",
    "    0.054999999701976776,\n",
    "    0.060499999672174454,\n",
    "    0.08489999920129776,\n",
    "    0.08579999953508377,\n",
    "    0.08789999783039093,\n",
    "    0.09144999831914902,\n",
    "    0.1136000007390976,\n",
    "    0.10740000009536743,\n",
    "    0.11794999986886978,\n",
    "    0.1237500011920929,\n",
    "    0.1326500028371811,\n",
    "    0.12060000002384186,\n",
    "    0.11569999903440475,\n",
    "    0.1407500058412552,\n",
    "    0.14315000176429749,\n",
    "    0.16075000166893005,\n",
    "    0.17649999260902405,\n",
    "    0.11675000190734863,\n",
    "    0.16535000503063202,\n",
    "    0.16449999809265137,\n",
    "    0.16314999759197235,\n",
    "    0.1738000065088272,\n",
    "    0.17149999737739563,\n",
    "    0.18574999272823334,\n",
    "    0.16689999401569366,\n",
    "    0.1839500069618225,\n",
    "    0.19009999930858612,\n",
    "    0.19050000607967377,\n",
    "    0.19679999351501465,\n",
    "    0.18019999563694,\n",
    "    0.18324999511241913,\n",
    "    0.20270000398159027,\n",
    "    0.1995999962091446,\n",
    "    0.18915000557899475,\n",
    "    0.20755000412464142,\n",
    "    0.21735000610351562,\n",
    "    0.1975499987602234,\n",
    "    0.19020000100135803,\n",
    "    0.19670000672340393,\n",
    "    0.19634999334812164,\n",
    "    0.21799999475479126,\n",
    "    0.21535000205039978,\n",
    "    0.1951500028371811,\n",
    "    0.19294999539852142,\n",
    "    0.2324499934911728,\n",
    "    0.21549999713897705,\n",
    "    0.21040000021457672,\n",
    "    0.19265000522136688,\n",
    "    0.2089499980211258,\n",
    "    0.23919999599456787,\n",
    "    0.23405000567436218,\n",
    "    0.21369999647140503,\n",
    "    0.25440001487731934,\n",
    "    0.22245000302791595,\n",
    "    0.22089999914169312,\n",
    "    0.2168000042438507,\n",
    "    0.21870000660419464,\n",
    "    0.2134000062942505,\n",
    "    0.1907999962568283,\n",
    "    0.2459000051021576,\n",
    "    0.2179500013589859,\n",
    "    0.24940000474452972,\n",
    "    0.2579500079154968]}},\n",
    " {'0.0001 512': {'loss': [5.599355697631836,\n",
    "    5.207976341247559,\n",
    "    5.025490760803223,\n",
    "    4.817569732666016,\n",
    "    4.6367387771606445,\n",
    "    4.4903740882873535,\n",
    "    4.363053321838379,\n",
    "    4.255809307098389,\n",
    "    4.161812782287598,\n",
    "    4.083789825439453,\n",
    "    4.009998321533203,\n",
    "    3.940415620803833,\n",
    "    3.877366304397583,\n",
    "    3.8221421241760254,\n",
    "    3.7703614234924316,\n",
    "    3.7156426906585693,\n",
    "    3.6737968921661377,\n",
    "    3.6244773864746094,\n",
    "    3.5857207775115967,\n",
    "    3.554090738296509,\n",
    "    3.5209901332855225,\n",
    "    3.4786295890808105,\n",
    "    3.4412081241607666,\n",
    "    3.414572238922119,\n",
    "    3.3853938579559326,\n",
    "    3.3511838912963867,\n",
    "    3.325505018234253,\n",
    "    3.30035400390625,\n",
    "    3.2816667556762695,\n",
    "    3.249246597290039,\n",
    "    3.218838930130005,\n",
    "    3.2005438804626465,\n",
    "    3.1768386363983154,\n",
    "    3.1556572914123535,\n",
    "    3.139047145843506,\n",
    "    3.1170878410339355,\n",
    "    3.096923828125,\n",
    "    3.0821354389190674,\n",
    "    3.065817356109619,\n",
    "    3.043306589126587,\n",
    "    3.0307085514068604],\n",
    "   'accuracy': [0.014687499962747097,\n",
    "    0.024924999102950096,\n",
    "    0.0351875014603138,\n",
    "    0.05113749951124191,\n",
    "    0.06769999861717224,\n",
    "    0.08043749630451202,\n",
    "    0.09513749927282333,\n",
    "    0.10813750326633453,\n",
    "    0.1200999990105629,\n",
    "    0.13016250729560852,\n",
    "    0.14233750104904175,\n",
    "    0.15111249685287476,\n",
    "    0.15947499871253967,\n",
    "    0.16805000603199005,\n",
    "    0.1751125007867813,\n",
    "    0.18322500586509705,\n",
    "    0.19002500176429749,\n",
    "    0.19817499816417694,\n",
    "    0.20514999330043793,\n",
    "    0.21043750643730164,\n",
    "    0.21576249599456787,\n",
    "    0.22273750603199005,\n",
    "    0.2282875031232834,\n",
    "    0.2326499968767166,\n",
    "    0.2378624975681305,\n",
    "    0.2425374984741211,\n",
    "    0.24744999408721924,\n",
    "    0.2511749863624573,\n",
    "    0.2544499933719635,\n",
    "    0.26307499408721924,\n",
    "    0.2656624913215637,\n",
    "    0.2707875072956085,\n",
    "    0.27617499232292175,\n",
    "    0.2763749957084656,\n",
    "    0.28068751096725464,\n",
    "    0.2840625047683716,\n",
    "    0.29006248712539673,\n",
    "    0.2912124991416931,\n",
    "    0.2933500111103058,\n",
    "    0.29698750376701355,\n",
    "    0.298675000667572],\n",
    "   'val_loss': [5.0885491371154785,\n",
    "    4.949437141418457,\n",
    "    5.166783809661865,\n",
    "    5.064779758453369,\n",
    "    4.920461177825928,\n",
    "    5.189326763153076,\n",
    "    5.126427173614502,\n",
    "    5.206149578094482,\n",
    "    4.746731281280518,\n",
    "    4.702942848205566,\n",
    "    4.7513227462768555,\n",
    "    4.792031288146973,\n",
    "    4.397158622741699,\n",
    "    4.166595935821533,\n",
    "    4.1070427894592285,\n",
    "    4.140213489532471,\n",
    "    4.198607921600342,\n",
    "    4.17410945892334,\n",
    "    4.093937873840332,\n",
    "    3.9497671127319336,\n",
    "    4.0640869140625,\n",
    "    3.8050832748413086,\n",
    "    4.047677993774414,\n",
    "    3.897669553756714,\n",
    "    4.150916576385498,\n",
    "    3.8246631622314453,\n",
    "    3.9056437015533447,\n",
    "    3.9794039726257324,\n",
    "    4.074214935302734,\n",
    "    3.8631789684295654,\n",
    "    3.6514346599578857,\n",
    "    3.9815852642059326,\n",
    "    3.688563585281372,\n",
    "    4.064929485321045,\n",
    "    3.8100812435150146,\n",
    "    3.746936798095703,\n",
    "    3.8620171546936035,\n",
    "    3.8396871089935303,\n",
    "    3.792923927307129,\n",
    "    3.74617338180542,\n",
    "    3.8780057430267334],\n",
    "   'val_accuracy': [0.02329999953508377,\n",
    "    0.03595000132918358,\n",
    "    0.024299999698996544,\n",
    "    0.03905000165104866,\n",
    "    0.05204999819397926,\n",
    "    0.04675000160932541,\n",
    "    0.04659999907016754,\n",
    "    0.04659999907016754,\n",
    "    0.061149999499320984,\n",
    "    0.0767500028014183,\n",
    "    0.07249999791383743,\n",
    "    0.07365000247955322,\n",
    "    0.0986500009894371,\n",
    "    0.12995000183582306,\n",
    "    0.13199999928474426,\n",
    "    0.12960000336170197,\n",
    "    0.12939999997615814,\n",
    "    0.1307000070810318,\n",
    "    0.1370999962091446,\n",
    "    0.15254999697208405,\n",
    "    0.14560000598430634,\n",
    "    0.17315000295639038,\n",
    "    0.15105000138282776,\n",
    "    0.16294999420642853,\n",
    "    0.13660000264644623,\n",
    "    0.1754000037908554,\n",
    "    0.1662999987602234,\n",
    "    0.1586499959230423,\n",
    "    0.1492999941110611,\n",
    "    0.1716500073671341,\n",
    "    0.20035000145435333,\n",
    "    0.16494999825954437,\n",
    "    0.19840000569820404,\n",
    "    0.15189999341964722,\n",
    "    0.18199999630451202,\n",
    "    0.19030000269412994,\n",
    "    0.17949999868869781,\n",
    "    0.18039999902248383,\n",
    "    0.188400000333786,\n",
    "    0.19290000200271606,\n",
    "    0.1754000037908554]}},\n",
    " {'0.0001 1024': {'loss': [5.673172950744629,\n",
    "    5.225280284881592,\n",
    "    5.001189231872559,\n",
    "    4.794386863708496,\n",
    "    4.62912130355835,\n",
    "    4.486423492431641,\n",
    "    4.363304615020752,\n",
    "    4.248741626739502,\n",
    "    4.165303707122803,\n",
    "    4.07966947555542,\n",
    "    4.001178741455078,\n",
    "    3.935920000076294,\n",
    "    3.866877317428589,\n",
    "    3.8103842735290527,\n",
    "    3.763564348220825,\n",
    "    3.707719087600708,\n",
    "    3.6690895557403564,\n",
    "    3.6254823207855225,\n",
    "    3.572871208190918,\n",
    "    3.5389301776885986,\n",
    "    3.5003409385681152,\n",
    "    3.4655444622039795,\n",
    "    3.428842306137085,\n",
    "    3.392688274383545,\n",
    "    3.364189386367798,\n",
    "    3.3400051593780518,\n",
    "    3.3097386360168457,\n",
    "    3.2831063270568848,\n",
    "    3.2565724849700928,\n",
    "    3.233107328414917,\n",
    "    3.205946683883667,\n",
    "    3.1900100708007812,\n",
    "    3.1683883666992188,\n",
    "    3.1424400806427,\n",
    "    3.128624439239502,\n",
    "    3.106316089630127,\n",
    "    3.0895955562591553],\n",
    "   'accuracy': [0.011274999938905239,\n",
    "    0.02370000071823597,\n",
    "    0.037950001657009125,\n",
    "    0.05420000106096268,\n",
    "    0.06655000150203705,\n",
    "    0.08253750205039978,\n",
    "    0.09691250324249268,\n",
    "    0.11031249910593033,\n",
    "    0.11942499876022339,\n",
    "    0.13151249289512634,\n",
    "    0.14139999449253082,\n",
    "    0.15000000596046448,\n",
    "    0.16167500615119934,\n",
    "    0.16848750412464142,\n",
    "    0.17598749697208405,\n",
    "    0.1859000027179718,\n",
    "    0.18958750367164612,\n",
    "    0.19653749465942383,\n",
    "    0.20548750460147858,\n",
    "    0.21166250109672546,\n",
    "    0.21768750250339508,\n",
    "    0.2253749966621399,\n",
    "    0.22868749499320984,\n",
    "    0.23618750274181366,\n",
    "    0.24191249907016754,\n",
    "    0.24531249701976776,\n",
    "    0.25049999356269836,\n",
    "    0.25657498836517334,\n",
    "    0.25981250405311584,\n",
    "    0.2638624906539917,\n",
    "    0.2694000005722046,\n",
    "    0.2703000009059906,\n",
    "    0.27441251277923584,\n",
    "    0.28037500381469727,\n",
    "    0.28222501277923584,\n",
    "    0.28856250643730164,\n",
    "    0.28968751430511475],\n",
    "   'val_loss': [5.138355255126953,\n",
    "    5.176791191101074,\n",
    "    5.115297794342041,\n",
    "    5.242786884307861,\n",
    "    5.279496669769287,\n",
    "    4.892899036407471,\n",
    "    4.9690704345703125,\n",
    "    4.875664234161377,\n",
    "    4.70344352722168,\n",
    "    4.672043323516846,\n",
    "    4.514686107635498,\n",
    "    4.324913024902344,\n",
    "    4.470050811767578,\n",
    "    4.371607303619385,\n",
    "    4.189382076263428,\n",
    "    4.4408392906188965,\n",
    "    4.150383472442627,\n",
    "    4.367187023162842,\n",
    "    4.094916820526123,\n",
    "    4.003081321716309,\n",
    "    4.178650379180908,\n",
    "    4.23727560043335,\n",
    "    4.337963104248047,\n",
    "    4.467939376831055,\n",
    "    3.9944875240325928,\n",
    "    4.156300067901611,\n",
    "    3.7422266006469727,\n",
    "    3.981631278991699,\n",
    "    3.9795913696289062,\n",
    "    3.976016044616699,\n",
    "    3.9677116870880127,\n",
    "    4.058425426483154,\n",
    "    4.508744239807129,\n",
    "    3.948549270629883,\n",
    "    4.027235507965088,\n",
    "    3.8870949745178223,\n",
    "    3.8628270626068115],\n",
    "   'val_accuracy': [0.021400000900030136,\n",
    "    0.022050000727176666,\n",
    "    0.03550000116229057,\n",
    "    0.031599998474121094,\n",
    "    0.03784999996423721,\n",
    "    0.05739999935030937,\n",
    "    0.050599999725818634,\n",
    "    0.05180000141263008,\n",
    "    0.06610000133514404,\n",
    "    0.07199999690055847,\n",
    "    0.08910000324249268,\n",
    "    0.10740000009536743,\n",
    "    0.08914999663829803,\n",
    "    0.09724999964237213,\n",
    "    0.11869999766349792,\n",
    "    0.09775000065565109,\n",
    "    0.12610000371932983,\n",
    "    0.1051499992609024,\n",
    "    0.13269999623298645,\n",
    "    0.14624999463558197,\n",
    "    0.1277499943971634,\n",
    "    0.12264999747276306,\n",
    "    0.11980000138282776,\n",
    "    0.10409999638795853,\n",
    "    0.14875000715255737,\n",
    "    0.13414999842643738,\n",
    "    0.18645000457763672,\n",
    "    0.15559999644756317,\n",
    "    0.1581999957561493,\n",
    "    0.15850000083446503,\n",
    "    0.15889999270439148,\n",
    "    0.15344999730587006,\n",
    "    0.1143999993801117,\n",
    "    0.16619999706745148,\n",
    "    0.15790000557899475,\n",
    "    0.17399999499320984,\n",
    "    0.17344999313354492]}},\n",
    " {'1e-05 64': {'loss': [6.267604351043701,\n",
    "    6.017229080200195,\n",
    "    5.795938968658447,\n",
    "    5.659814357757568,\n",
    "    5.554079055786133,\n",
    "    5.48541784286499,\n",
    "    5.41881799697876,\n",
    "    5.352870941162109,\n",
    "    5.2993879318237305,\n",
    "    5.248549938201904,\n",
    "    5.190084457397461,\n",
    "    5.152253150939941,\n",
    "    5.11154317855835,\n",
    "    5.075594902038574,\n",
    "    5.033681392669678,\n",
    "    4.990336894989014],\n",
    "   'accuracy': [0.005925000179558992,\n",
    "    0.008512499742209911,\n",
    "    0.010425000451505184,\n",
    "    0.012087499722838402,\n",
    "    0.012962499633431435,\n",
    "    0.014425000175833702,\n",
    "    0.016737500205636024,\n",
    "    0.019687499850988388,\n",
    "    0.022162500768899918,\n",
    "    0.025474999099969864,\n",
    "    0.028224999085068703,\n",
    "    0.030799999833106995,\n",
    "    0.03412500023841858,\n",
    "    0.03584999963641167,\n",
    "    0.03947500139474869,\n",
    "    0.04036249965429306],\n",
    "   'val_loss': [5.4791259765625,\n",
    "    5.482903480529785,\n",
    "    5.480290412902832,\n",
    "    5.433551788330078,\n",
    "    5.374540328979492,\n",
    "    5.313061714172363,\n",
    "    5.30340051651001,\n",
    "    5.35342264175415,\n",
    "    5.407526969909668,\n",
    "    5.39150333404541,\n",
    "    5.546731472015381,\n",
    "    5.426642417907715,\n",
    "    5.511419773101807,\n",
    "    5.510039329528809,\n",
    "    5.626955032348633,\n",
    "    5.581814289093018],\n",
    "   'val_accuracy': [0.007400000002235174,\n",
    "    0.011649999767541885,\n",
    "    0.012550000101327896,\n",
    "    0.011699999682605267,\n",
    "    0.011950000189244747,\n",
    "    0.013749999925494194,\n",
    "    0.016249999403953552,\n",
    "    0.016950000077486038,\n",
    "    0.01850000023841858,\n",
    "    0.020600000396370888,\n",
    "    0.02225000038743019,\n",
    "    0.023150000721216202,\n",
    "    0.02669999934732914,\n",
    "    0.024550000205636024,\n",
    "    0.0239499993622303,\n",
    "    0.02225000038743019]}},\n",
    " {'1e-05 128': {'loss': [6.260848045349121,\n",
    "    6.068812370300293,\n",
    "    5.857532978057861,\n",
    "    5.691555500030518,\n",
    "    5.578389644622803,\n",
    "    5.497231483459473,\n",
    "    5.4271674156188965,\n",
    "    5.367839813232422,\n",
    "    5.298673629760742,\n",
    "    5.239190578460693,\n",
    "    5.187838077545166,\n",
    "    5.142300128936768,\n",
    "    5.106889724731445,\n",
    "    5.064700126647949,\n",
    "    5.021420478820801,\n",
    "    4.992188930511475,\n",
    "    4.952150821685791],\n",
    "   'accuracy': [0.005837500095367432,\n",
    "    0.007600000128149986,\n",
    "    0.009925000369548798,\n",
    "    0.01192499976605177,\n",
    "    0.01269999984651804,\n",
    "    0.01484999991953373,\n",
    "    0.016587499529123306,\n",
    "    0.01837499998509884,\n",
    "    0.021962499246001244,\n",
    "    0.025074999779462814,\n",
    "    0.02866250090301037,\n",
    "    0.030774999409914017,\n",
    "    0.0343874990940094,\n",
    "    0.036649998277425766,\n",
    "    0.0392875000834465,\n",
    "    0.041349999606609344,\n",
    "    0.045249998569488525],\n",
    "   'val_loss': [5.572654724121094,\n",
    "    5.707645416259766,\n",
    "    5.644395351409912,\n",
    "    5.402872085571289,\n",
    "    5.301148891448975,\n",
    "    5.265952110290527,\n",
    "    5.228416919708252,\n",
    "    5.22368860244751,\n",
    "    5.234049320220947,\n",
    "    5.240478515625,\n",
    "    5.231258869171143,\n",
    "    5.284363746643066,\n",
    "    5.352663993835449,\n",
    "    5.302968978881836,\n",
    "    5.407995223999023,\n",
    "    5.392138957977295,\n",
    "    5.465516567230225],\n",
    "   'val_accuracy': [0.006099999882280827,\n",
    "    0.008200000040233135,\n",
    "    0.009800000116229057,\n",
    "    0.012400000356137753,\n",
    "    0.016300000250339508,\n",
    "    0.01769999973475933,\n",
    "    0.01785000041127205,\n",
    "    0.02044999971985817,\n",
    "    0.022749999538064003,\n",
    "    0.02290000021457672,\n",
    "    0.02474999986588955,\n",
    "    0.022050000727176666,\n",
    "    0.020500000566244125,\n",
    "    0.021849999204277992,\n",
    "    0.0210999995470047,\n",
    "    0.02215000055730343,\n",
    "    0.023399999365210533]}},\n",
    " {'1e-05 256': {'loss': [6.2733869552612305,\n",
    "    6.079184532165527,\n",
    "    5.8941874504089355,\n",
    "    5.756016731262207,\n",
    "    5.632758617401123,\n",
    "    5.525523662567139,\n",
    "    5.4603962898254395,\n",
    "    5.391711711883545,\n",
    "    5.3332014083862305,\n",
    "    5.2925944328308105,\n",
    "    5.2477006912231445,\n",
    "    5.209285259246826,\n",
    "    5.168747425079346,\n",
    "    5.12693977355957,\n",
    "    5.081826210021973,\n",
    "    5.044910907745361,\n",
    "    5.0017547607421875,\n",
    "    4.963526248931885,\n",
    "    4.92711877822876,\n",
    "    4.886775970458984,\n",
    "    4.853367805480957],\n",
    "   'accuracy': [0.005462499801069498,\n",
    "    0.006049999967217445,\n",
    "    0.007887500338256359,\n",
    "    0.009349999949336052,\n",
    "    0.010837499983608723,\n",
    "    0.013749999925494194,\n",
    "    0.015462500043213367,\n",
    "    0.019087500870227814,\n",
    "    0.021575000137090683,\n",
    "    0.02317499928176403,\n",
    "    0.025550000369548798,\n",
    "    0.02671249955892563,\n",
    "    0.029712500050663948,\n",
    "    0.0325625017285347,\n",
    "    0.0351249985396862,\n",
    "    0.038100000470876694,\n",
    "    0.04228749871253967,\n",
    "    0.043425001204013824,\n",
    "    0.04749999940395355,\n",
    "    0.0494999997317791,\n",
    "    0.05178749933838844],\n",
    "   'val_loss': [5.4757609367370605,\n",
    "    5.490946292877197,\n",
    "    5.4458842277526855,\n",
    "    5.368358135223389,\n",
    "    5.236701011657715,\n",
    "    5.1611199378967285,\n",
    "    5.118547439575195,\n",
    "    5.05600118637085,\n",
    "    5.034750938415527,\n",
    "    5.002837657928467,\n",
    "    4.9590325355529785,\n",
    "    4.983459949493408,\n",
    "    4.978888034820557,\n",
    "    4.968429088592529,\n",
    "    4.989798545837402,\n",
    "    5.040584564208984,\n",
    "    5.06900691986084,\n",
    "    5.21587610244751,\n",
    "    5.244900226593018,\n",
    "    5.246007919311523,\n",
    "    5.402960777282715],\n",
    "   'val_accuracy': [0.006500000134110451,\n",
    "    0.006599999964237213,\n",
    "    0.00774999987334013,\n",
    "    0.010250000283122063,\n",
    "    0.015949999913573265,\n",
    "    0.020600000396370888,\n",
    "    0.02645000070333481,\n",
    "    0.030750000849366188,\n",
    "    0.03164999932050705,\n",
    "    0.0357000008225441,\n",
    "    0.03880000114440918,\n",
    "    0.03709999844431877,\n",
    "    0.03799999877810478,\n",
    "    0.039650000631809235,\n",
    "    0.03685000166296959,\n",
    "    0.03460000082850456,\n",
    "    0.03530000150203705,\n",
    "    0.03034999966621399,\n",
    "    0.028349999338388443,\n",
    "    0.02969999983906746,\n",
    "    0.027049999684095383]}},\n",
    " {'1e-05 512': {'loss': [6.266663074493408,\n",
    "    6.037073612213135,\n",
    "    5.8088459968566895,\n",
    "    5.651182174682617,\n",
    "    5.55121374130249,\n",
    "    5.482537269592285,\n",
    "    5.405886173248291,\n",
    "    5.34839391708374,\n",
    "    5.300048351287842,\n",
    "    5.25050163269043,\n",
    "    5.214582920074463,\n",
    "    5.164236545562744,\n",
    "    5.126221179962158,\n",
    "    5.081775188446045,\n",
    "    5.035394191741943,\n",
    "    4.997166633605957,\n",
    "    4.962401390075684,\n",
    "    4.934241771697998,\n",
    "    4.892258644104004],\n",
    "   'accuracy': [0.005712499842047691,\n",
    "    0.007675000000745058,\n",
    "    0.010075000114738941,\n",
    "    0.012199999764561653,\n",
    "    0.013700000010430813,\n",
    "    0.014887499623000622,\n",
    "    0.017112499102950096,\n",
    "    0.019487500190734863,\n",
    "    0.021974999457597733,\n",
    "    0.024712499231100082,\n",
    "    0.026462500914931297,\n",
    "    0.029650000855326653,\n",
    "    0.032625000923871994,\n",
    "    0.03454999998211861,\n",
    "    0.03818750008940697,\n",
    "    0.041099999099969864,\n",
    "    0.04267499968409538,\n",
    "    0.045049998909235,\n",
    "    0.0484125018119812],\n",
    "   'val_loss': [5.614554405212402,\n",
    "    5.815329074859619,\n",
    "    5.888481140136719,\n",
    "    5.678643226623535,\n",
    "    5.498057842254639,\n",
    "    5.461031436920166,\n",
    "    5.506048202514648,\n",
    "    5.329260349273682,\n",
    "    5.241473197937012,\n",
    "    5.303952693939209,\n",
    "    5.249098300933838,\n",
    "    5.344089031219482,\n",
    "    6.024963855743408,\n",
    "    6.048304080963135,\n",
    "    6.155496120452881,\n",
    "    5.795054912567139,\n",
    "    5.687230587005615,\n",
    "    5.648983001708984,\n",
    "    5.465303897857666],\n",
    "   'val_accuracy': [0.0064500002190470695,\n",
    "    0.008249999955296516,\n",
    "    0.010300000198185444,\n",
    "    0.013050000183284283,\n",
    "    0.015150000341236591,\n",
    "    0.01810000091791153,\n",
    "    0.018850000575184822,\n",
    "    0.020250000059604645,\n",
    "    0.023000000044703484,\n",
    "    0.0210999995470047,\n",
    "    0.025350000709295273,\n",
    "    0.026000000536441803,\n",
    "    0.020400000736117363,\n",
    "    0.019600000232458115,\n",
    "    0.018850000575184822,\n",
    "    0.020549999549984932,\n",
    "    0.021250000223517418,\n",
    "    0.02005000039935112,\n",
    "    0.020150000229477882]}},\n",
    " {'1e-05 1024': {'loss': [6.257532596588135,\n",
    "    6.037821292877197,\n",
    "    5.788599491119385,\n",
    "    5.635698318481445,\n",
    "    5.532815933227539,\n",
    "    5.464034557342529,\n",
    "    5.404558181762695,\n",
    "    5.349939346313477,\n",
    "    5.287420272827148,\n",
    "    5.2331342697143555,\n",
    "    5.186380386352539,\n",
    "    5.1402668952941895,\n",
    "    5.1003618240356445,\n",
    "    5.053704261779785,\n",
    "    5.017181873321533,\n",
    "    4.981784820556641,\n",
    "    4.936587810516357,\n",
    "    4.911896228790283],\n",
    "   'accuracy': [0.005837500095367432,\n",
    "    0.007974999956786633,\n",
    "    0.010787500068545341,\n",
    "    0.011837500147521496,\n",
    "    0.013425000011920929,\n",
    "    0.01484999991953373,\n",
    "    0.01743750087916851,\n",
    "    0.018699999898672104,\n",
    "    0.022224999964237213,\n",
    "    0.024775000289082527,\n",
    "    0.028449999168515205,\n",
    "    0.030649999156594276,\n",
    "    0.03311249986290932,\n",
    "    0.037037499248981476,\n",
    "    0.037812501192092896,\n",
    "    0.04091250151395798,\n",
    "    0.0440250001847744,\n",
    "    0.04691249877214432],\n",
    "   'val_loss': [5.674829006195068,\n",
    "    5.659399032592773,\n",
    "    5.578372478485107,\n",
    "    5.453276634216309,\n",
    "    5.363699436187744,\n",
    "    5.350625991821289,\n",
    "    5.372450828552246,\n",
    "    5.276909351348877,\n",
    "    5.3093156814575195,\n",
    "    5.304832935333252,\n",
    "    5.313027858734131,\n",
    "    5.455801010131836,\n",
    "    5.41414737701416,\n",
    "    5.431419849395752,\n",
    "    5.44774866104126,\n",
    "    5.480873107910156,\n",
    "    5.542534351348877,\n",
    "    5.559055805206299],\n",
    "   'val_accuracy': [0.006649999879300594,\n",
    "    0.01054999977350235,\n",
    "    0.013749999925494194,\n",
    "    0.013799999840557575,\n",
    "    0.016699999570846558,\n",
    "    0.01655000075697899,\n",
    "    0.01614999957382679,\n",
    "    0.017899999395012856,\n",
    "    0.01875000074505806,\n",
    "    0.020800000056624413,\n",
    "    0.021050000563263893,\n",
    "    0.01889999955892563,\n",
    "    0.01875000074505806,\n",
    "    0.01850000023841858,\n",
    "    0.018850000575184822,\n",
    "    0.019600000232458115,\n",
    "    0.02085000090301037,\n",
    "    0.020749999210238457]}},\n",
    " {'1e-06 64': {'loss': [6.374655723571777,\n",
    "    6.3521857261657715,\n",
    "    6.34626579284668,\n",
    "    6.316930770874023,\n",
    "    6.29805850982666,\n",
    "    6.282906532287598,\n",
    "    6.268648624420166,\n",
    "    6.238188743591309,\n",
    "    6.220863342285156,\n",
    "    6.19840669631958,\n",
    "    6.177266597747803,\n",
    "    6.152695655822754,\n",
    "    6.14560604095459],\n",
    "   'accuracy': [0.005237500183284283,\n",
    "    0.005062500014901161,\n",
    "    0.004987500142306089,\n",
    "    0.0048374999314546585,\n",
    "    0.005574999842792749,\n",
    "    0.005249999929219484,\n",
    "    0.006087500136345625,\n",
    "    0.006262499839067459,\n",
    "    0.006200000178068876,\n",
    "    0.005925000179558992,\n",
    "    0.0066999997943639755,\n",
    "    0.0067125000059604645,\n",
    "    0.006562499795109034],\n",
    "   'val_loss': [5.546321392059326,\n",
    "    5.5315656661987305,\n",
    "    5.52140998840332,\n",
    "    5.5196003913879395,\n",
    "    5.523080825805664,\n",
    "    5.532283782958984,\n",
    "    5.538686275482178,\n",
    "    5.540533542633057,\n",
    "    5.553930282592773,\n",
    "    5.578012943267822,\n",
    "    5.598945617675781,\n",
    "    5.605686187744141,\n",
    "    5.622829437255859],\n",
    "   'val_accuracy': [0.00494999997317791,\n",
    "    0.005049999803304672,\n",
    "    0.004650000017136335,\n",
    "    0.005150000099092722,\n",
    "    0.005049999803304672,\n",
    "    0.005849999841302633,\n",
    "    0.0062500000931322575,\n",
    "    0.005750000011175871,\n",
    "    0.006949999835342169,\n",
    "    0.006099999882280827,\n",
    "    0.006149999797344208,\n",
    "    0.0062500000931322575,\n",
    "    0.007000000216066837]}},\n",
    " {'1e-06 128': {'loss': [6.357712745666504,\n",
    "    6.320926189422607,\n",
    "    6.290989875793457,\n",
    "    6.255410194396973,\n",
    "    6.22971773147583,\n",
    "    6.206090450286865,\n",
    "    6.1700873374938965,\n",
    "    6.147754192352295,\n",
    "    6.108140468597412,\n",
    "    6.079620361328125,\n",
    "    6.049965858459473,\n",
    "    6.018250942230225,\n",
    "    5.994989395141602,\n",
    "    5.97418212890625,\n",
    "    5.944056034088135,\n",
    "    5.911797523498535,\n",
    "    5.888168811798096,\n",
    "    5.863096714019775,\n",
    "    5.8310322761535645,\n",
    "    5.815792083740234,\n",
    "    5.8002400398254395,\n",
    "    5.766543865203857,\n",
    "    5.7542724609375,\n",
    "    5.730904579162598,\n",
    "    5.707512378692627,\n",
    "    5.696931838989258,\n",
    "    5.685831546783447,\n",
    "    5.661146640777588,\n",
    "    5.648227691650391,\n",
    "    5.635883808135986,\n",
    "    5.6259989738464355,\n",
    "    5.616201400756836,\n",
    "    5.602025985717773,\n",
    "    5.584847450256348,\n",
    "    5.578152656555176,\n",
    "    5.569258689880371,\n",
    "    5.552056312561035,\n",
    "    5.549827575683594,\n",
    "    5.530740261077881,\n",
    "    5.5257439613342285,\n",
    "    5.513364315032959,\n",
    "    5.503505706787109,\n",
    "    5.4976806640625,\n",
    "    5.48573637008667,\n",
    "    5.473630905151367,\n",
    "    5.471259117126465,\n",
    "    5.460187911987305,\n",
    "    5.452154636383057,\n",
    "    5.439949035644531,\n",
    "    5.433635711669922,\n",
    "    5.42807674407959,\n",
    "    5.41071081161499,\n",
    "    5.4043354988098145,\n",
    "    5.398841857910156,\n",
    "    5.394458770751953,\n",
    "    5.386724948883057,\n",
    "    5.379947662353516,\n",
    "    5.375017166137695,\n",
    "    5.365105152130127,\n",
    "    5.358132839202881,\n",
    "    5.349124431610107,\n",
    "    5.343623638153076,\n",
    "    5.338870048522949,\n",
    "    5.336495876312256,\n",
    "    5.324650287628174,\n",
    "    5.320096015930176,\n",
    "    5.3115363121032715],\n",
    "   'accuracy': [0.0048500001430511475,\n",
    "    0.005812500137835741,\n",
    "    0.005574999842792749,\n",
    "    0.005524999927729368,\n",
    "    0.005675000138580799,\n",
    "    0.005750000011175871,\n",
    "    0.006775000132620335,\n",
    "    0.006087500136345625,\n",
    "    0.00647500017657876,\n",
    "    0.007287499960511923,\n",
    "    0.007487500086426735,\n",
    "    0.007149999961256981,\n",
    "    0.007362499833106995,\n",
    "    0.007887500338256359,\n",
    "    0.008674999698996544,\n",
    "    0.008962499909102917,\n",
    "    0.008562499657273293,\n",
    "    0.009074999950826168,\n",
    "    0.00971249956637621,\n",
    "    0.00971249956637621,\n",
    "    0.009912500157952309,\n",
    "    0.010337499901652336,\n",
    "    0.009937499649822712,\n",
    "    0.010324999690055847,\n",
    "    0.010900000110268593,\n",
    "    0.010712499730288982,\n",
    "    0.010637500323355198,\n",
    "    0.011474999599158764,\n",
    "    0.012550000101327896,\n",
    "    0.012225000187754631,\n",
    "    0.011737500317394733,\n",
    "    0.012262499891221523,\n",
    "    0.01341249980032444,\n",
    "    0.013462499715387821,\n",
    "    0.013387500308454037,\n",
    "    0.01295000035315752,\n",
    "    0.013624999672174454,\n",
    "    0.013787499628961086,\n",
    "    0.014475000090897083,\n",
    "    0.014712500385940075,\n",
    "    0.014412499964237213,\n",
    "    0.01600000075995922,\n",
    "    0.015462500043213367,\n",
    "    0.015775000676512718,\n",
    "    0.016574999317526817,\n",
    "    0.0165375005453825,\n",
    "    0.01691249944269657,\n",
    "    0.017224999144673347,\n",
    "    0.017287500202655792,\n",
    "    0.01744999922811985,\n",
    "    0.018024999648332596,\n",
    "    0.017537500709295273,\n",
    "    0.019449999555945396,\n",
    "    0.019562499597668648,\n",
    "    0.01993750035762787,\n",
    "    0.019087500870227814,\n",
    "    0.021150000393390656,\n",
    "    0.020787499845027924,\n",
    "    0.020275000482797623,\n",
    "    0.020487500354647636,\n",
    "    0.02095000073313713,\n",
    "    0.02241249941289425,\n",
    "    0.02085000090301037,\n",
    "    0.022212499752640724,\n",
    "    0.022562500089406967,\n",
    "    0.023512499406933784,\n",
    "    0.02367500029504299],\n",
    "   'val_loss': [5.572366714477539,\n",
    "    5.558899402618408,\n",
    "    5.552966117858887,\n",
    "    5.5507121086120605,\n",
    "    5.551476001739502,\n",
    "    5.544964790344238,\n",
    "    5.55507755279541,\n",
    "    5.531571865081787,\n",
    "    5.535589218139648,\n",
    "    5.532002925872803,\n",
    "    5.529697418212891,\n",
    "    5.533504486083984,\n",
    "    5.514553070068359,\n",
    "    5.507997989654541,\n",
    "    5.494556427001953,\n",
    "    5.482053279876709,\n",
    "    5.467048168182373,\n",
    "    5.453505992889404,\n",
    "    5.4420366287231445,\n",
    "    5.4488301277160645,\n",
    "    5.457552909851074,\n",
    "    5.442082405090332,\n",
    "    5.455855369567871,\n",
    "    5.447612762451172,\n",
    "    5.4451985359191895,\n",
    "    5.414621829986572,\n",
    "    5.413037300109863,\n",
    "    5.380223274230957,\n",
    "    5.376701831817627,\n",
    "    5.362453460693359,\n",
    "    5.336065292358398,\n",
    "    5.321049213409424,\n",
    "    5.315622806549072,\n",
    "    5.299064636230469,\n",
    "    5.283480644226074,\n",
    "    5.278284072875977,\n",
    "    5.260913848876953,\n",
    "    5.248435020446777,\n",
    "    5.240515232086182,\n",
    "    5.224936485290527,\n",
    "    5.219989776611328,\n",
    "    5.212223052978516,\n",
    "    5.205439567565918,\n",
    "    5.199947834014893,\n",
    "    5.187648296356201,\n",
    "    5.173678398132324,\n",
    "    5.175662994384766,\n",
    "    5.172379493713379,\n",
    "    5.163205623626709,\n",
    "    5.157362937927246,\n",
    "    5.1526594161987305,\n",
    "    5.149214744567871,\n",
    "    5.1423659324646,\n",
    "    5.140865802764893,\n",
    "    5.141373634338379,\n",
    "    5.136879920959473,\n",
    "    5.12803316116333,\n",
    "    5.128530502319336,\n",
    "    5.123592376708984,\n",
    "    5.12498140335083,\n",
    "    5.125528335571289,\n",
    "    5.12770938873291,\n",
    "    5.124312400817871,\n",
    "    5.122936248779297,\n",
    "    5.127377986907959,\n",
    "    5.1309099197387695,\n",
    "    5.129536151885986],\n",
    "   'val_accuracy': [0.005799999926239252,\n",
    "    0.005849999841302633,\n",
    "    0.005499999970197678,\n",
    "    0.006149999797344208,\n",
    "    0.005900000222027302,\n",
    "    0.006850000005215406,\n",
    "    0.006599999964237213,\n",
    "    0.0071000000461936,\n",
    "    0.006399999838322401,\n",
    "    0.0071000000461936,\n",
    "    0.007149999961256981,\n",
    "    0.0076500000432133675,\n",
    "    0.007699999958276749,\n",
    "    0.00865000020712614,\n",
    "    0.00925000011920929,\n",
    "    0.008999999612569809,\n",
    "    0.008949999697506428,\n",
    "    0.009349999949336052,\n",
    "    0.010049999691545963,\n",
    "    0.010599999688565731,\n",
    "    0.009800000116229057,\n",
    "    0.010649999603629112,\n",
    "    0.011149999685585499,\n",
    "    0.011549999937415123,\n",
    "    0.011300000362098217,\n",
    "    0.011800000444054604,\n",
    "    0.01209999993443489,\n",
    "    0.012550000101327896,\n",
    "    0.012749999761581421,\n",
    "    0.01295000035315752,\n",
    "    0.013799999840557575,\n",
    "    0.013650000095367432,\n",
    "    0.0142000000923872,\n",
    "    0.014449999667704105,\n",
    "    0.01484999991953373,\n",
    "    0.01575000025331974,\n",
    "    0.015350000001490116,\n",
    "    0.016499999910593033,\n",
    "    0.01655000075697899,\n",
    "    0.01759999990463257,\n",
    "    0.017899999395012856,\n",
    "    0.018799999728798866,\n",
    "    0.018699999898672104,\n",
    "    0.01915000006556511,\n",
    "    0.020099999383091927,\n",
    "    0.02070000022649765,\n",
    "    0.020250000059604645,\n",
    "    0.021199999377131462,\n",
    "    0.021649999544024467,\n",
    "    0.022600000724196434,\n",
    "    0.023000000044703484,\n",
    "    0.02355000004172325,\n",
    "    0.023649999871850014,\n",
    "    0.0239499993622303,\n",
    "    0.02384999953210354,\n",
    "    0.023900000378489494,\n",
    "    0.025100000202655792,\n",
    "    0.02484999969601631,\n",
    "    0.026100000366568565,\n",
    "    0.026850000023841858,\n",
    "    0.026799999177455902,\n",
    "    0.026599999517202377,\n",
    "    0.027249999344348907,\n",
    "    0.0272000003606081,\n",
    "    0.027000000700354576,\n",
    "    0.026900000870227814,\n",
    "    0.027049999684095383]}},\n",
    " {'1e-06 256': {'loss': [6.357344150543213,\n",
    "    6.3432512283325195,\n",
    "    6.322662830352783,\n",
    "    6.289546012878418,\n",
    "    6.279897689819336,\n",
    "    6.260500907897949,\n",
    "    6.231764793395996,\n",
    "    6.221284866333008,\n",
    "    6.201572418212891,\n",
    "    6.1799798011779785,\n",
    "    6.15764856338501],\n",
    "   'accuracy': [0.004749999847263098,\n",
    "    0.005400000140070915,\n",
    "    0.0048500001430511475,\n",
    "    0.005574999842792749,\n",
    "    0.0057749999687075615,\n",
    "    0.005237500183284283,\n",
    "    0.00572500005364418,\n",
    "    0.005750000011175871,\n",
    "    0.005712499842047691,\n",
    "    0.0061125000938773155,\n",
    "    0.006599999964237213],\n",
    "   'val_loss': [5.565440654754639,\n",
    "    5.568357944488525,\n",
    "    5.578430652618408,\n",
    "    5.591640949249268,\n",
    "    5.614657402038574,\n",
    "    5.629776954650879,\n",
    "    5.665003299713135,\n",
    "    5.691984176635742,\n",
    "    5.70894193649292,\n",
    "    5.709456443786621,\n",
    "    5.770325183868408],\n",
    "   'val_accuracy': [0.004800000227987766,\n",
    "    0.004650000017136335,\n",
    "    0.0052999998442828655,\n",
    "    0.005049999803304672,\n",
    "    0.004900000058114529,\n",
    "    0.0052999998442828655,\n",
    "    0.0052999998442828655,\n",
    "    0.006000000052154064,\n",
    "    0.00634999992325902,\n",
    "    0.005249999929219484,\n",
    "    0.005799999926239252]}},\n",
    " {'1e-06 512': {'loss': [6.350846767425537,\n",
    "    6.340063095092773,\n",
    "    6.3106818199157715,\n",
    "    6.284351825714111,\n",
    "    6.2627763748168945,\n",
    "    6.239655017852783,\n",
    "    6.217000961303711,\n",
    "    6.191588878631592,\n",
    "    6.163886547088623,\n",
    "    6.158532619476318,\n",
    "    6.1404218673706055],\n",
    "   'accuracy': [0.00507500022649765,\n",
    "    0.005162499845027924,\n",
    "    0.0053125000558793545,\n",
    "    0.005675000138580799,\n",
    "    0.005412499886006117,\n",
    "    0.005750000011175871,\n",
    "    0.005987499840557575,\n",
    "    0.006300000008195639,\n",
    "    0.005900000222027302,\n",
    "    0.006387500092387199,\n",
    "    0.0057875001803040504],\n",
    "   'val_loss': [5.576487064361572,\n",
    "    5.577495098114014,\n",
    "    5.567077159881592,\n",
    "    5.5725908279418945,\n",
    "    5.581059455871582,\n",
    "    5.597627639770508,\n",
    "    5.622756481170654,\n",
    "    5.612503528594971,\n",
    "    5.643679141998291,\n",
    "    5.650357246398926,\n",
    "    5.659717559814453],\n",
    "   'val_accuracy': [0.005549999885261059,\n",
    "    0.006149999797344208,\n",
    "    0.006399999838322401,\n",
    "    0.006399999838322401,\n",
    "    0.006750000175088644,\n",
    "    0.006949999835342169,\n",
    "    0.006800000090152025,\n",
    "    0.007400000002235174,\n",
    "    0.007350000087171793,\n",
    "    0.0066999997943639755,\n",
    "    0.006800000090152025]}},\n",
    " {'1e-06 1024': {'loss': [6.386002063751221,\n",
    "    6.364927291870117,\n",
    "    6.336163520812988,\n",
    "    6.31344747543335,\n",
    "    6.293752670288086,\n",
    "    6.268531322479248,\n",
    "    6.23527717590332,\n",
    "    6.210179328918457,\n",
    "    6.194598197937012,\n",
    "    6.170181751251221,\n",
    "    6.145379543304443,\n",
    "    6.121821880340576,\n",
    "    6.095661640167236,\n",
    "    6.0733323097229],\n",
    "   'accuracy': [0.004987500142306089,\n",
    "    0.005100000184029341,\n",
    "    0.00559999980032444,\n",
    "    0.00572500005364418,\n",
    "    0.005137499887496233,\n",
    "    0.005912499967962503,\n",
    "    0.006124999839812517,\n",
    "    0.006162500008940697,\n",
    "    0.006137500051409006,\n",
    "    0.005737499799579382,\n",
    "    0.006262499839067459,\n",
    "    0.006187499966472387,\n",
    "    0.006612500175833702,\n",
    "    0.006887500174343586],\n",
    "   'val_loss': [5.535607814788818,\n",
    "    5.525020122528076,\n",
    "    5.51685905456543,\n",
    "    5.512446880340576,\n",
    "    5.509700775146484,\n",
    "    5.518462181091309,\n",
    "    5.518831729888916,\n",
    "    5.527840614318848,\n",
    "    5.520087718963623,\n",
    "    5.5228424072265625,\n",
    "    5.524868011474609,\n",
    "    5.524053573608398,\n",
    "    5.531241416931152,\n",
    "    5.524345874786377],\n",
    "   'val_accuracy': [0.005100000184029341,\n",
    "    0.004800000227987766,\n",
    "    0.005499999970197678,\n",
    "    0.005549999885261059,\n",
    "    0.0056500001810491085,\n",
    "    0.005799999926239252,\n",
    "    0.005950000137090683,\n",
    "    0.006200000178068876,\n",
    "    0.005950000137090683,\n",
    "    0.0056500001810491085,\n",
    "    0.005849999841302633,\n",
    "    0.005900000222027302,\n",
    "    0.005950000137090683,\n",
    "    0.006949999835342169]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "140abe42-0928-4c42-b64d-0dbb4f74d950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0.001 64': {'loss': [5.380972862243652,\n",
       "    4.88289213180542,\n",
       "    4.59045934677124,\n",
       "    4.402263641357422,\n",
       "    4.270577907562256,\n",
       "    4.161617755889893,\n",
       "    4.0691728591918945,\n",
       "    3.9810867309570312,\n",
       "    3.9025256633758545,\n",
       "    3.818938732147217,\n",
       "    3.753160238265991,\n",
       "    3.69100284576416,\n",
       "    3.631304979324341,\n",
       "    3.5823192596435547,\n",
       "    3.5368168354034424,\n",
       "    3.482234477996826,\n",
       "    3.4457242488861084,\n",
       "    3.398023843765259,\n",
       "    3.3656530380249023,\n",
       "    3.337454319000244,\n",
       "    3.3048651218414307,\n",
       "    3.274305820465088,\n",
       "    3.243847131729126,\n",
       "    3.2164480686187744,\n",
       "    3.194758892059326,\n",
       "    3.1663668155670166,\n",
       "    3.1440253257751465,\n",
       "    3.120410919189453,\n",
       "    3.1022531986236572,\n",
       "    3.084674835205078,\n",
       "    3.0618607997894287,\n",
       "    3.0420565605163574,\n",
       "    3.026094436645508,\n",
       "    3.013417959213257,\n",
       "    2.9940083026885986,\n",
       "    2.978736639022827,\n",
       "    2.962615489959717,\n",
       "    2.9524595737457275,\n",
       "    2.933278799057007,\n",
       "    2.921670913696289,\n",
       "    2.9037067890167236,\n",
       "    2.8881051540374756,\n",
       "    2.8793790340423584,\n",
       "    2.869946241378784,\n",
       "    2.8450393676757812,\n",
       "    2.84320330619812,\n",
       "    2.8290092945098877,\n",
       "    2.819101095199585,\n",
       "    2.8135299682617188,\n",
       "    2.800690174102783,\n",
       "    2.786313772201538],\n",
       "   'accuracy': [0.014050000347197056,\n",
       "    0.0356375016272068,\n",
       "    0.06199999898672104,\n",
       "    0.08322499692440033,\n",
       "    0.09948749840259552,\n",
       "    0.11368750035762787,\n",
       "    0.1269875019788742,\n",
       "    0.13932499289512634,\n",
       "    0.1509000062942505,\n",
       "    0.16362500190734863,\n",
       "    0.1735374927520752,\n",
       "    0.18277500569820404,\n",
       "    0.1933249980211258,\n",
       "    0.20071250200271606,\n",
       "    0.20909999310970306,\n",
       "    0.21722500026226044,\n",
       "    0.2225874960422516,\n",
       "    0.23074999451637268,\n",
       "    0.2375749945640564,\n",
       "    0.24185000360012054,\n",
       "    0.2462249994277954,\n",
       "    0.25485000014305115,\n",
       "    0.2577250003814697,\n",
       "    0.2642875015735626,\n",
       "    0.26643750071525574,\n",
       "    0.27227500081062317,\n",
       "    0.27668750286102295,\n",
       "    0.28107500076293945,\n",
       "    0.28417500853538513,\n",
       "    0.2877500057220459,\n",
       "    0.2925125062465668,\n",
       "    0.2947250008583069,\n",
       "    0.2974500060081482,\n",
       "    0.30018749833106995,\n",
       "    0.3014124929904938,\n",
       "    0.3070499897003174,\n",
       "    0.3094500005245209,\n",
       "    0.31363749504089355,\n",
       "    0.3161875009536743,\n",
       "    0.3155125081539154,\n",
       "    0.3220750093460083,\n",
       "    0.32276248931884766,\n",
       "    0.3248875141143799,\n",
       "    0.3268125057220459,\n",
       "    0.3328624963760376,\n",
       "    0.33003750443458557,\n",
       "    0.3340874910354614,\n",
       "    0.3365125060081482,\n",
       "    0.3371250033378601,\n",
       "    0.34007498621940613,\n",
       "    0.34437501430511475],\n",
       "   'val_loss': [4.998109340667725,\n",
       "    4.626512050628662,\n",
       "    4.685070514678955,\n",
       "    4.469832420349121,\n",
       "    4.603459358215332,\n",
       "    4.5693840980529785,\n",
       "    4.4600830078125,\n",
       "    4.491162300109863,\n",
       "    4.238203525543213,\n",
       "    4.522250175476074,\n",
       "    4.304540157318115,\n",
       "    3.955239772796631,\n",
       "    4.292548656463623,\n",
       "    4.220411777496338,\n",
       "    4.31406831741333,\n",
       "    3.7115683555603027,\n",
       "    4.092424392700195,\n",
       "    3.7309703826904297,\n",
       "    3.7967007160186768,\n",
       "    3.5147335529327393,\n",
       "    3.6226963996887207,\n",
       "    3.6616389751434326,\n",
       "    3.64664888381958,\n",
       "    3.688899517059326,\n",
       "    3.912198543548584,\n",
       "    3.57243013381958,\n",
       "    3.596893072128296,\n",
       "    3.970215320587158,\n",
       "    3.4958086013793945,\n",
       "    3.5953707695007324,\n",
       "    3.855001926422119,\n",
       "    3.9466819763183594,\n",
       "    3.749704599380493,\n",
       "    3.5355544090270996,\n",
       "    3.5787007808685303,\n",
       "    3.6151959896087646,\n",
       "    3.6805686950683594,\n",
       "    3.4542672634124756,\n",
       "    3.3811960220336914,\n",
       "    3.5760698318481445,\n",
       "    3.299720287322998,\n",
       "    3.5418739318847656,\n",
       "    3.4775071144104004,\n",
       "    3.746504783630371,\n",
       "    3.589543342590332,\n",
       "    3.327893018722534,\n",
       "    3.4535012245178223,\n",
       "    3.4636528491973877,\n",
       "    3.57951283454895,\n",
       "    3.524543285369873,\n",
       "    3.389202833175659],\n",
       "   'val_accuracy': [0.02604999952018261,\n",
       "    0.05974999815225601,\n",
       "    0.05764999985694885,\n",
       "    0.08015000075101852,\n",
       "    0.07705000042915344,\n",
       "    0.07840000092983246,\n",
       "    0.10189999639987946,\n",
       "    0.09489999711513519,\n",
       "    0.11954999715089798,\n",
       "    0.10814999788999557,\n",
       "    0.11980000138282776,\n",
       "    0.15360000729560852,\n",
       "    0.12620000541210175,\n",
       "    0.13529999554157257,\n",
       "    0.12964999675750732,\n",
       "    0.1902499943971634,\n",
       "    0.1449500024318695,\n",
       "    0.19345000386238098,\n",
       "    0.1785999983549118,\n",
       "    0.2198999971151352,\n",
       "    0.20100000500679016,\n",
       "    0.20080000162124634,\n",
       "    0.2054000049829483,\n",
       "    0.20489999651908875,\n",
       "    0.1720999926328659,\n",
       "    0.21389999985694885,\n",
       "    0.2134999930858612,\n",
       "    0.1679999977350235,\n",
       "    0.2301499992609024,\n",
       "    0.21539999544620514,\n",
       "    0.1890999972820282,\n",
       "    0.17704999446868896,\n",
       "    0.19840000569820404,\n",
       "    0.22210000455379486,\n",
       "    0.2138500064611435,\n",
       "    0.21490000188350677,\n",
       "    0.2101999968290329,\n",
       "    0.24199999868869781,\n",
       "    0.2479500025510788,\n",
       "    0.22235000133514404,\n",
       "    0.25964999198913574,\n",
       "    0.22095000743865967,\n",
       "    0.23389999568462372,\n",
       "    0.20595000684261322,\n",
       "    0.22769999504089355,\n",
       "    0.25769999623298645,\n",
       "    0.24365000426769257,\n",
       "    0.23855000734329224,\n",
       "    0.22939999401569366,\n",
       "    0.23614999651908875,\n",
       "    0.2468000054359436]}},\n",
       " {'0.001 128': {'loss': [5.398235321044922,\n",
       "    4.929057598114014,\n",
       "    4.665840148925781,\n",
       "    4.4579572677612305,\n",
       "    4.279703140258789,\n",
       "    4.1497368812561035,\n",
       "    4.040450572967529,\n",
       "    3.9445407390594482,\n",
       "    3.8555238246917725,\n",
       "    3.7789437770843506,\n",
       "    3.7030932903289795,\n",
       "    3.643432378768921,\n",
       "    3.5916762351989746,\n",
       "    3.5409820079803467,\n",
       "    3.4997975826263428,\n",
       "    3.456397771835327,\n",
       "    3.4179797172546387,\n",
       "    3.384612798690796,\n",
       "    3.3581230640411377,\n",
       "    3.325962543487549,\n",
       "    3.2980382442474365,\n",
       "    3.2698280811309814,\n",
       "    3.2454450130462646,\n",
       "    3.221140146255493,\n",
       "    3.209409475326538,\n",
       "    3.1760811805725098,\n",
       "    3.1604702472686768,\n",
       "    3.1363110542297363,\n",
       "    3.121663808822632,\n",
       "    3.1028053760528564,\n",
       "    3.0830276012420654,\n",
       "    3.0703465938568115,\n",
       "    3.054239273071289,\n",
       "    3.036747932434082,\n",
       "    3.0256943702697754,\n",
       "    2.999448776245117],\n",
       "   'accuracy': [0.013650000095367432,\n",
       "    0.035374999046325684,\n",
       "    0.05810000002384186,\n",
       "    0.07986249774694443,\n",
       "    0.10311249643564224,\n",
       "    0.12060000002384186,\n",
       "    0.1336749941110611,\n",
       "    0.14765000343322754,\n",
       "    0.15992499887943268,\n",
       "    0.17326250672340393,\n",
       "    0.1845874935388565,\n",
       "    0.19189999997615814,\n",
       "    0.20237499475479126,\n",
       "    0.21074999868869781,\n",
       "    0.21613749861717224,\n",
       "    0.22378750145435333,\n",
       "    0.2296375036239624,\n",
       "    0.23483750224113464,\n",
       "    0.23951250314712524,\n",
       "    0.24683749675750732,\n",
       "    0.24992500245571136,\n",
       "    0.2565250098705292,\n",
       "    0.26054999232292175,\n",
       "    0.26368749141693115,\n",
       "    0.26618748903274536,\n",
       "    0.27111250162124634,\n",
       "    0.27408748865127563,\n",
       "    0.28001248836517334,\n",
       "    0.283112496137619,\n",
       "    0.2867625057697296,\n",
       "    0.28923749923706055,\n",
       "    0.28975000977516174,\n",
       "    0.2943499982357025,\n",
       "    0.2967750132083893,\n",
       "    0.2968375086784363,\n",
       "    0.303912490606308],\n",
       "   'val_loss': [5.336450576782227,\n",
       "    5.185443878173828,\n",
       "    4.77726411819458,\n",
       "    4.383225917816162,\n",
       "    4.294454097747803,\n",
       "    4.185427188873291,\n",
       "    4.131650924682617,\n",
       "    4.0677924156188965,\n",
       "    3.7311596870422363,\n",
       "    3.9122190475463867,\n",
       "    3.7389543056488037,\n",
       "    3.5440473556518555,\n",
       "    3.7979061603546143,\n",
       "    3.6554551124572754,\n",
       "    3.7371511459350586,\n",
       "    3.8949050903320312,\n",
       "    3.744931936264038,\n",
       "    3.5023820400238037,\n",
       "    3.601569175720215,\n",
       "    3.7563929557800293,\n",
       "    3.559474229812622,\n",
       "    4.084846019744873,\n",
       "    3.6438913345336914,\n",
       "    3.562164783477783,\n",
       "    3.631662607192993,\n",
       "    3.364089012145996,\n",
       "    3.4835281372070312,\n",
       "    3.419027328491211,\n",
       "    3.5625598430633545,\n",
       "    3.6389360427856445,\n",
       "    3.3570010662078857,\n",
       "    3.3840508460998535,\n",
       "    3.603421449661255,\n",
       "    3.5824172496795654,\n",
       "    3.3887062072753906,\n",
       "    3.687533140182495],\n",
       "   'val_accuracy': [0.023649999871850014,\n",
       "    0.03739999979734421,\n",
       "    0.05339999869465828,\n",
       "    0.09560000151395798,\n",
       "    0.1006999984383583,\n",
       "    0.1177000030875206,\n",
       "    0.1262499988079071,\n",
       "    0.13725000619888306,\n",
       "    0.1821500062942505,\n",
       "    0.16304999589920044,\n",
       "    0.1834000051021576,\n",
       "    0.21130000054836273,\n",
       "    0.17509999871253967,\n",
       "    0.195250004529953,\n",
       "    0.187049999833107,\n",
       "    0.16854999959468842,\n",
       "    0.1890999972820282,\n",
       "    0.22040000557899475,\n",
       "    0.2101999968290329,\n",
       "    0.18719999492168427,\n",
       "    0.21205000579357147,\n",
       "    0.15925000607967377,\n",
       "    0.20284999907016754,\n",
       "    0.21185000240802765,\n",
       "    0.20479999482631683,\n",
       "    0.24025000631809235,\n",
       "    0.22759999334812164,\n",
       "    0.23559999465942383,\n",
       "    0.2184000015258789,\n",
       "    0.20469999313354492,\n",
       "    0.2479500025510788,\n",
       "    0.24089999496936798,\n",
       "    0.2167000025510788,\n",
       "    0.22059999406337738,\n",
       "    0.24410000443458557,\n",
       "    0.20915000140666962]}},\n",
       " {'0.001 256': {'loss': [5.41646671295166,\n",
       "    4.965508937835693,\n",
       "    4.681892395019531,\n",
       "    4.445862770080566,\n",
       "    4.280278205871582,\n",
       "    4.164406776428223,\n",
       "    4.070413589477539,\n",
       "    3.979759454727173,\n",
       "    3.9032516479492188,\n",
       "    3.8317174911499023,\n",
       "    3.7660350799560547,\n",
       "    3.6987922191619873,\n",
       "    3.640148162841797,\n",
       "    3.588186740875244,\n",
       "    3.545795202255249,\n",
       "    3.503152847290039,\n",
       "    3.4601101875305176,\n",
       "    3.416248321533203,\n",
       "    3.3857405185699463,\n",
       "    3.3523733615875244,\n",
       "    3.3214097023010254,\n",
       "    3.2915585041046143,\n",
       "    3.2643768787384033,\n",
       "    3.23797869682312,\n",
       "    3.213845729827881,\n",
       "    3.1892921924591064,\n",
       "    3.172537326812744,\n",
       "    3.1481356620788574,\n",
       "    3.1219472885131836,\n",
       "    3.1049628257751465,\n",
       "    3.0851800441741943,\n",
       "    3.0678939819335938],\n",
       "   'accuracy': [0.012199999764561653,\n",
       "    0.030637500807642937,\n",
       "    0.05511249974370003,\n",
       "    0.08034999668598175,\n",
       "    0.10257499665021896,\n",
       "    0.1174750030040741,\n",
       "    0.13042500615119934,\n",
       "    0.14362500607967377,\n",
       "    0.1529500037431717,\n",
       "    0.16382500529289246,\n",
       "    0.1728000044822693,\n",
       "    0.1844875067472458,\n",
       "    0.19212499260902405,\n",
       "    0.20257499814033508,\n",
       "    0.20698750019073486,\n",
       "    0.21318750083446503,\n",
       "    0.22338749468326569,\n",
       "    0.23016250133514404,\n",
       "    0.23276250064373016,\n",
       "    0.24070000648498535,\n",
       "    0.2459374964237213,\n",
       "    0.2526625096797943,\n",
       "    0.25731250643730164,\n",
       "    0.2614625096321106,\n",
       "    0.26676249504089355,\n",
       "    0.2705000042915344,\n",
       "    0.272350013256073,\n",
       "    0.2767125070095062,\n",
       "    0.28126248717308044,\n",
       "    0.2832624912261963,\n",
       "    0.28692498803138733,\n",
       "    0.29391250014305115],\n",
       "   'val_loss': [5.167325973510742,\n",
       "    4.861729621887207,\n",
       "    4.617612838745117,\n",
       "    4.744391918182373,\n",
       "    4.786172389984131,\n",
       "    4.465488910675049,\n",
       "    4.521059513092041,\n",
       "    4.220287322998047,\n",
       "    4.375972747802734,\n",
       "    4.5542707443237305,\n",
       "    3.968606948852539,\n",
       "    4.111158847808838,\n",
       "    4.059375762939453,\n",
       "    3.9070608615875244,\n",
       "    3.764113187789917,\n",
       "    4.350565433502197,\n",
       "    3.9265449047088623,\n",
       "    4.073580741882324,\n",
       "    3.8039441108703613,\n",
       "    3.923696517944336,\n",
       "    3.927260637283325,\n",
       "    3.621936798095703,\n",
       "    3.8098859786987305,\n",
       "    3.7892098426818848,\n",
       "    3.6890077590942383,\n",
       "    3.828418016433716,\n",
       "    3.634707450866699,\n",
       "    3.886996030807495,\n",
       "    3.674081325531006,\n",
       "    3.687849998474121,\n",
       "    3.6345415115356445,\n",
       "    3.89713978767395],\n",
       "   'val_accuracy': [0.021549999713897705,\n",
       "    0.04565000161528587,\n",
       "    0.06679999828338623,\n",
       "    0.06584999710321426,\n",
       "    0.0697999969124794,\n",
       "    0.0957999974489212,\n",
       "    0.09440000355243683,\n",
       "    0.12250000238418579,\n",
       "    0.11294999718666077,\n",
       "    0.10339999943971634,\n",
       "    0.15139999985694885,\n",
       "    0.1395999938249588,\n",
       "    0.14695000648498535,\n",
       "    0.16095000505447388,\n",
       "    0.1829500049352646,\n",
       "    0.1277499943971634,\n",
       "    0.16664999723434448,\n",
       "    0.15444999933242798,\n",
       "    0.17919999361038208,\n",
       "    0.16965000331401825,\n",
       "    0.18129999935626984,\n",
       "    0.20685000717639923,\n",
       "    0.1858000010251999,\n",
       "    0.18684999644756317,\n",
       "    0.2048500031232834,\n",
       "    0.1899999976158142,\n",
       "    0.20634999871253967,\n",
       "    0.1814499944448471,\n",
       "    0.21085000038146973,\n",
       "    0.20479999482631683,\n",
       "    0.21199999749660492,\n",
       "    0.17990000545978546]}},\n",
       " {'0.001 512': {'loss': [5.425540447235107,\n",
       "    4.972785472869873,\n",
       "    4.747498035430908,\n",
       "    4.5916595458984375,\n",
       "    4.42104434967041,\n",
       "    4.252651691436768,\n",
       "    4.142390251159668,\n",
       "    4.037528991699219,\n",
       "    3.951474905014038,\n",
       "    3.866628885269165,\n",
       "    3.7965164184570312,\n",
       "    3.734131336212158,\n",
       "    3.6655397415161133,\n",
       "    3.6112301349639893,\n",
       "    3.561716079711914,\n",
       "    3.5161664485931396,\n",
       "    3.472609043121338,\n",
       "    3.4430930614471436,\n",
       "    3.4037833213806152,\n",
       "    3.367410182952881,\n",
       "    3.3401925563812256,\n",
       "    3.307070732116699,\n",
       "    3.2812395095825195,\n",
       "    3.2633724212646484,\n",
       "    3.2378435134887695,\n",
       "    3.2084810733795166,\n",
       "    3.191025733947754,\n",
       "    3.167804479598999,\n",
       "    3.147981882095337,\n",
       "    3.1305294036865234,\n",
       "    3.1090545654296875,\n",
       "    3.092212200164795,\n",
       "    3.080221652984619,\n",
       "    3.061870813369751,\n",
       "    3.0446791648864746,\n",
       "    3.025101900100708,\n",
       "    3.0141050815582275,\n",
       "    2.997021198272705,\n",
       "    2.9907093048095703,\n",
       "    2.9698522090911865],\n",
       "   'accuracy': [0.012612500227987766,\n",
       "    0.028075000271201134,\n",
       "    0.047212500125169754,\n",
       "    0.06651250272989273,\n",
       "    0.08612500131130219,\n",
       "    0.10700000077486038,\n",
       "    0.12222500145435333,\n",
       "    0.1353124976158142,\n",
       "    0.14506250619888306,\n",
       "    0.15853750705718994,\n",
       "    0.16893750429153442,\n",
       "    0.17803749442100525,\n",
       "    0.18816250562667847,\n",
       "    0.19821250438690186,\n",
       "    0.20526249706745148,\n",
       "    0.2122499942779541,\n",
       "    0.22072499990463257,\n",
       "    0.2256374955177307,\n",
       "    0.23383750021457672,\n",
       "    0.23852500319480896,\n",
       "    0.2434999942779541,\n",
       "    0.24793750047683716,\n",
       "    0.25270000100135803,\n",
       "    0.2563624978065491,\n",
       "    0.26071250438690186,\n",
       "    0.26656249165534973,\n",
       "    0.26903748512268066,\n",
       "    0.273312509059906,\n",
       "    0.27576249837875366,\n",
       "    0.27605000138282776,\n",
       "    0.2820124924182892,\n",
       "    0.2860499918460846,\n",
       "    0.2892250120639801,\n",
       "    0.2916249930858612,\n",
       "    0.2951749861240387,\n",
       "    0.29813748598098755,\n",
       "    0.3014875054359436,\n",
       "    0.3044374883174896,\n",
       "    0.30541250109672546,\n",
       "    0.30959999561309814],\n",
       "   'val_loss': [5.104207992553711,\n",
       "    4.9171953201293945,\n",
       "    4.605762004852295,\n",
       "    4.560888767242432,\n",
       "    4.385295867919922,\n",
       "    4.4329118728637695,\n",
       "    4.401804447174072,\n",
       "    4.1764631271362305,\n",
       "    4.1465277671813965,\n",
       "    4.135563850402832,\n",
       "    4.088298320770264,\n",
       "    4.12937593460083,\n",
       "    4.020236492156982,\n",
       "    3.9311118125915527,\n",
       "    3.8753793239593506,\n",
       "    3.911860466003418,\n",
       "    3.882169485092163,\n",
       "    3.6205499172210693,\n",
       "    3.7780096530914307,\n",
       "    4.190998554229736,\n",
       "    3.8558743000030518,\n",
       "    3.7247543334960938,\n",
       "    3.839735507965088,\n",
       "    3.969674587249756,\n",
       "    3.9030725955963135,\n",
       "    3.586792469024658,\n",
       "    3.6394999027252197,\n",
       "    4.1039605140686035,\n",
       "    3.8206582069396973,\n",
       "    3.5762953758239746,\n",
       "    3.861940622329712,\n",
       "    4.071001052856445,\n",
       "    3.7340426445007324,\n",
       "    3.964594841003418,\n",
       "    3.797785520553589,\n",
       "    3.645781993865967,\n",
       "    3.8786609172821045,\n",
       "    3.9132590293884277,\n",
       "    3.825976610183716,\n",
       "    3.9830949306488037],\n",
       "   'val_accuracy': [0.021700000390410423,\n",
       "    0.03465000167489052,\n",
       "    0.06735000014305115,\n",
       "    0.07164999842643738,\n",
       "    0.09849999845027924,\n",
       "    0.09719999879598618,\n",
       "    0.10540000349283218,\n",
       "    0.12635000050067902,\n",
       "    0.1298000067472458,\n",
       "    0.13324999809265137,\n",
       "    0.13660000264644623,\n",
       "    0.13740000128746033,\n",
       "    0.15000000596046448,\n",
       "    0.16214999556541443,\n",
       "    0.16619999706745148,\n",
       "    0.16664999723434448,\n",
       "    0.1664000004529953,\n",
       "    0.19869999587535858,\n",
       "    0.18639999628067017,\n",
       "    0.14374999701976776,\n",
       "    0.17685000598430634,\n",
       "    0.19404999911785126,\n",
       "    0.1764499992132187,\n",
       "    0.16824999451637268,\n",
       "    0.18019999563694,\n",
       "    0.21615000069141388,\n",
       "    0.20765000581741333,\n",
       "    0.16175000369548798,\n",
       "    0.18539999425411224,\n",
       "    0.21809999644756317,\n",
       "    0.18559999763965607,\n",
       "    0.16455000638961792,\n",
       "    0.1972000002861023,\n",
       "    0.18410000205039978,\n",
       "    0.18764999508857727,\n",
       "    0.21699999272823334,\n",
       "    0.18925000727176666,\n",
       "    0.18205000460147858,\n",
       "    0.19505000114440918,\n",
       "    0.17925000190734863]}},\n",
       " {'0.001 1024': {'loss': [5.4175848960876465,\n",
       "    4.965285778045654,\n",
       "    4.7500176429748535,\n",
       "    4.573967456817627,\n",
       "    4.371896266937256,\n",
       "    4.233785152435303,\n",
       "    4.13319206237793,\n",
       "    4.038333415985107,\n",
       "    3.9549448490142822,\n",
       "    3.8773012161254883,\n",
       "    3.8130812644958496,\n",
       "    3.7536051273345947,\n",
       "    3.690673828125,\n",
       "    3.6381359100341797,\n",
       "    3.5863616466522217,\n",
       "    3.5468008518218994,\n",
       "    3.5069851875305176,\n",
       "    3.4628617763519287,\n",
       "    3.423189401626587,\n",
       "    3.3934688568115234,\n",
       "    3.359309673309326,\n",
       "    3.326706647872925,\n",
       "    3.295933485031128,\n",
       "    3.2754404544830322,\n",
       "    3.249460458755493,\n",
       "    3.2246854305267334,\n",
       "    3.2024621963500977,\n",
       "    3.1792452335357666,\n",
       "    3.157184362411499,\n",
       "    3.1373322010040283,\n",
       "    3.115111827850342,\n",
       "    3.104977607727051,\n",
       "    3.077868938446045,\n",
       "    3.0615055561065674,\n",
       "    3.045233726501465,\n",
       "    3.025437593460083,\n",
       "    3.0141243934631348,\n",
       "    2.9999120235443115,\n",
       "    2.988591432571411,\n",
       "    2.97119402885437,\n",
       "    2.9606311321258545,\n",
       "    2.9425368309020996,\n",
       "    2.929497480392456,\n",
       "    2.9173474311828613,\n",
       "    2.9076476097106934,\n",
       "    2.8913228511810303,\n",
       "    2.883925199508667,\n",
       "    2.8723132610321045,\n",
       "    2.857321262359619],\n",
       "   'accuracy': [0.011887500062584877,\n",
       "    0.02968749962747097,\n",
       "    0.048112500458955765,\n",
       "    0.06724999845027924,\n",
       "    0.09184999763965607,\n",
       "    0.10696250200271606,\n",
       "    0.12177500128746033,\n",
       "    0.13394999504089355,\n",
       "    0.14591249823570251,\n",
       "    0.15672500431537628,\n",
       "    0.16584999859333038,\n",
       "    0.17317500710487366,\n",
       "    0.1858375072479248,\n",
       "    0.1938374936580658,\n",
       "    0.20194999873638153,\n",
       "    0.20971250534057617,\n",
       "    0.21559999883174896,\n",
       "    0.22175000607967377,\n",
       "    0.2280375063419342,\n",
       "    0.2356874942779541,\n",
       "    0.23951250314712524,\n",
       "    0.24504999816417694,\n",
       "    0.24921250343322754,\n",
       "    0.25373750925064087,\n",
       "    0.25942501425743103,\n",
       "    0.26202499866485596,\n",
       "    0.2661125063896179,\n",
       "    0.27201250195503235,\n",
       "    0.27639999985694885,\n",
       "    0.2786000072956085,\n",
       "    0.28380000591278076,\n",
       "    0.28511250019073486,\n",
       "    0.2891624867916107,\n",
       "    0.2902125120162964,\n",
       "    0.2942875027656555,\n",
       "    0.2986375093460083,\n",
       "    0.30149999260902405,\n",
       "    0.30344998836517334,\n",
       "    0.30576249957084656,\n",
       "    0.3084374964237213,\n",
       "    0.31126248836517334,\n",
       "    0.3146499991416931,\n",
       "    0.31683748960494995,\n",
       "    0.31898748874664307,\n",
       "    0.32077500224113464,\n",
       "    0.32276248931884766,\n",
       "    0.32374998927116394,\n",
       "    0.32788750529289246,\n",
       "    0.32942500710487366],\n",
       "   'val_loss': [4.997028350830078,\n",
       "    4.809463024139404,\n",
       "    4.646267414093018,\n",
       "    4.513217926025391,\n",
       "    4.249942779541016,\n",
       "    4.532133102416992,\n",
       "    4.366448879241943,\n",
       "    4.6031012535095215,\n",
       "    4.145541667938232,\n",
       "    4.047222137451172,\n",
       "    3.7811856269836426,\n",
       "    3.975999593734741,\n",
       "    4.023699760437012,\n",
       "    4.22852087020874,\n",
       "    3.853475332260132,\n",
       "    3.855295419692993,\n",
       "    3.719769239425659,\n",
       "    3.838487386703491,\n",
       "    3.7486038208007812,\n",
       "    4.127103328704834,\n",
       "    3.804311752319336,\n",
       "    3.852501630783081,\n",
       "    3.701923131942749,\n",
       "    3.6806910037994385,\n",
       "    3.6834464073181152,\n",
       "    3.974796772003174,\n",
       "    3.7511661052703857,\n",
       "    3.6554758548736572,\n",
       "    3.516702651977539,\n",
       "    3.864788770675659,\n",
       "    3.4832234382629395,\n",
       "    3.89087176322937,\n",
       "    3.64274263381958,\n",
       "    3.65311336517334,\n",
       "    3.6276304721832275,\n",
       "    3.678154230117798,\n",
       "    3.684835910797119,\n",
       "    3.616126537322998,\n",
       "    3.3634612560272217,\n",
       "    3.4490511417388916,\n",
       "    3.712157726287842,\n",
       "    3.754551649093628,\n",
       "    3.4329581260681152,\n",
       "    3.619537115097046,\n",
       "    3.4735429286956787,\n",
       "    3.795548439025879,\n",
       "    3.7407116889953613,\n",
       "    3.5187971591949463,\n",
       "    3.3811299800872803],\n",
       "   'val_accuracy': [0.030150000005960464,\n",
       "    0.045049998909235,\n",
       "    0.06509999930858612,\n",
       "    0.07989999651908875,\n",
       "    0.10980000346899033,\n",
       "    0.0917000025510788,\n",
       "    0.1014999970793724,\n",
       "    0.0872500017285347,\n",
       "    0.1269499957561493,\n",
       "    0.13950000703334808,\n",
       "    0.17180000245571136,\n",
       "    0.15029999613761902,\n",
       "    0.14480000734329224,\n",
       "    0.12794999778270721,\n",
       "    0.16335000097751617,\n",
       "    0.16384999454021454,\n",
       "    0.18799999356269836,\n",
       "    0.17634999752044678,\n",
       "    0.18725000321865082,\n",
       "    0.14444999396800995,\n",
       "    0.17865000665187836,\n",
       "    0.17579999566078186,\n",
       "    0.1941000074148178,\n",
       "    0.1967500001192093,\n",
       "    0.19814999401569366,\n",
       "    0.17204999923706055,\n",
       "    0.19300000369548798,\n",
       "    0.2053000032901764,\n",
       "    0.22014999389648438,\n",
       "    0.18529999256134033,\n",
       "    0.23229999840259552,\n",
       "    0.18170000612735748,\n",
       "    0.20960000157356262,\n",
       "    0.2113499939441681,\n",
       "    0.21344999969005585,\n",
       "    0.2134000062942505,\n",
       "    0.20200000703334808,\n",
       "    0.21915000677108765,\n",
       "    0.2505500018596649,\n",
       "    0.23964999616146088,\n",
       "    0.2069000005722046,\n",
       "    0.19939999282360077,\n",
       "    0.24390000104904175,\n",
       "    0.2214999943971634,\n",
       "    0.24060000479221344,\n",
       "    0.2037999927997589,\n",
       "    0.20569999516010284,\n",
       "    0.2345000058412552,\n",
       "    0.25049999356269836]}},\n",
       " {'0.0001 64': {'loss': [5.6755571365356445,\n",
       "    5.2651801109313965,\n",
       "    5.024635314941406,\n",
       "    4.8296380043029785,\n",
       "    4.645527362823486,\n",
       "    4.494906425476074,\n",
       "    4.372969627380371,\n",
       "    4.251951217651367,\n",
       "    4.1576151847839355,\n",
       "    4.0735883712768555,\n",
       "    3.993648052215576,\n",
       "    3.917069911956787,\n",
       "    3.8664674758911133,\n",
       "    3.8050196170806885,\n",
       "    3.7532925605773926,\n",
       "    3.7018120288848877,\n",
       "    3.656303882598877,\n",
       "    3.6209840774536133,\n",
       "    3.5795187950134277,\n",
       "    3.5299227237701416,\n",
       "    3.4985604286193848,\n",
       "    3.468120813369751,\n",
       "    3.4218266010284424,\n",
       "    3.397037982940674,\n",
       "    3.367960214614868,\n",
       "    3.338864803314209,\n",
       "    3.308605194091797,\n",
       "    3.284505844116211,\n",
       "    3.2590014934539795,\n",
       "    3.2342846393585205,\n",
       "    3.2097599506378174,\n",
       "    3.1895458698272705,\n",
       "    3.1672401428222656,\n",
       "    3.145247459411621,\n",
       "    3.123673439025879,\n",
       "    3.1046605110168457,\n",
       "    3.0885348320007324,\n",
       "    3.071380376815796,\n",
       "    3.04931902885437,\n",
       "    3.0347132682800293,\n",
       "    3.0198097229003906,\n",
       "    3.004102945327759],\n",
       "   'accuracy': [0.010824999772012234,\n",
       "    0.022462500259280205,\n",
       "    0.03421249985694885,\n",
       "    0.05034999921917915,\n",
       "    0.06511250138282776,\n",
       "    0.08043749630451202,\n",
       "    0.09438750147819519,\n",
       "    0.10757499933242798,\n",
       "    0.12018749862909317,\n",
       "    0.13407500088214874,\n",
       "    0.14281250536441803,\n",
       "    0.15324999392032623,\n",
       "    0.16118749976158142,\n",
       "    0.17135000228881836,\n",
       "    0.17848749458789825,\n",
       "    0.18643750250339508,\n",
       "    0.19203749299049377,\n",
       "    0.1992875039577484,\n",
       "    0.2054000049829483,\n",
       "    0.2126999944448471,\n",
       "    0.21906250715255737,\n",
       "    0.22317500412464142,\n",
       "    0.23223750293254852,\n",
       "    0.234375,\n",
       "    0.24086250364780426,\n",
       "    0.24638749659061432,\n",
       "    0.2524000108242035,\n",
       "    0.2548624873161316,\n",
       "    0.259737491607666,\n",
       "    0.2637999951839447,\n",
       "    0.26641249656677246,\n",
       "    0.27131250500679016,\n",
       "    0.27623748779296875,\n",
       "    0.27978751063346863,\n",
       "    0.28347501158714294,\n",
       "    0.28654998540878296,\n",
       "    0.2879999876022339,\n",
       "    0.29155001044273376,\n",
       "    0.29676249623298645,\n",
       "    0.30147498846054077,\n",
       "    0.3025999963283539,\n",
       "    0.3063249886035919],\n",
       "   'val_loss': [5.424478054046631,\n",
       "    5.115505695343018,\n",
       "    5.1067795753479,\n",
       "    5.555928707122803,\n",
       "    5.489780902862549,\n",
       "    5.5496416091918945,\n",
       "    5.074118137359619,\n",
       "    4.880539894104004,\n",
       "    4.663767337799072,\n",
       "    4.342531681060791,\n",
       "    4.615381240844727,\n",
       "    4.551671028137207,\n",
       "    4.238384246826172,\n",
       "    4.503440856933594,\n",
       "    4.26278829574585,\n",
       "    4.18805456161499,\n",
       "    4.3090338706970215,\n",
       "    4.238126754760742,\n",
       "    3.9927196502685547,\n",
       "    4.233205795288086,\n",
       "    4.063185691833496,\n",
       "    4.007913112640381,\n",
       "    4.167824745178223,\n",
       "    4.217369556427002,\n",
       "    4.107588291168213,\n",
       "    3.8877949714660645,\n",
       "    4.180495738983154,\n",
       "    3.8142757415771484,\n",
       "    4.096854209899902,\n",
       "    3.9780008792877197,\n",
       "    4.079400539398193,\n",
       "    3.7510159015655518,\n",
       "    3.990731716156006,\n",
       "    3.94224214553833,\n",
       "    3.8512632846832275,\n",
       "    3.8651280403137207,\n",
       "    3.8574628829956055,\n",
       "    4.080048084259033,\n",
       "    3.895232915878296,\n",
       "    3.764482021331787,\n",
       "    3.9898996353149414,\n",
       "    3.9140090942382812],\n",
       "   'val_accuracy': [0.01209999993443489,\n",
       "    0.024000000208616257,\n",
       "    0.032600000500679016,\n",
       "    0.0239499993622303,\n",
       "    0.029500000178813934,\n",
       "    0.03020000085234642,\n",
       "    0.04114999994635582,\n",
       "    0.059450000524520874,\n",
       "    0.07479999959468842,\n",
       "    0.10170000046491623,\n",
       "    0.07944999635219574,\n",
       "    0.08720000088214874,\n",
       "    0.11535000056028366,\n",
       "    0.09404999762773514,\n",
       "    0.11105000227689743,\n",
       "    0.11969999969005585,\n",
       "    0.10954999923706055,\n",
       "    0.12304999679327011,\n",
       "    0.14640000462532043,\n",
       "    0.11905000358819962,\n",
       "    0.1424500048160553,\n",
       "    0.14914999902248383,\n",
       "    0.13300000131130219,\n",
       "    0.1256999969482422,\n",
       "    0.14135000109672546,\n",
       "    0.16474999487400055,\n",
       "    0.13300000131130219,\n",
       "    0.1766500025987625,\n",
       "    0.14169999957084656,\n",
       "    0.15995000302791595,\n",
       "    0.14740000665187836,\n",
       "    0.187950000166893,\n",
       "    0.16075000166893005,\n",
       "    0.16130000352859497,\n",
       "    0.17685000598430634,\n",
       "    0.1736000031232834,\n",
       "    0.17845000326633453,\n",
       "    0.155349999666214,\n",
       "    0.18039999902248383,\n",
       "    0.19075000286102295,\n",
       "    0.16654999554157257,\n",
       "    0.18539999425411224]}},\n",
       " {'0.0001 128': {'loss': [5.6521897315979,\n",
       "    5.253465175628662,\n",
       "    5.033880233764648,\n",
       "    4.823861122131348,\n",
       "    4.648655891418457,\n",
       "    4.502961158752441,\n",
       "    4.37501859664917,\n",
       "    4.258752346038818,\n",
       "    4.167827129364014,\n",
       "    4.085801124572754,\n",
       "    4.00006103515625,\n",
       "    3.9345703125,\n",
       "    3.861755847930908,\n",
       "    3.812703847885132,\n",
       "    3.7539148330688477,\n",
       "    3.709221601486206,\n",
       "    3.6577417850494385,\n",
       "    3.6140847206115723,\n",
       "    3.571835994720459,\n",
       "    3.53460693359375,\n",
       "    3.497523784637451,\n",
       "    3.4623327255249023,\n",
       "    3.4122092723846436,\n",
       "    3.3942949771881104,\n",
       "    3.360109806060791,\n",
       "    3.327932834625244,\n",
       "    3.3026926517486572,\n",
       "    3.2809882164001465,\n",
       "    3.2527267932891846,\n",
       "    3.2260992527008057,\n",
       "    3.2066304683685303,\n",
       "    3.181710958480835,\n",
       "    3.1636369228363037],\n",
       "   'accuracy': [0.011412500403821468,\n",
       "    0.021774999797344208,\n",
       "    0.03564999997615814,\n",
       "    0.050187498331069946,\n",
       "    0.06424999982118607,\n",
       "    0.0794999971985817,\n",
       "    0.09324999898672104,\n",
       "    0.10679999738931656,\n",
       "    0.11906249821186066,\n",
       "    0.1308249980211258,\n",
       "    0.1429625004529953,\n",
       "    0.15171250700950623,\n",
       "    0.16380000114440918,\n",
       "    0.16865000128746033,\n",
       "    0.17848749458789825,\n",
       "    0.18656249344348907,\n",
       "    0.1941000074148178,\n",
       "    0.20055000483989716,\n",
       "    0.20527499914169312,\n",
       "    0.2136625051498413,\n",
       "    0.21826249361038208,\n",
       "    0.22552500665187836,\n",
       "    0.23325000703334808,\n",
       "    0.23759999871253967,\n",
       "    0.24102500081062317,\n",
       "    0.24808749556541443,\n",
       "    0.2515375018119812,\n",
       "    0.2540374994277954,\n",
       "    0.259737491607666,\n",
       "    0.2637374997138977,\n",
       "    0.26762500405311584,\n",
       "    0.2728624939918518,\n",
       "    0.27627500891685486],\n",
       "   'val_loss': [5.411470890045166,\n",
       "    5.250885963439941,\n",
       "    5.529110431671143,\n",
       "    5.404518127441406,\n",
       "    5.241802215576172,\n",
       "    4.9073686599731445,\n",
       "    5.056259632110596,\n",
       "    4.911518573760986,\n",
       "    5.023073673248291,\n",
       "    4.631990909576416,\n",
       "    4.806445598602295,\n",
       "    4.501296520233154,\n",
       "    4.346408367156982,\n",
       "    4.452198505401611,\n",
       "    4.384766101837158,\n",
       "    4.161999702453613,\n",
       "    4.16569185256958,\n",
       "    4.196908950805664,\n",
       "    4.3013505935668945,\n",
       "    4.092235565185547,\n",
       "    4.109773635864258,\n",
       "    4.277789115905762,\n",
       "    3.830918073654175,\n",
       "    3.937544822692871,\n",
       "    4.067415714263916,\n",
       "    4.035284042358398,\n",
       "    3.8364856243133545,\n",
       "    4.038198947906494,\n",
       "    3.9795258045196533,\n",
       "    3.88439679145813,\n",
       "    3.8586463928222656,\n",
       "    4.059926986694336,\n",
       "    4.027804851531982],\n",
       "   'val_accuracy': [0.012400000356137753,\n",
       "    0.02215000055730343,\n",
       "    0.01850000023841858,\n",
       "    0.03674999997019768,\n",
       "    0.037300001829862595,\n",
       "    0.05525000020861626,\n",
       "    0.05745000019669533,\n",
       "    0.056699998676776886,\n",
       "    0.058150000870227814,\n",
       "    0.08560000360012054,\n",
       "    0.07005000114440918,\n",
       "    0.09179999679327011,\n",
       "    0.11100000143051147,\n",
       "    0.09759999811649323,\n",
       "    0.10970000177621841,\n",
       "    0.12729999423027039,\n",
       "    0.1285499930381775,\n",
       "    0.12514999508857727,\n",
       "    0.11945000290870667,\n",
       "    0.14055000245571136,\n",
       "    0.13555000722408295,\n",
       "    0.11635000258684158,\n",
       "    0.17090000212192535,\n",
       "    0.1550000011920929,\n",
       "    0.14970000088214874,\n",
       "    0.147599995136261,\n",
       "    0.1737000048160553,\n",
       "    0.15125000476837158,\n",
       "    0.15680000185966492,\n",
       "    0.17155000567436218,\n",
       "    0.17444999516010284,\n",
       "    0.15729999542236328,\n",
       "    0.1555500030517578]}},\n",
       " {'0.0001 256': {'loss': [5.635287284851074,\n",
       "    5.23573112487793,\n",
       "    5.026516437530518,\n",
       "    4.827541828155518,\n",
       "    4.658937454223633,\n",
       "    4.521057605743408,\n",
       "    4.391213893890381,\n",
       "    4.274911403656006,\n",
       "    4.184296607971191,\n",
       "    4.097282409667969,\n",
       "    4.0216193199157715,\n",
       "    3.9508860111236572,\n",
       "    3.887836217880249,\n",
       "    3.8293561935424805,\n",
       "    3.7815821170806885,\n",
       "    3.726233959197998,\n",
       "    3.676273822784424,\n",
       "    3.6326887607574463,\n",
       "    3.5907082557678223,\n",
       "    3.5490801334381104,\n",
       "    3.5118660926818848,\n",
       "    3.476710557937622,\n",
       "    3.442990303039551,\n",
       "    3.4068446159362793,\n",
       "    3.3730928897857666,\n",
       "    3.3571019172668457,\n",
       "    3.325476884841919,\n",
       "    3.3001413345336914,\n",
       "    3.2740581035614014,\n",
       "    3.244558334350586,\n",
       "    3.2202296257019043,\n",
       "    3.201946973800659,\n",
       "    3.1838512420654297,\n",
       "    3.161637783050537,\n",
       "    3.1441078186035156,\n",
       "    3.126201629638672,\n",
       "    3.1077053546905518,\n",
       "    3.091050148010254,\n",
       "    3.073134660720825,\n",
       "    3.0564937591552734,\n",
       "    3.0459630489349365,\n",
       "    3.0179214477539062,\n",
       "    3.0129051208496094,\n",
       "    2.9994215965270996,\n",
       "    2.985323905944824,\n",
       "    2.9677135944366455,\n",
       "    2.9573278427124023,\n",
       "    2.9444737434387207,\n",
       "    2.9335110187530518,\n",
       "    2.923152446746826,\n",
       "    2.9093635082244873,\n",
       "    2.894211530685425,\n",
       "    2.8823437690734863,\n",
       "    2.868797540664673,\n",
       "    2.858016014099121,\n",
       "    2.845028877258301,\n",
       "    2.8386197090148926,\n",
       "    2.829180955886841,\n",
       "    2.825305938720703,\n",
       "    2.8137190341949463,\n",
       "    2.8031973838806152,\n",
       "    2.793246030807495,\n",
       "    2.7875375747680664,\n",
       "    2.771512269973755,\n",
       "    2.7607104778289795,\n",
       "    2.7514822483062744,\n",
       "    2.744201421737671,\n",
       "    2.731503486633301,\n",
       "    2.7236106395721436],\n",
       "   'accuracy': [0.010987499728798866,\n",
       "    0.021800000220537186,\n",
       "    0.03312499821186066,\n",
       "    0.0489250011742115,\n",
       "    0.06433749943971634,\n",
       "    0.07641249895095825,\n",
       "    0.09206250309944153,\n",
       "    0.10558749735355377,\n",
       "    0.1168999969959259,\n",
       "    0.12748749554157257,\n",
       "    0.1393750011920929,\n",
       "    0.1482750028371811,\n",
       "    0.1581375002861023,\n",
       "    0.16682499647140503,\n",
       "    0.17321249842643738,\n",
       "    0.18129999935626984,\n",
       "    0.1895499974489212,\n",
       "    0.19562500715255737,\n",
       "    0.20288750529289246,\n",
       "    0.2090124934911728,\n",
       "    0.21629999577999115,\n",
       "    0.2230374962091446,\n",
       "    0.22813749313354492,\n",
       "    0.23377500474452972,\n",
       "    0.23729999363422394,\n",
       "    0.24186250567436218,\n",
       "    0.2475624978542328,\n",
       "    0.24951249361038208,\n",
       "    0.2574000060558319,\n",
       "    0.2608124911785126,\n",
       "    0.26614999771118164,\n",
       "    0.26816248893737793,\n",
       "    0.2729249894618988,\n",
       "    0.27617499232292175,\n",
       "    0.28216248750686646,\n",
       "    0.2842000126838684,\n",
       "    0.2878875136375427,\n",
       "    0.2885875105857849,\n",
       "    0.2923625111579895,\n",
       "    0.2961125075817108,\n",
       "    0.2975125014781952,\n",
       "    0.3029249906539917,\n",
       "    0.30320000648498535,\n",
       "    0.305400013923645,\n",
       "    0.3100000023841858,\n",
       "    0.31183749437332153,\n",
       "    0.3125250041484833,\n",
       "    0.318325012922287,\n",
       "    0.31804999709129333,\n",
       "    0.31987500190734863,\n",
       "    0.32269999384880066,\n",
       "    0.3277375102043152,\n",
       "    0.32785001397132874,\n",
       "    0.33153748512268066,\n",
       "    0.33219999074935913,\n",
       "    0.335037499666214,\n",
       "    0.33533748984336853,\n",
       "    0.33845001459121704,\n",
       "    0.3405500054359436,\n",
       "    0.3416000008583069,\n",
       "    0.34521248936653137,\n",
       "    0.34318751096725464,\n",
       "    0.3447374999523163,\n",
       "    0.34796249866485596,\n",
       "    0.35333749651908875,\n",
       "    0.3543500006198883,\n",
       "    0.35507500171661377,\n",
       "    0.35583749413490295,\n",
       "    0.35756251215934753],\n",
       "   'val_loss': [5.59302282333374,\n",
       "    6.245638847351074,\n",
       "    5.364558219909668,\n",
       "    5.593954086303711,\n",
       "    5.2952351570129395,\n",
       "    4.616180896759033,\n",
       "    4.917805194854736,\n",
       "    4.8339128494262695,\n",
       "    4.480705261230469,\n",
       "    4.53255558013916,\n",
       "    4.466858386993408,\n",
       "    4.510854244232178,\n",
       "    4.277856826782227,\n",
       "    4.372178077697754,\n",
       "    4.23385763168335,\n",
       "    4.203474521636963,\n",
       "    4.1146321296691895,\n",
       "    4.2475175857543945,\n",
       "    4.318978786468506,\n",
       "    4.025015830993652,\n",
       "    4.066944599151611,\n",
       "    3.924344539642334,\n",
       "    3.8199424743652344,\n",
       "    4.365871429443359,\n",
       "    3.903102397918701,\n",
       "    3.9057796001434326,\n",
       "    3.8969101905822754,\n",
       "    3.8612473011016846,\n",
       "    3.8846774101257324,\n",
       "    3.7560160160064697,\n",
       "    3.9347152709960938,\n",
       "    3.7501065731048584,\n",
       "    3.7642714977264404,\n",
       "    3.723398447036743,\n",
       "    3.6881160736083984,\n",
       "    3.8137731552124023,\n",
       "    3.8387277126312256,\n",
       "    3.662757396697998,\n",
       "    3.72711443901062,\n",
       "    3.7273483276367188,\n",
       "    3.632136821746826,\n",
       "    3.603520631790161,\n",
       "    3.733233690261841,\n",
       "    3.815927743911743,\n",
       "    3.7718424797058105,\n",
       "    3.732658624649048,\n",
       "    3.593083143234253,\n",
       "    3.5991692543029785,\n",
       "    3.7858524322509766,\n",
       "    3.8326475620269775,\n",
       "    3.47650146484375,\n",
       "    3.6739680767059326,\n",
       "    3.6670515537261963,\n",
       "    3.7756073474884033,\n",
       "    3.669278860092163,\n",
       "    3.4506940841674805,\n",
       "    3.5075109004974365,\n",
       "    3.670701503753662,\n",
       "    3.366098165512085,\n",
       "    3.6222925186157227,\n",
       "    3.619891881942749,\n",
       "    3.657230854034424,\n",
       "    3.6209700107574463,\n",
       "    3.6779682636260986,\n",
       "    3.911665678024292,\n",
       "    3.4693241119384766,\n",
       "    3.670677661895752,\n",
       "    3.4613699913024902,\n",
       "    3.361825704574585],\n",
       "   'val_accuracy': [0.012450000271201134,\n",
       "    0.01360000018030405,\n",
       "    0.023150000721216202,\n",
       "    0.020800000056624413,\n",
       "    0.03595000132918358,\n",
       "    0.07159999758005142,\n",
       "    0.054999999701976776,\n",
       "    0.060499999672174454,\n",
       "    0.08489999920129776,\n",
       "    0.08579999953508377,\n",
       "    0.08789999783039093,\n",
       "    0.09144999831914902,\n",
       "    0.1136000007390976,\n",
       "    0.10740000009536743,\n",
       "    0.11794999986886978,\n",
       "    0.1237500011920929,\n",
       "    0.1326500028371811,\n",
       "    0.12060000002384186,\n",
       "    0.11569999903440475,\n",
       "    0.1407500058412552,\n",
       "    0.14315000176429749,\n",
       "    0.16075000166893005,\n",
       "    0.17649999260902405,\n",
       "    0.11675000190734863,\n",
       "    0.16535000503063202,\n",
       "    0.16449999809265137,\n",
       "    0.16314999759197235,\n",
       "    0.1738000065088272,\n",
       "    0.17149999737739563,\n",
       "    0.18574999272823334,\n",
       "    0.16689999401569366,\n",
       "    0.1839500069618225,\n",
       "    0.19009999930858612,\n",
       "    0.19050000607967377,\n",
       "    0.19679999351501465,\n",
       "    0.18019999563694,\n",
       "    0.18324999511241913,\n",
       "    0.20270000398159027,\n",
       "    0.1995999962091446,\n",
       "    0.18915000557899475,\n",
       "    0.20755000412464142,\n",
       "    0.21735000610351562,\n",
       "    0.1975499987602234,\n",
       "    0.19020000100135803,\n",
       "    0.19670000672340393,\n",
       "    0.19634999334812164,\n",
       "    0.21799999475479126,\n",
       "    0.21535000205039978,\n",
       "    0.1951500028371811,\n",
       "    0.19294999539852142,\n",
       "    0.2324499934911728,\n",
       "    0.21549999713897705,\n",
       "    0.21040000021457672,\n",
       "    0.19265000522136688,\n",
       "    0.2089499980211258,\n",
       "    0.23919999599456787,\n",
       "    0.23405000567436218,\n",
       "    0.21369999647140503,\n",
       "    0.25440001487731934,\n",
       "    0.22245000302791595,\n",
       "    0.22089999914169312,\n",
       "    0.2168000042438507,\n",
       "    0.21870000660419464,\n",
       "    0.2134000062942505,\n",
       "    0.1907999962568283,\n",
       "    0.2459000051021576,\n",
       "    0.2179500013589859,\n",
       "    0.24940000474452972,\n",
       "    0.2579500079154968]}},\n",
       " {'0.0001 512': {'loss': [5.599355697631836,\n",
       "    5.207976341247559,\n",
       "    5.025490760803223,\n",
       "    4.817569732666016,\n",
       "    4.6367387771606445,\n",
       "    4.4903740882873535,\n",
       "    4.363053321838379,\n",
       "    4.255809307098389,\n",
       "    4.161812782287598,\n",
       "    4.083789825439453,\n",
       "    4.009998321533203,\n",
       "    3.940415620803833,\n",
       "    3.877366304397583,\n",
       "    3.8221421241760254,\n",
       "    3.7703614234924316,\n",
       "    3.7156426906585693,\n",
       "    3.6737968921661377,\n",
       "    3.6244773864746094,\n",
       "    3.5857207775115967,\n",
       "    3.554090738296509,\n",
       "    3.5209901332855225,\n",
       "    3.4786295890808105,\n",
       "    3.4412081241607666,\n",
       "    3.414572238922119,\n",
       "    3.3853938579559326,\n",
       "    3.3511838912963867,\n",
       "    3.325505018234253,\n",
       "    3.30035400390625,\n",
       "    3.2816667556762695,\n",
       "    3.249246597290039,\n",
       "    3.218838930130005,\n",
       "    3.2005438804626465,\n",
       "    3.1768386363983154,\n",
       "    3.1556572914123535,\n",
       "    3.139047145843506,\n",
       "    3.1170878410339355,\n",
       "    3.096923828125,\n",
       "    3.0821354389190674,\n",
       "    3.065817356109619,\n",
       "    3.043306589126587,\n",
       "    3.0307085514068604],\n",
       "   'accuracy': [0.014687499962747097,\n",
       "    0.024924999102950096,\n",
       "    0.0351875014603138,\n",
       "    0.05113749951124191,\n",
       "    0.06769999861717224,\n",
       "    0.08043749630451202,\n",
       "    0.09513749927282333,\n",
       "    0.10813750326633453,\n",
       "    0.1200999990105629,\n",
       "    0.13016250729560852,\n",
       "    0.14233750104904175,\n",
       "    0.15111249685287476,\n",
       "    0.15947499871253967,\n",
       "    0.16805000603199005,\n",
       "    0.1751125007867813,\n",
       "    0.18322500586509705,\n",
       "    0.19002500176429749,\n",
       "    0.19817499816417694,\n",
       "    0.20514999330043793,\n",
       "    0.21043750643730164,\n",
       "    0.21576249599456787,\n",
       "    0.22273750603199005,\n",
       "    0.2282875031232834,\n",
       "    0.2326499968767166,\n",
       "    0.2378624975681305,\n",
       "    0.2425374984741211,\n",
       "    0.24744999408721924,\n",
       "    0.2511749863624573,\n",
       "    0.2544499933719635,\n",
       "    0.26307499408721924,\n",
       "    0.2656624913215637,\n",
       "    0.2707875072956085,\n",
       "    0.27617499232292175,\n",
       "    0.2763749957084656,\n",
       "    0.28068751096725464,\n",
       "    0.2840625047683716,\n",
       "    0.29006248712539673,\n",
       "    0.2912124991416931,\n",
       "    0.2933500111103058,\n",
       "    0.29698750376701355,\n",
       "    0.298675000667572],\n",
       "   'val_loss': [5.0885491371154785,\n",
       "    4.949437141418457,\n",
       "    5.166783809661865,\n",
       "    5.064779758453369,\n",
       "    4.920461177825928,\n",
       "    5.189326763153076,\n",
       "    5.126427173614502,\n",
       "    5.206149578094482,\n",
       "    4.746731281280518,\n",
       "    4.702942848205566,\n",
       "    4.7513227462768555,\n",
       "    4.792031288146973,\n",
       "    4.397158622741699,\n",
       "    4.166595935821533,\n",
       "    4.1070427894592285,\n",
       "    4.140213489532471,\n",
       "    4.198607921600342,\n",
       "    4.17410945892334,\n",
       "    4.093937873840332,\n",
       "    3.9497671127319336,\n",
       "    4.0640869140625,\n",
       "    3.8050832748413086,\n",
       "    4.047677993774414,\n",
       "    3.897669553756714,\n",
       "    4.150916576385498,\n",
       "    3.8246631622314453,\n",
       "    3.9056437015533447,\n",
       "    3.9794039726257324,\n",
       "    4.074214935302734,\n",
       "    3.8631789684295654,\n",
       "    3.6514346599578857,\n",
       "    3.9815852642059326,\n",
       "    3.688563585281372,\n",
       "    4.064929485321045,\n",
       "    3.8100812435150146,\n",
       "    3.746936798095703,\n",
       "    3.8620171546936035,\n",
       "    3.8396871089935303,\n",
       "    3.792923927307129,\n",
       "    3.74617338180542,\n",
       "    3.8780057430267334],\n",
       "   'val_accuracy': [0.02329999953508377,\n",
       "    0.03595000132918358,\n",
       "    0.024299999698996544,\n",
       "    0.03905000165104866,\n",
       "    0.05204999819397926,\n",
       "    0.04675000160932541,\n",
       "    0.04659999907016754,\n",
       "    0.04659999907016754,\n",
       "    0.061149999499320984,\n",
       "    0.0767500028014183,\n",
       "    0.07249999791383743,\n",
       "    0.07365000247955322,\n",
       "    0.0986500009894371,\n",
       "    0.12995000183582306,\n",
       "    0.13199999928474426,\n",
       "    0.12960000336170197,\n",
       "    0.12939999997615814,\n",
       "    0.1307000070810318,\n",
       "    0.1370999962091446,\n",
       "    0.15254999697208405,\n",
       "    0.14560000598430634,\n",
       "    0.17315000295639038,\n",
       "    0.15105000138282776,\n",
       "    0.16294999420642853,\n",
       "    0.13660000264644623,\n",
       "    0.1754000037908554,\n",
       "    0.1662999987602234,\n",
       "    0.1586499959230423,\n",
       "    0.1492999941110611,\n",
       "    0.1716500073671341,\n",
       "    0.20035000145435333,\n",
       "    0.16494999825954437,\n",
       "    0.19840000569820404,\n",
       "    0.15189999341964722,\n",
       "    0.18199999630451202,\n",
       "    0.19030000269412994,\n",
       "    0.17949999868869781,\n",
       "    0.18039999902248383,\n",
       "    0.188400000333786,\n",
       "    0.19290000200271606,\n",
       "    0.1754000037908554]}},\n",
       " {'0.0001 1024': {'loss': [5.673172950744629,\n",
       "    5.225280284881592,\n",
       "    5.001189231872559,\n",
       "    4.794386863708496,\n",
       "    4.62912130355835,\n",
       "    4.486423492431641,\n",
       "    4.363304615020752,\n",
       "    4.248741626739502,\n",
       "    4.165303707122803,\n",
       "    4.07966947555542,\n",
       "    4.001178741455078,\n",
       "    3.935920000076294,\n",
       "    3.866877317428589,\n",
       "    3.8103842735290527,\n",
       "    3.763564348220825,\n",
       "    3.707719087600708,\n",
       "    3.6690895557403564,\n",
       "    3.6254823207855225,\n",
       "    3.572871208190918,\n",
       "    3.5389301776885986,\n",
       "    3.5003409385681152,\n",
       "    3.4655444622039795,\n",
       "    3.428842306137085,\n",
       "    3.392688274383545,\n",
       "    3.364189386367798,\n",
       "    3.3400051593780518,\n",
       "    3.3097386360168457,\n",
       "    3.2831063270568848,\n",
       "    3.2565724849700928,\n",
       "    3.233107328414917,\n",
       "    3.205946683883667,\n",
       "    3.1900100708007812,\n",
       "    3.1683883666992188,\n",
       "    3.1424400806427,\n",
       "    3.128624439239502,\n",
       "    3.106316089630127,\n",
       "    3.0895955562591553],\n",
       "   'accuracy': [0.011274999938905239,\n",
       "    0.02370000071823597,\n",
       "    0.037950001657009125,\n",
       "    0.05420000106096268,\n",
       "    0.06655000150203705,\n",
       "    0.08253750205039978,\n",
       "    0.09691250324249268,\n",
       "    0.11031249910593033,\n",
       "    0.11942499876022339,\n",
       "    0.13151249289512634,\n",
       "    0.14139999449253082,\n",
       "    0.15000000596046448,\n",
       "    0.16167500615119934,\n",
       "    0.16848750412464142,\n",
       "    0.17598749697208405,\n",
       "    0.1859000027179718,\n",
       "    0.18958750367164612,\n",
       "    0.19653749465942383,\n",
       "    0.20548750460147858,\n",
       "    0.21166250109672546,\n",
       "    0.21768750250339508,\n",
       "    0.2253749966621399,\n",
       "    0.22868749499320984,\n",
       "    0.23618750274181366,\n",
       "    0.24191249907016754,\n",
       "    0.24531249701976776,\n",
       "    0.25049999356269836,\n",
       "    0.25657498836517334,\n",
       "    0.25981250405311584,\n",
       "    0.2638624906539917,\n",
       "    0.2694000005722046,\n",
       "    0.2703000009059906,\n",
       "    0.27441251277923584,\n",
       "    0.28037500381469727,\n",
       "    0.28222501277923584,\n",
       "    0.28856250643730164,\n",
       "    0.28968751430511475],\n",
       "   'val_loss': [5.138355255126953,\n",
       "    5.176791191101074,\n",
       "    5.115297794342041,\n",
       "    5.242786884307861,\n",
       "    5.279496669769287,\n",
       "    4.892899036407471,\n",
       "    4.9690704345703125,\n",
       "    4.875664234161377,\n",
       "    4.70344352722168,\n",
       "    4.672043323516846,\n",
       "    4.514686107635498,\n",
       "    4.324913024902344,\n",
       "    4.470050811767578,\n",
       "    4.371607303619385,\n",
       "    4.189382076263428,\n",
       "    4.4408392906188965,\n",
       "    4.150383472442627,\n",
       "    4.367187023162842,\n",
       "    4.094916820526123,\n",
       "    4.003081321716309,\n",
       "    4.178650379180908,\n",
       "    4.23727560043335,\n",
       "    4.337963104248047,\n",
       "    4.467939376831055,\n",
       "    3.9944875240325928,\n",
       "    4.156300067901611,\n",
       "    3.7422266006469727,\n",
       "    3.981631278991699,\n",
       "    3.9795913696289062,\n",
       "    3.976016044616699,\n",
       "    3.9677116870880127,\n",
       "    4.058425426483154,\n",
       "    4.508744239807129,\n",
       "    3.948549270629883,\n",
       "    4.027235507965088,\n",
       "    3.8870949745178223,\n",
       "    3.8628270626068115],\n",
       "   'val_accuracy': [0.021400000900030136,\n",
       "    0.022050000727176666,\n",
       "    0.03550000116229057,\n",
       "    0.031599998474121094,\n",
       "    0.03784999996423721,\n",
       "    0.05739999935030937,\n",
       "    0.050599999725818634,\n",
       "    0.05180000141263008,\n",
       "    0.06610000133514404,\n",
       "    0.07199999690055847,\n",
       "    0.08910000324249268,\n",
       "    0.10740000009536743,\n",
       "    0.08914999663829803,\n",
       "    0.09724999964237213,\n",
       "    0.11869999766349792,\n",
       "    0.09775000065565109,\n",
       "    0.12610000371932983,\n",
       "    0.1051499992609024,\n",
       "    0.13269999623298645,\n",
       "    0.14624999463558197,\n",
       "    0.1277499943971634,\n",
       "    0.12264999747276306,\n",
       "    0.11980000138282776,\n",
       "    0.10409999638795853,\n",
       "    0.14875000715255737,\n",
       "    0.13414999842643738,\n",
       "    0.18645000457763672,\n",
       "    0.15559999644756317,\n",
       "    0.1581999957561493,\n",
       "    0.15850000083446503,\n",
       "    0.15889999270439148,\n",
       "    0.15344999730587006,\n",
       "    0.1143999993801117,\n",
       "    0.16619999706745148,\n",
       "    0.15790000557899475,\n",
       "    0.17399999499320984,\n",
       "    0.17344999313354492]}},\n",
       " {'1e-05 64': {'loss': [6.267604351043701,\n",
       "    6.017229080200195,\n",
       "    5.795938968658447,\n",
       "    5.659814357757568,\n",
       "    5.554079055786133,\n",
       "    5.48541784286499,\n",
       "    5.41881799697876,\n",
       "    5.352870941162109,\n",
       "    5.2993879318237305,\n",
       "    5.248549938201904,\n",
       "    5.190084457397461,\n",
       "    5.152253150939941,\n",
       "    5.11154317855835,\n",
       "    5.075594902038574,\n",
       "    5.033681392669678,\n",
       "    4.990336894989014],\n",
       "   'accuracy': [0.005925000179558992,\n",
       "    0.008512499742209911,\n",
       "    0.010425000451505184,\n",
       "    0.012087499722838402,\n",
       "    0.012962499633431435,\n",
       "    0.014425000175833702,\n",
       "    0.016737500205636024,\n",
       "    0.019687499850988388,\n",
       "    0.022162500768899918,\n",
       "    0.025474999099969864,\n",
       "    0.028224999085068703,\n",
       "    0.030799999833106995,\n",
       "    0.03412500023841858,\n",
       "    0.03584999963641167,\n",
       "    0.03947500139474869,\n",
       "    0.04036249965429306],\n",
       "   'val_loss': [5.4791259765625,\n",
       "    5.482903480529785,\n",
       "    5.480290412902832,\n",
       "    5.433551788330078,\n",
       "    5.374540328979492,\n",
       "    5.313061714172363,\n",
       "    5.30340051651001,\n",
       "    5.35342264175415,\n",
       "    5.407526969909668,\n",
       "    5.39150333404541,\n",
       "    5.546731472015381,\n",
       "    5.426642417907715,\n",
       "    5.511419773101807,\n",
       "    5.510039329528809,\n",
       "    5.626955032348633,\n",
       "    5.581814289093018],\n",
       "   'val_accuracy': [0.007400000002235174,\n",
       "    0.011649999767541885,\n",
       "    0.012550000101327896,\n",
       "    0.011699999682605267,\n",
       "    0.011950000189244747,\n",
       "    0.013749999925494194,\n",
       "    0.016249999403953552,\n",
       "    0.016950000077486038,\n",
       "    0.01850000023841858,\n",
       "    0.020600000396370888,\n",
       "    0.02225000038743019,\n",
       "    0.023150000721216202,\n",
       "    0.02669999934732914,\n",
       "    0.024550000205636024,\n",
       "    0.0239499993622303,\n",
       "    0.02225000038743019]}},\n",
       " {'1e-05 128': {'loss': [6.260848045349121,\n",
       "    6.068812370300293,\n",
       "    5.857532978057861,\n",
       "    5.691555500030518,\n",
       "    5.578389644622803,\n",
       "    5.497231483459473,\n",
       "    5.4271674156188965,\n",
       "    5.367839813232422,\n",
       "    5.298673629760742,\n",
       "    5.239190578460693,\n",
       "    5.187838077545166,\n",
       "    5.142300128936768,\n",
       "    5.106889724731445,\n",
       "    5.064700126647949,\n",
       "    5.021420478820801,\n",
       "    4.992188930511475,\n",
       "    4.952150821685791],\n",
       "   'accuracy': [0.005837500095367432,\n",
       "    0.007600000128149986,\n",
       "    0.009925000369548798,\n",
       "    0.01192499976605177,\n",
       "    0.01269999984651804,\n",
       "    0.01484999991953373,\n",
       "    0.016587499529123306,\n",
       "    0.01837499998509884,\n",
       "    0.021962499246001244,\n",
       "    0.025074999779462814,\n",
       "    0.02866250090301037,\n",
       "    0.030774999409914017,\n",
       "    0.0343874990940094,\n",
       "    0.036649998277425766,\n",
       "    0.0392875000834465,\n",
       "    0.041349999606609344,\n",
       "    0.045249998569488525],\n",
       "   'val_loss': [5.572654724121094,\n",
       "    5.707645416259766,\n",
       "    5.644395351409912,\n",
       "    5.402872085571289,\n",
       "    5.301148891448975,\n",
       "    5.265952110290527,\n",
       "    5.228416919708252,\n",
       "    5.22368860244751,\n",
       "    5.234049320220947,\n",
       "    5.240478515625,\n",
       "    5.231258869171143,\n",
       "    5.284363746643066,\n",
       "    5.352663993835449,\n",
       "    5.302968978881836,\n",
       "    5.407995223999023,\n",
       "    5.392138957977295,\n",
       "    5.465516567230225],\n",
       "   'val_accuracy': [0.006099999882280827,\n",
       "    0.008200000040233135,\n",
       "    0.009800000116229057,\n",
       "    0.012400000356137753,\n",
       "    0.016300000250339508,\n",
       "    0.01769999973475933,\n",
       "    0.01785000041127205,\n",
       "    0.02044999971985817,\n",
       "    0.022749999538064003,\n",
       "    0.02290000021457672,\n",
       "    0.02474999986588955,\n",
       "    0.022050000727176666,\n",
       "    0.020500000566244125,\n",
       "    0.021849999204277992,\n",
       "    0.0210999995470047,\n",
       "    0.02215000055730343,\n",
       "    0.023399999365210533]}},\n",
       " {'1e-05 256': {'loss': [6.2733869552612305,\n",
       "    6.079184532165527,\n",
       "    5.8941874504089355,\n",
       "    5.756016731262207,\n",
       "    5.632758617401123,\n",
       "    5.525523662567139,\n",
       "    5.4603962898254395,\n",
       "    5.391711711883545,\n",
       "    5.3332014083862305,\n",
       "    5.2925944328308105,\n",
       "    5.2477006912231445,\n",
       "    5.209285259246826,\n",
       "    5.168747425079346,\n",
       "    5.12693977355957,\n",
       "    5.081826210021973,\n",
       "    5.044910907745361,\n",
       "    5.0017547607421875,\n",
       "    4.963526248931885,\n",
       "    4.92711877822876,\n",
       "    4.886775970458984,\n",
       "    4.853367805480957],\n",
       "   'accuracy': [0.005462499801069498,\n",
       "    0.006049999967217445,\n",
       "    0.007887500338256359,\n",
       "    0.009349999949336052,\n",
       "    0.010837499983608723,\n",
       "    0.013749999925494194,\n",
       "    0.015462500043213367,\n",
       "    0.019087500870227814,\n",
       "    0.021575000137090683,\n",
       "    0.02317499928176403,\n",
       "    0.025550000369548798,\n",
       "    0.02671249955892563,\n",
       "    0.029712500050663948,\n",
       "    0.0325625017285347,\n",
       "    0.0351249985396862,\n",
       "    0.038100000470876694,\n",
       "    0.04228749871253967,\n",
       "    0.043425001204013824,\n",
       "    0.04749999940395355,\n",
       "    0.0494999997317791,\n",
       "    0.05178749933838844],\n",
       "   'val_loss': [5.4757609367370605,\n",
       "    5.490946292877197,\n",
       "    5.4458842277526855,\n",
       "    5.368358135223389,\n",
       "    5.236701011657715,\n",
       "    5.1611199378967285,\n",
       "    5.118547439575195,\n",
       "    5.05600118637085,\n",
       "    5.034750938415527,\n",
       "    5.002837657928467,\n",
       "    4.9590325355529785,\n",
       "    4.983459949493408,\n",
       "    4.978888034820557,\n",
       "    4.968429088592529,\n",
       "    4.989798545837402,\n",
       "    5.040584564208984,\n",
       "    5.06900691986084,\n",
       "    5.21587610244751,\n",
       "    5.244900226593018,\n",
       "    5.246007919311523,\n",
       "    5.402960777282715],\n",
       "   'val_accuracy': [0.006500000134110451,\n",
       "    0.006599999964237213,\n",
       "    0.00774999987334013,\n",
       "    0.010250000283122063,\n",
       "    0.015949999913573265,\n",
       "    0.020600000396370888,\n",
       "    0.02645000070333481,\n",
       "    0.030750000849366188,\n",
       "    0.03164999932050705,\n",
       "    0.0357000008225441,\n",
       "    0.03880000114440918,\n",
       "    0.03709999844431877,\n",
       "    0.03799999877810478,\n",
       "    0.039650000631809235,\n",
       "    0.03685000166296959,\n",
       "    0.03460000082850456,\n",
       "    0.03530000150203705,\n",
       "    0.03034999966621399,\n",
       "    0.028349999338388443,\n",
       "    0.02969999983906746,\n",
       "    0.027049999684095383]}},\n",
       " {'1e-05 512': {'loss': [6.266663074493408,\n",
       "    6.037073612213135,\n",
       "    5.8088459968566895,\n",
       "    5.651182174682617,\n",
       "    5.55121374130249,\n",
       "    5.482537269592285,\n",
       "    5.405886173248291,\n",
       "    5.34839391708374,\n",
       "    5.300048351287842,\n",
       "    5.25050163269043,\n",
       "    5.214582920074463,\n",
       "    5.164236545562744,\n",
       "    5.126221179962158,\n",
       "    5.081775188446045,\n",
       "    5.035394191741943,\n",
       "    4.997166633605957,\n",
       "    4.962401390075684,\n",
       "    4.934241771697998,\n",
       "    4.892258644104004],\n",
       "   'accuracy': [0.005712499842047691,\n",
       "    0.007675000000745058,\n",
       "    0.010075000114738941,\n",
       "    0.012199999764561653,\n",
       "    0.013700000010430813,\n",
       "    0.014887499623000622,\n",
       "    0.017112499102950096,\n",
       "    0.019487500190734863,\n",
       "    0.021974999457597733,\n",
       "    0.024712499231100082,\n",
       "    0.026462500914931297,\n",
       "    0.029650000855326653,\n",
       "    0.032625000923871994,\n",
       "    0.03454999998211861,\n",
       "    0.03818750008940697,\n",
       "    0.041099999099969864,\n",
       "    0.04267499968409538,\n",
       "    0.045049998909235,\n",
       "    0.0484125018119812],\n",
       "   'val_loss': [5.614554405212402,\n",
       "    5.815329074859619,\n",
       "    5.888481140136719,\n",
       "    5.678643226623535,\n",
       "    5.498057842254639,\n",
       "    5.461031436920166,\n",
       "    5.506048202514648,\n",
       "    5.329260349273682,\n",
       "    5.241473197937012,\n",
       "    5.303952693939209,\n",
       "    5.249098300933838,\n",
       "    5.344089031219482,\n",
       "    6.024963855743408,\n",
       "    6.048304080963135,\n",
       "    6.155496120452881,\n",
       "    5.795054912567139,\n",
       "    5.687230587005615,\n",
       "    5.648983001708984,\n",
       "    5.465303897857666],\n",
       "   'val_accuracy': [0.0064500002190470695,\n",
       "    0.008249999955296516,\n",
       "    0.010300000198185444,\n",
       "    0.013050000183284283,\n",
       "    0.015150000341236591,\n",
       "    0.01810000091791153,\n",
       "    0.018850000575184822,\n",
       "    0.020250000059604645,\n",
       "    0.023000000044703484,\n",
       "    0.0210999995470047,\n",
       "    0.025350000709295273,\n",
       "    0.026000000536441803,\n",
       "    0.020400000736117363,\n",
       "    0.019600000232458115,\n",
       "    0.018850000575184822,\n",
       "    0.020549999549984932,\n",
       "    0.021250000223517418,\n",
       "    0.02005000039935112,\n",
       "    0.020150000229477882]}},\n",
       " {'1e-05 1024': {'loss': [6.257532596588135,\n",
       "    6.037821292877197,\n",
       "    5.788599491119385,\n",
       "    5.635698318481445,\n",
       "    5.532815933227539,\n",
       "    5.464034557342529,\n",
       "    5.404558181762695,\n",
       "    5.349939346313477,\n",
       "    5.287420272827148,\n",
       "    5.2331342697143555,\n",
       "    5.186380386352539,\n",
       "    5.1402668952941895,\n",
       "    5.1003618240356445,\n",
       "    5.053704261779785,\n",
       "    5.017181873321533,\n",
       "    4.981784820556641,\n",
       "    4.936587810516357,\n",
       "    4.911896228790283],\n",
       "   'accuracy': [0.005837500095367432,\n",
       "    0.007974999956786633,\n",
       "    0.010787500068545341,\n",
       "    0.011837500147521496,\n",
       "    0.013425000011920929,\n",
       "    0.01484999991953373,\n",
       "    0.01743750087916851,\n",
       "    0.018699999898672104,\n",
       "    0.022224999964237213,\n",
       "    0.024775000289082527,\n",
       "    0.028449999168515205,\n",
       "    0.030649999156594276,\n",
       "    0.03311249986290932,\n",
       "    0.037037499248981476,\n",
       "    0.037812501192092896,\n",
       "    0.04091250151395798,\n",
       "    0.0440250001847744,\n",
       "    0.04691249877214432],\n",
       "   'val_loss': [5.674829006195068,\n",
       "    5.659399032592773,\n",
       "    5.578372478485107,\n",
       "    5.453276634216309,\n",
       "    5.363699436187744,\n",
       "    5.350625991821289,\n",
       "    5.372450828552246,\n",
       "    5.276909351348877,\n",
       "    5.3093156814575195,\n",
       "    5.304832935333252,\n",
       "    5.313027858734131,\n",
       "    5.455801010131836,\n",
       "    5.41414737701416,\n",
       "    5.431419849395752,\n",
       "    5.44774866104126,\n",
       "    5.480873107910156,\n",
       "    5.542534351348877,\n",
       "    5.559055805206299],\n",
       "   'val_accuracy': [0.006649999879300594,\n",
       "    0.01054999977350235,\n",
       "    0.013749999925494194,\n",
       "    0.013799999840557575,\n",
       "    0.016699999570846558,\n",
       "    0.01655000075697899,\n",
       "    0.01614999957382679,\n",
       "    0.017899999395012856,\n",
       "    0.01875000074505806,\n",
       "    0.020800000056624413,\n",
       "    0.021050000563263893,\n",
       "    0.01889999955892563,\n",
       "    0.01875000074505806,\n",
       "    0.01850000023841858,\n",
       "    0.018850000575184822,\n",
       "    0.019600000232458115,\n",
       "    0.02085000090301037,\n",
       "    0.020749999210238457]}},\n",
       " {'1e-06 64': {'loss': [6.374655723571777,\n",
       "    6.3521857261657715,\n",
       "    6.34626579284668,\n",
       "    6.316930770874023,\n",
       "    6.29805850982666,\n",
       "    6.282906532287598,\n",
       "    6.268648624420166,\n",
       "    6.238188743591309,\n",
       "    6.220863342285156,\n",
       "    6.19840669631958,\n",
       "    6.177266597747803,\n",
       "    6.152695655822754,\n",
       "    6.14560604095459],\n",
       "   'accuracy': [0.005237500183284283,\n",
       "    0.005062500014901161,\n",
       "    0.004987500142306089,\n",
       "    0.0048374999314546585,\n",
       "    0.005574999842792749,\n",
       "    0.005249999929219484,\n",
       "    0.006087500136345625,\n",
       "    0.006262499839067459,\n",
       "    0.006200000178068876,\n",
       "    0.005925000179558992,\n",
       "    0.0066999997943639755,\n",
       "    0.0067125000059604645,\n",
       "    0.006562499795109034],\n",
       "   'val_loss': [5.546321392059326,\n",
       "    5.5315656661987305,\n",
       "    5.52140998840332,\n",
       "    5.5196003913879395,\n",
       "    5.523080825805664,\n",
       "    5.532283782958984,\n",
       "    5.538686275482178,\n",
       "    5.540533542633057,\n",
       "    5.553930282592773,\n",
       "    5.578012943267822,\n",
       "    5.598945617675781,\n",
       "    5.605686187744141,\n",
       "    5.622829437255859],\n",
       "   'val_accuracy': [0.00494999997317791,\n",
       "    0.005049999803304672,\n",
       "    0.004650000017136335,\n",
       "    0.005150000099092722,\n",
       "    0.005049999803304672,\n",
       "    0.005849999841302633,\n",
       "    0.0062500000931322575,\n",
       "    0.005750000011175871,\n",
       "    0.006949999835342169,\n",
       "    0.006099999882280827,\n",
       "    0.006149999797344208,\n",
       "    0.0062500000931322575,\n",
       "    0.007000000216066837]}},\n",
       " {'1e-06 128': {'loss': [6.357712745666504,\n",
       "    6.320926189422607,\n",
       "    6.290989875793457,\n",
       "    6.255410194396973,\n",
       "    6.22971773147583,\n",
       "    6.206090450286865,\n",
       "    6.1700873374938965,\n",
       "    6.147754192352295,\n",
       "    6.108140468597412,\n",
       "    6.079620361328125,\n",
       "    6.049965858459473,\n",
       "    6.018250942230225,\n",
       "    5.994989395141602,\n",
       "    5.97418212890625,\n",
       "    5.944056034088135,\n",
       "    5.911797523498535,\n",
       "    5.888168811798096,\n",
       "    5.863096714019775,\n",
       "    5.8310322761535645,\n",
       "    5.815792083740234,\n",
       "    5.8002400398254395,\n",
       "    5.766543865203857,\n",
       "    5.7542724609375,\n",
       "    5.730904579162598,\n",
       "    5.707512378692627,\n",
       "    5.696931838989258,\n",
       "    5.685831546783447,\n",
       "    5.661146640777588,\n",
       "    5.648227691650391,\n",
       "    5.635883808135986,\n",
       "    5.6259989738464355,\n",
       "    5.616201400756836,\n",
       "    5.602025985717773,\n",
       "    5.584847450256348,\n",
       "    5.578152656555176,\n",
       "    5.569258689880371,\n",
       "    5.552056312561035,\n",
       "    5.549827575683594,\n",
       "    5.530740261077881,\n",
       "    5.5257439613342285,\n",
       "    5.513364315032959,\n",
       "    5.503505706787109,\n",
       "    5.4976806640625,\n",
       "    5.48573637008667,\n",
       "    5.473630905151367,\n",
       "    5.471259117126465,\n",
       "    5.460187911987305,\n",
       "    5.452154636383057,\n",
       "    5.439949035644531,\n",
       "    5.433635711669922,\n",
       "    5.42807674407959,\n",
       "    5.41071081161499,\n",
       "    5.4043354988098145,\n",
       "    5.398841857910156,\n",
       "    5.394458770751953,\n",
       "    5.386724948883057,\n",
       "    5.379947662353516,\n",
       "    5.375017166137695,\n",
       "    5.365105152130127,\n",
       "    5.358132839202881,\n",
       "    5.349124431610107,\n",
       "    5.343623638153076,\n",
       "    5.338870048522949,\n",
       "    5.336495876312256,\n",
       "    5.324650287628174,\n",
       "    5.320096015930176,\n",
       "    5.3115363121032715],\n",
       "   'accuracy': [0.0048500001430511475,\n",
       "    0.005812500137835741,\n",
       "    0.005574999842792749,\n",
       "    0.005524999927729368,\n",
       "    0.005675000138580799,\n",
       "    0.005750000011175871,\n",
       "    0.006775000132620335,\n",
       "    0.006087500136345625,\n",
       "    0.00647500017657876,\n",
       "    0.007287499960511923,\n",
       "    0.007487500086426735,\n",
       "    0.007149999961256981,\n",
       "    0.007362499833106995,\n",
       "    0.007887500338256359,\n",
       "    0.008674999698996544,\n",
       "    0.008962499909102917,\n",
       "    0.008562499657273293,\n",
       "    0.009074999950826168,\n",
       "    0.00971249956637621,\n",
       "    0.00971249956637621,\n",
       "    0.009912500157952309,\n",
       "    0.010337499901652336,\n",
       "    0.009937499649822712,\n",
       "    0.010324999690055847,\n",
       "    0.010900000110268593,\n",
       "    0.010712499730288982,\n",
       "    0.010637500323355198,\n",
       "    0.011474999599158764,\n",
       "    0.012550000101327896,\n",
       "    0.012225000187754631,\n",
       "    0.011737500317394733,\n",
       "    0.012262499891221523,\n",
       "    0.01341249980032444,\n",
       "    0.013462499715387821,\n",
       "    0.013387500308454037,\n",
       "    0.01295000035315752,\n",
       "    0.013624999672174454,\n",
       "    0.013787499628961086,\n",
       "    0.014475000090897083,\n",
       "    0.014712500385940075,\n",
       "    0.014412499964237213,\n",
       "    0.01600000075995922,\n",
       "    0.015462500043213367,\n",
       "    0.015775000676512718,\n",
       "    0.016574999317526817,\n",
       "    0.0165375005453825,\n",
       "    0.01691249944269657,\n",
       "    0.017224999144673347,\n",
       "    0.017287500202655792,\n",
       "    0.01744999922811985,\n",
       "    0.018024999648332596,\n",
       "    0.017537500709295273,\n",
       "    0.019449999555945396,\n",
       "    0.019562499597668648,\n",
       "    0.01993750035762787,\n",
       "    0.019087500870227814,\n",
       "    0.021150000393390656,\n",
       "    0.020787499845027924,\n",
       "    0.020275000482797623,\n",
       "    0.020487500354647636,\n",
       "    0.02095000073313713,\n",
       "    0.02241249941289425,\n",
       "    0.02085000090301037,\n",
       "    0.022212499752640724,\n",
       "    0.022562500089406967,\n",
       "    0.023512499406933784,\n",
       "    0.02367500029504299],\n",
       "   'val_loss': [5.572366714477539,\n",
       "    5.558899402618408,\n",
       "    5.552966117858887,\n",
       "    5.5507121086120605,\n",
       "    5.551476001739502,\n",
       "    5.544964790344238,\n",
       "    5.55507755279541,\n",
       "    5.531571865081787,\n",
       "    5.535589218139648,\n",
       "    5.532002925872803,\n",
       "    5.529697418212891,\n",
       "    5.533504486083984,\n",
       "    5.514553070068359,\n",
       "    5.507997989654541,\n",
       "    5.494556427001953,\n",
       "    5.482053279876709,\n",
       "    5.467048168182373,\n",
       "    5.453505992889404,\n",
       "    5.4420366287231445,\n",
       "    5.4488301277160645,\n",
       "    5.457552909851074,\n",
       "    5.442082405090332,\n",
       "    5.455855369567871,\n",
       "    5.447612762451172,\n",
       "    5.4451985359191895,\n",
       "    5.414621829986572,\n",
       "    5.413037300109863,\n",
       "    5.380223274230957,\n",
       "    5.376701831817627,\n",
       "    5.362453460693359,\n",
       "    5.336065292358398,\n",
       "    5.321049213409424,\n",
       "    5.315622806549072,\n",
       "    5.299064636230469,\n",
       "    5.283480644226074,\n",
       "    5.278284072875977,\n",
       "    5.260913848876953,\n",
       "    5.248435020446777,\n",
       "    5.240515232086182,\n",
       "    5.224936485290527,\n",
       "    5.219989776611328,\n",
       "    5.212223052978516,\n",
       "    5.205439567565918,\n",
       "    5.199947834014893,\n",
       "    5.187648296356201,\n",
       "    5.173678398132324,\n",
       "    5.175662994384766,\n",
       "    5.172379493713379,\n",
       "    5.163205623626709,\n",
       "    5.157362937927246,\n",
       "    5.1526594161987305,\n",
       "    5.149214744567871,\n",
       "    5.1423659324646,\n",
       "    5.140865802764893,\n",
       "    5.141373634338379,\n",
       "    5.136879920959473,\n",
       "    5.12803316116333,\n",
       "    5.128530502319336,\n",
       "    5.123592376708984,\n",
       "    5.12498140335083,\n",
       "    5.125528335571289,\n",
       "    5.12770938873291,\n",
       "    5.124312400817871,\n",
       "    5.122936248779297,\n",
       "    5.127377986907959,\n",
       "    5.1309099197387695,\n",
       "    5.129536151885986],\n",
       "   'val_accuracy': [0.005799999926239252,\n",
       "    0.005849999841302633,\n",
       "    0.005499999970197678,\n",
       "    0.006149999797344208,\n",
       "    0.005900000222027302,\n",
       "    0.006850000005215406,\n",
       "    0.006599999964237213,\n",
       "    0.0071000000461936,\n",
       "    0.006399999838322401,\n",
       "    0.0071000000461936,\n",
       "    0.007149999961256981,\n",
       "    0.0076500000432133675,\n",
       "    0.007699999958276749,\n",
       "    0.00865000020712614,\n",
       "    0.00925000011920929,\n",
       "    0.008999999612569809,\n",
       "    0.008949999697506428,\n",
       "    0.009349999949336052,\n",
       "    0.010049999691545963,\n",
       "    0.010599999688565731,\n",
       "    0.009800000116229057,\n",
       "    0.010649999603629112,\n",
       "    0.011149999685585499,\n",
       "    0.011549999937415123,\n",
       "    0.011300000362098217,\n",
       "    0.011800000444054604,\n",
       "    0.01209999993443489,\n",
       "    0.012550000101327896,\n",
       "    0.012749999761581421,\n",
       "    0.01295000035315752,\n",
       "    0.013799999840557575,\n",
       "    0.013650000095367432,\n",
       "    0.0142000000923872,\n",
       "    0.014449999667704105,\n",
       "    0.01484999991953373,\n",
       "    0.01575000025331974,\n",
       "    0.015350000001490116,\n",
       "    0.016499999910593033,\n",
       "    0.01655000075697899,\n",
       "    0.01759999990463257,\n",
       "    0.017899999395012856,\n",
       "    0.018799999728798866,\n",
       "    0.018699999898672104,\n",
       "    0.01915000006556511,\n",
       "    0.020099999383091927,\n",
       "    0.02070000022649765,\n",
       "    0.020250000059604645,\n",
       "    0.021199999377131462,\n",
       "    0.021649999544024467,\n",
       "    0.022600000724196434,\n",
       "    0.023000000044703484,\n",
       "    0.02355000004172325,\n",
       "    0.023649999871850014,\n",
       "    0.0239499993622303,\n",
       "    0.02384999953210354,\n",
       "    0.023900000378489494,\n",
       "    0.025100000202655792,\n",
       "    0.02484999969601631,\n",
       "    0.026100000366568565,\n",
       "    0.026850000023841858,\n",
       "    0.026799999177455902,\n",
       "    0.026599999517202377,\n",
       "    0.027249999344348907,\n",
       "    0.0272000003606081,\n",
       "    0.027000000700354576,\n",
       "    0.026900000870227814,\n",
       "    0.027049999684095383]}},\n",
       " {'1e-06 256': {'loss': [6.357344150543213,\n",
       "    6.3432512283325195,\n",
       "    6.322662830352783,\n",
       "    6.289546012878418,\n",
       "    6.279897689819336,\n",
       "    6.260500907897949,\n",
       "    6.231764793395996,\n",
       "    6.221284866333008,\n",
       "    6.201572418212891,\n",
       "    6.1799798011779785,\n",
       "    6.15764856338501],\n",
       "   'accuracy': [0.004749999847263098,\n",
       "    0.005400000140070915,\n",
       "    0.0048500001430511475,\n",
       "    0.005574999842792749,\n",
       "    0.0057749999687075615,\n",
       "    0.005237500183284283,\n",
       "    0.00572500005364418,\n",
       "    0.005750000011175871,\n",
       "    0.005712499842047691,\n",
       "    0.0061125000938773155,\n",
       "    0.006599999964237213],\n",
       "   'val_loss': [5.565440654754639,\n",
       "    5.568357944488525,\n",
       "    5.578430652618408,\n",
       "    5.591640949249268,\n",
       "    5.614657402038574,\n",
       "    5.629776954650879,\n",
       "    5.665003299713135,\n",
       "    5.691984176635742,\n",
       "    5.70894193649292,\n",
       "    5.709456443786621,\n",
       "    5.770325183868408],\n",
       "   'val_accuracy': [0.004800000227987766,\n",
       "    0.004650000017136335,\n",
       "    0.0052999998442828655,\n",
       "    0.005049999803304672,\n",
       "    0.004900000058114529,\n",
       "    0.0052999998442828655,\n",
       "    0.0052999998442828655,\n",
       "    0.006000000052154064,\n",
       "    0.00634999992325902,\n",
       "    0.005249999929219484,\n",
       "    0.005799999926239252]}},\n",
       " {'1e-06 512': {'loss': [6.350846767425537,\n",
       "    6.340063095092773,\n",
       "    6.3106818199157715,\n",
       "    6.284351825714111,\n",
       "    6.2627763748168945,\n",
       "    6.239655017852783,\n",
       "    6.217000961303711,\n",
       "    6.191588878631592,\n",
       "    6.163886547088623,\n",
       "    6.158532619476318,\n",
       "    6.1404218673706055],\n",
       "   'accuracy': [0.00507500022649765,\n",
       "    0.005162499845027924,\n",
       "    0.0053125000558793545,\n",
       "    0.005675000138580799,\n",
       "    0.005412499886006117,\n",
       "    0.005750000011175871,\n",
       "    0.005987499840557575,\n",
       "    0.006300000008195639,\n",
       "    0.005900000222027302,\n",
       "    0.006387500092387199,\n",
       "    0.0057875001803040504],\n",
       "   'val_loss': [5.576487064361572,\n",
       "    5.577495098114014,\n",
       "    5.567077159881592,\n",
       "    5.5725908279418945,\n",
       "    5.581059455871582,\n",
       "    5.597627639770508,\n",
       "    5.622756481170654,\n",
       "    5.612503528594971,\n",
       "    5.643679141998291,\n",
       "    5.650357246398926,\n",
       "    5.659717559814453],\n",
       "   'val_accuracy': [0.005549999885261059,\n",
       "    0.006149999797344208,\n",
       "    0.006399999838322401,\n",
       "    0.006399999838322401,\n",
       "    0.006750000175088644,\n",
       "    0.006949999835342169,\n",
       "    0.006800000090152025,\n",
       "    0.007400000002235174,\n",
       "    0.007350000087171793,\n",
       "    0.0066999997943639755,\n",
       "    0.006800000090152025]}},\n",
       " {'1e-06 1024': {'loss': [6.386002063751221,\n",
       "    6.364927291870117,\n",
       "    6.336163520812988,\n",
       "    6.31344747543335,\n",
       "    6.293752670288086,\n",
       "    6.268531322479248,\n",
       "    6.23527717590332,\n",
       "    6.210179328918457,\n",
       "    6.194598197937012,\n",
       "    6.170181751251221,\n",
       "    6.145379543304443,\n",
       "    6.121821880340576,\n",
       "    6.095661640167236,\n",
       "    6.0733323097229],\n",
       "   'accuracy': [0.004987500142306089,\n",
       "    0.005100000184029341,\n",
       "    0.00559999980032444,\n",
       "    0.00572500005364418,\n",
       "    0.005137499887496233,\n",
       "    0.005912499967962503,\n",
       "    0.006124999839812517,\n",
       "    0.006162500008940697,\n",
       "    0.006137500051409006,\n",
       "    0.005737499799579382,\n",
       "    0.006262499839067459,\n",
       "    0.006187499966472387,\n",
       "    0.006612500175833702,\n",
       "    0.006887500174343586],\n",
       "   'val_loss': [5.535607814788818,\n",
       "    5.525020122528076,\n",
       "    5.51685905456543,\n",
       "    5.512446880340576,\n",
       "    5.509700775146484,\n",
       "    5.518462181091309,\n",
       "    5.518831729888916,\n",
       "    5.527840614318848,\n",
       "    5.520087718963623,\n",
       "    5.5228424072265625,\n",
       "    5.524868011474609,\n",
       "    5.524053573608398,\n",
       "    5.531241416931152,\n",
       "    5.524345874786377],\n",
       "   'val_accuracy': [0.005100000184029341,\n",
       "    0.004800000227987766,\n",
       "    0.005499999970197678,\n",
       "    0.005549999885261059,\n",
       "    0.0056500001810491085,\n",
       "    0.005799999926239252,\n",
       "    0.005950000137090683,\n",
       "    0.006200000178068876,\n",
       "    0.005950000137090683,\n",
       "    0.0056500001810491085,\n",
       "    0.005849999841302633,\n",
       "    0.005900000222027302,\n",
       "    0.005950000137090683,\n",
       "    0.006949999835342169]}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_list_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1322f7a-5ea9-4657-a197-917dd26c48b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3, learning_rate=0.001):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6421c-f79e-44e5-96a7-4de35610966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3, learning_rate=0.001):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "                                                                                                                      \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58d4b3c5-faef-4cc1-ad0f-cec94e44ed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 256)       7168      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 256)      1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 256)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 1024)      4719616   \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 1024)      9438208   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 1024)     4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 1024)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 2048)        18876416  \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 2048)        37750784  \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 2048)        37750784  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 2048)       8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 2048)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4, 4, 2048)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               8388864   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               51400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,517,768\n",
      "Trainable params: 133,509,576\n",
      "Non-trainable params: 8,192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      " 216/1250 [====>.........................] - ETA: 9:20 - loss: 5.8114 - accuracy: 0.0077"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(conv_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     56\u001b[0m conv_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[0;32m     57\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     58\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 60\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m history_list_2\u001b[38;5;241m.\u001b[39mappend({lr: history\u001b[38;5;241m.\u001b[39mhistory})\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3, learning_rate=0.001):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img)\n",
    "\n",
    "   \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "\n",
    "    # X = tf.keras.layers.Dense(units=256, activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    # X = tf.keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "history_list_2 = []\n",
    "for lr in [0.001, 0.0001, 0.00001, 0.000001]:\n",
    "    print(f'Learning rate: {lr}')\n",
    "    conv_model = convolutional_model((64, 64, 3))\n",
    "    print(conv_model.summary())\n",
    "    \n",
    "    conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=128, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.01,\n",
    "            patience=10,\n",
    "            verbose=0,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=False\n",
    "        )])\n",
    "    history_list_2.append({lr: history.history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82843a26-609b-4b06-88e8-50bef8eb840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.01\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               3277000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,736,584\n",
      "Trainable params: 34,732,744\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 319s 251ms/step - loss: 7.1723 - accuracy: 0.0122 - val_loss: 5.7966 - val_accuracy: 0.0073\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 11104s 9s/step - loss: 5.3263 - accuracy: 0.0170 - val_loss: 6.0818 - val_accuracy: 0.0120\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 5.3295 - accuracy: 0.0208 - val_loss: 86.4306 - val_accuracy: 0.0141\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 5.2314 - accuracy: 0.0303 - val_loss: 685950016.0000 - val_accuracy: 0.0224\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 5.1532 - accuracy: 0.0393 - val_loss: 361463.3750 - val_accuracy: 0.0273\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 5.1492 - accuracy: 0.0428 - val_loss: 474093408.0000 - val_accuracy: 0.0336\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 5.0645 - accuracy: 0.0514 - val_loss: 1227.7896 - val_accuracy: 0.0473\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 5.0138 - accuracy: 0.0578 - val_loss: 148732.5625 - val_accuracy: 0.0389\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.9758 - accuracy: 0.0624 - val_loss: 4708076.0000 - val_accuracy: 0.0465\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.9197 - accuracy: 0.0699 - val_loss: 256810096.0000 - val_accuracy: 0.0446\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.8615 - accuracy: 0.0763 - val_loss: 1769275264.0000 - val_accuracy: 0.0520\n",
      "Learning rate: 0.001\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               3277000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,736,584\n",
      "Trainable params: 34,732,744\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 6.4018 - accuracy: 0.0097 - val_loss: 5.5280 - val_accuracy: 0.0072\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.9932 - accuracy: 0.0253 - val_loss: 5.4257 - val_accuracy: 0.0222\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 298s 239ms/step - loss: 4.8158 - accuracy: 0.0405 - val_loss: 5.1904 - val_accuracy: 0.0277\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 298s 239ms/step - loss: 4.6437 - accuracy: 0.0560 - val_loss: 4.7432 - val_accuracy: 0.0538\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.5174 - accuracy: 0.0681 - val_loss: 5.6829 - val_accuracy: 0.0298\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.3928 - accuracy: 0.0832 - val_loss: 5.7250 - val_accuracy: 0.0355\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.2967 - accuracy: 0.0936 - val_loss: 5.0062 - val_accuracy: 0.0622\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 298s 239ms/step - loss: 4.2223 - accuracy: 0.1040 - val_loss: 5.0742 - val_accuracy: 0.0631\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 310s 248ms/step - loss: 4.1554 - accuracy: 0.1130 - val_loss: 5.4598 - val_accuracy: 0.0500\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 317s 254ms/step - loss: 4.0705 - accuracy: 0.1245 - val_loss: 5.7057 - val_accuracy: 0.0628\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 301s 240ms/step - loss: 4.0094 - accuracy: 0.1327 - val_loss: 10.6591 - val_accuracy: 0.0664\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.9295 - accuracy: 0.1445 - val_loss: 4.6579 - val_accuracy: 0.0964\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.8608 - accuracy: 0.1529 - val_loss: 4.4598 - val_accuracy: 0.1074\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.7831 - accuracy: 0.1674 - val_loss: 5.0071 - val_accuracy: 0.0850\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 301s 240ms/step - loss: 3.6971 - accuracy: 0.1791 - val_loss: 4.5463 - val_accuracy: 0.1079\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 301s 240ms/step - loss: 3.6308 - accuracy: 0.1913 - val_loss: 34.5048 - val_accuracy: 0.0931\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 301s 240ms/step - loss: 3.5672 - accuracy: 0.2011 - val_loss: 4.6597 - val_accuracy: 0.1082\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.5073 - accuracy: 0.2091 - val_loss: 4.8171 - val_accuracy: 0.1076\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 301s 240ms/step - loss: 3.4545 - accuracy: 0.2190 - val_loss: 4.9729 - val_accuracy: 0.0975\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 303s 243ms/step - loss: 3.4018 - accuracy: 0.2250 - val_loss: 4.6933 - val_accuracy: 0.1138\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.3895 - accuracy: 0.2286 - val_loss: 4.4508 - val_accuracy: 0.1345\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 303s 242ms/step - loss: 3.3126 - accuracy: 0.2429 - val_loss: 4.1431 - val_accuracy: 0.1544\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.2673 - accuracy: 0.2524 - val_loss: 14.1201 - val_accuracy: 0.1378\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.2237 - accuracy: 0.2594 - val_loss: 4.2459 - val_accuracy: 0.1573\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.2477 - accuracy: 0.2561 - val_loss: 4.0234 - val_accuracy: 0.1738\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.1422 - accuracy: 0.2742 - val_loss: 4.4872 - val_accuracy: 0.1498\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 302s 242ms/step - loss: 3.1010 - accuracy: 0.2804 - val_loss: 4.1670 - val_accuracy: 0.1637\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 3.0683 - accuracy: 0.2864 - val_loss: 6.8254 - val_accuracy: 0.1285\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 297s 238ms/step - loss: 3.0392 - accuracy: 0.2898 - val_loss: 4.8984 - val_accuracy: 0.1322\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 2.9896 - accuracy: 0.3018 - val_loss: 4.5947 - val_accuracy: 0.1469\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 2.9572 - accuracy: 0.3097 - val_loss: 4.9932 - val_accuracy: 0.1585\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 297s 238ms/step - loss: 2.9179 - accuracy: 0.3152 - val_loss: 133.0963 - val_accuracy: 0.1836\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 2.8884 - accuracy: 0.3207 - val_loss: 30.5205 - val_accuracy: 0.1943\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 298s 238ms/step - loss: 2.8552 - accuracy: 0.3271 - val_loss: 43.3281 - val_accuracy: 0.1597\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 297s 238ms/step - loss: 2.8181 - accuracy: 0.3346 - val_loss: 8.4664 - val_accuracy: 0.1660\n",
      "Learning rate: 0.0001\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               3277000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,736,584\n",
      "Trainable params: 34,732,744\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 302s 240ms/step - loss: 5.5798 - accuracy: 0.0213 - val_loss: 5.2542 - val_accuracy: 0.0330\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 4.8278 - accuracy: 0.0565 - val_loss: 4.9166 - val_accuracy: 0.0650\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 4.4747 - accuracy: 0.0910 - val_loss: 4.9377 - val_accuracy: 0.0692\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 4.2075 - accuracy: 0.1214 - val_loss: 4.9283 - val_accuracy: 0.0831\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 3.9781 - accuracy: 0.1502 - val_loss: 4.8879 - val_accuracy: 0.0892\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.7959 - accuracy: 0.1766 - val_loss: 4.6793 - val_accuracy: 0.1197\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.6146 - accuracy: 0.2030 - val_loss: 4.7480 - val_accuracy: 0.1121\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.4721 - accuracy: 0.2256 - val_loss: 4.6557 - val_accuracy: 0.1321\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.3483 - accuracy: 0.2446 - val_loss: 4.8222 - val_accuracy: 0.1240\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 3.2309 - accuracy: 0.2659 - val_loss: 4.1110 - val_accuracy: 0.1801\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 3.1207 - accuracy: 0.2852 - val_loss: 4.5600 - val_accuracy: 0.1417\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.0208 - accuracy: 0.3028 - val_loss: 5.1108 - val_accuracy: 0.1336\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.9332 - accuracy: 0.3170 - val_loss: 4.1761 - val_accuracy: 0.1924\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.8441 - accuracy: 0.3336 - val_loss: 5.2404 - val_accuracy: 0.1384\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.7543 - accuracy: 0.3507 - val_loss: 4.1678 - val_accuracy: 0.1952\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.6742 - accuracy: 0.3658 - val_loss: 4.3676 - val_accuracy: 0.1951\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.5918 - accuracy: 0.3800 - val_loss: 4.1288 - val_accuracy: 0.2089\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.5145 - accuracy: 0.3956 - val_loss: 4.5653 - val_accuracy: 0.1860\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.4430 - accuracy: 0.4103 - val_loss: 4.1211 - val_accuracy: 0.2251\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 2.3751 - accuracy: 0.4207 - val_loss: 4.3782 - val_accuracy: 0.2043\n",
      "Learning rate: 0.0001\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 64, 64, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 64, 64, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 32, 32, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 32, 32, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 16, 16, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 8, 8, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 8, 8, 1024)        4719616   \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 8, 8, 1024)        9438208   \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 8, 8, 1024)       4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 4, 4, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 200)               3277000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,736,584\n",
      "Trainable params: 34,732,744\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 302s 240ms/step - loss: 5.4995 - accuracy: 0.0249 - val_loss: 5.0662 - val_accuracy: 0.0428\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 4.7761 - accuracy: 0.0640 - val_loss: 5.1179 - val_accuracy: 0.0617\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 4.4281 - accuracy: 0.0967 - val_loss: 6.5144 - val_accuracy: 0.0331\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 4.1731 - accuracy: 0.1258 - val_loss: 4.9780 - val_accuracy: 0.0836\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.9616 - accuracy: 0.1532 - val_loss: 5.2172 - val_accuracy: 0.0803\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.7653 - accuracy: 0.1812 - val_loss: 4.5902 - val_accuracy: 0.1179\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 3.5925 - accuracy: 0.2083 - val_loss: 4.8090 - val_accuracy: 0.1099\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 3.4458 - accuracy: 0.2313 - val_loss: 4.6692 - val_accuracy: 0.1312\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 3.3189 - accuracy: 0.2517 - val_loss: 5.2916 - val_accuracy: 0.1053\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.2070 - accuracy: 0.2691 - val_loss: 4.9480 - val_accuracy: 0.1233\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.1023 - accuracy: 0.2873 - val_loss: 4.7545 - val_accuracy: 0.1361\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 3.0039 - accuracy: 0.3051 - val_loss: 4.3523 - val_accuracy: 0.1664\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.9065 - accuracy: 0.3236 - val_loss: 4.5370 - val_accuracy: 0.1637\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.8155 - accuracy: 0.3398 - val_loss: 4.3008 - val_accuracy: 0.1938\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.7333 - accuracy: 0.3536 - val_loss: 4.3125 - val_accuracy: 0.2025\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.6549 - accuracy: 0.3691 - val_loss: 4.6742 - val_accuracy: 0.1832\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.5714 - accuracy: 0.3853 - val_loss: 4.4575 - val_accuracy: 0.1917\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.4998 - accuracy: 0.3972 - val_loss: 4.5893 - val_accuracy: 0.1958\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.4262 - accuracy: 0.4119 - val_loss: 3.9436 - val_accuracy: 0.2318\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.3591 - accuracy: 0.4268 - val_loss: 4.6164 - val_accuracy: 0.1935\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.2886 - accuracy: 0.4392 - val_loss: 4.2972 - val_accuracy: 0.2202\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.2122 - accuracy: 0.4554 - val_loss: 4.3180 - val_accuracy: 0.2252\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 2.1566 - accuracy: 0.4644 - val_loss: 4.1859 - val_accuracy: 0.2406\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.0838 - accuracy: 0.4782 - val_loss: 4.1606 - val_accuracy: 0.2475\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 299s 239ms/step - loss: 2.0169 - accuracy: 0.4928 - val_loss: 4.3203 - val_accuracy: 0.2351\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 1.9552 - accuracy: 0.5066 - val_loss: 4.7121 - val_accuracy: 0.2213\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 1.8917 - accuracy: 0.5182 - val_loss: 4.2549 - val_accuracy: 0.2546\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 300s 239ms/step - loss: 1.8354 - accuracy: 0.5312 - val_loss: 4.9276 - val_accuracy: 0.2209\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 300s 240ms/step - loss: 1.7733 - accuracy: 0.5433 - val_loss: 4.5614 - val_accuracy: 0.2425\n"
     ]
    }
   ],
   "source": [
    "history_list = []\n",
    "for lr in [0.01, 0.001, 0.0001, 0.0001]:\n",
    "    print(f'Learning rate: {lr}')\n",
    "    conv_model = convolutional_model((64, 64, 3))\n",
    "    print(conv_model.summary())\n",
    "    \n",
    "    conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=256, epochs=200,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.01,\n",
    "            patience=10,\n",
    "            verbose=0,\n",
    "            mode='auto',\n",
    "            baseline=None,\n",
    "            restore_best_weights=False\n",
    "        )])\n",
    "    history_list.append({lr: history.history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd1d43-71d3-45f2-83b2-0773f7f65b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65916292-a9e0-4ada-9939-c6b03101aab5",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c028ef-9c4f-4205-9067-f6df7bf8240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not bad + increase filters\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    \n",
    "    X = tfl.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    # X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=1024, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332b61b-96cb-430b-98a6-ef13cd370234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d622c-08be-4274-a462-0d448d11526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=2048, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=1024, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    \n",
    "\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "print(conv_model.summary())\n",
    "\n",
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset, batch_size=16, epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5c0dd04-1566-4ff3-a5cd-21ade6d351bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 512)       1966592   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 16, 16, 1024)      4719616   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 1024)     4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 8, 2048)        18876416  \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 8, 8, 2048)       8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 4, 2048)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 2048)        0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 4, 4, 4096)        75501568  \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4, 4, 4096)       16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 2, 2, 4096)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               8389120   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,090,312\n",
      "Trainable params: 110,074,056\n",
      "Non-trainable params: 16,256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (5,5), strides = (1,1), padding='same')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (5,3), strides = (1,1), padding='same')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 4096 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "    X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='valid')(X)\n",
    "\n",
    "   \n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2cb6a72a-3037-41c5-a6bd-421d323f9721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " re_lu_41 (ReLU)             (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " re_lu_42 (ReLU)             (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " re_lu_43 (ReLU)             (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 16, 16, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 16, 16, 512)       1966592   \n",
      "                                                                 \n",
      " re_lu_44 (ReLU)             (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 16, 16, 1024)      4719616   \n",
      "                                                                 \n",
      " re_lu_45 (ReLU)             (None, 16, 16, 1024)      0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 8, 8, 1024)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 8, 8, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 8, 8, 2048)        18876416  \n",
      "                                                                 \n",
      " re_lu_46 (ReLU)             (None, 8, 8, 2048)        0         \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 4, 4, 2048)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 4, 4, 2048)        0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               16777728  \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,944,840\n",
      "Trainable params: 42,944,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 60 train 20 test\n",
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (5,5), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(1, 1), padding='same')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    # X = tf.keras.layers.Conv2D(filters = 4096 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "    # X = tf.keras.layers.ReLU()(X)\n",
    "    # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "   \n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7b1d2ca-b15e-4260-8ebd-2f4c654e6afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 64)        4864      \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 512)       1966592   \n",
      "                                                                 \n",
      " re_lu_25 (ReLU)             (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 1024)      4719616   \n",
      "                                                                 \n",
      " re_lu_26 (ReLU)             (None, 16, 16, 1024)      0         \n",
      "                                                                 \n",
      " average_pooling2d_11 (Avera  (None, 8, 8, 1024)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 8, 8, 1024)        0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               33554944  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,848,712\n",
      "Trainable params: 40,848,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def convolutional_model(input_shape, drop_out=0.3):\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (5,5), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (5,5), strides = (1,1), padding='same')(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (5,3), strides = (1,1), padding='same')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.layers.ReLU()(X)\n",
    "    X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    # X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "    # # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    # X = tf.keras.layers.ReLU()(X)\n",
    "    # X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    # X = tf.keras.layers.Conv2D(filters = 4096 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "    # # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    # X = tf.keras.layers.ReLU()(X)\n",
    "    # X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "   \n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "    return model\n",
    "\n",
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c11f6b08-a0fc-47cd-a57a-3ef53e00df5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " re_lu_12 (ReLU)             (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 32, 32, 32)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 64)        8256      \n",
      "                                                                 \n",
      " re_lu_13 (ReLU)             (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 16, 16, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 16, 16, 128)       32896     \n",
      "                                                                 \n",
      " re_lu_14 (ReLU)             (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 8, 8, 128)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,339,464\n",
      "Trainable params: 4,339,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (2,2), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (2,2), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "  \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Dense(units=512, activation='relu')(X)\n",
    "    \n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     # X = tf.keras.layers.Dropout(0.3)(X)\n",
    "   \n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e1e616-ce45-46f3-8a79-cd56f2dfc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (5,5), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (5,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 4096 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8353c1b6-6bb4-4e4f-a816-ad355ae16bb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 16 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (5,5), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (5,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 4096 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     # X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     # X = tf.keras.layers.Conv2D(filters = 2048 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(1,1), padding='same')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d7417be-f7cb-42d0-bffc-21bb4b8998a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def convolutional_model(input_shape, drop_out=0.3):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "   \n",
    "#     X = tf.keras.layers.Conv2D(filters = 16 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 512 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "#     X = tf.keras.layers.ReLU()(X)\n",
    "#     X = tf.keras.layers.Dropout(drop_out)(X)\n",
    "\n",
    "#     X = tf.keras.layers.Conv2D(filters = 1024 , kernel_size= (3,3), strides = (1,1), padding='same', activation='relu')(X)\n",
    "#     X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(1,1), padding='same')(X)\n",
    "\n",
    "   \n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "    \n",
    "\n",
    "#     # X = tf.keras.layers.Dense(units=50, activation='softmax')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 1)(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43152588-b080-4df0-8d75-7f0d6a09d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "# # X = tf.keras.layers.ReLU()(X)\n",
    "# # X = tfl.Add()([X, X_shortcut])\n",
    "\n",
    "\n",
    "# def convolutional_model(input_shape):\n",
    "#     input_img = tf.keras.Input(shape=input_shape)\n",
    "#     X = input_img\n",
    "#     # input_img = data_augmentation(input_img) # это с каждой эпохой происходит ци как? это вообще здесь должно быть?\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "   \n",
    "#     X = tf.keras.layers.Conv2D(filters = 16 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 32 , kernel_size= (3,3), strides = (1,1), padding='same')(X)  \n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "    \n",
    "#     # X_shortcut = X\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    \n",
    "#     # X = tf.keras.layers.Dropout(0.3)(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 64 , kernel_size= (1,1), strides = (1,1), padding='same')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "    \n",
    "#     X = tf.keras.layers.Conv2D(filters = 128 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "\n",
    "#     # X = tfl.Add()([X, X_shortcut])\n",
    "    \n",
    "#     X = tf.keras.layers.MaxPool2D(pool_size=(4,4), strides=(4, 4), padding='same')(X)\n",
    "\n",
    "#     # X = tf.keras.layers.Conv2D(filters = 256 , kernel_size= (3,3), strides = (1,1), padding='same')(X)\n",
    "#     # X = tfl.BatchNormalization(axis = 3)(X)\n",
    "#     # X = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "#     X = tf.keras.layers.Dropout(0.3)(X)\n",
    "#     X = tf.keras.layers.Flatten()(X)\n",
    "\n",
    "#     # X = tf.keras.layers.Dense(units=2000, activation='relu')(X)\n",
    "#     # X = tf.keras.layers.Dense(units=1000, activation='relu')(X)\n",
    "#     X = tf.keras.layers.Dense(units=200, activation='softmax')(X)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=input_img, outputs=X)\n",
    "#     return model\n",
    "\n",
    "# conv_model = convolutional_model((64, 64, 3))\n",
    "# # conv_model.compile(optimizer='adam',\n",
    "# #                   loss='categorical_crossentropy',\n",
    "# #                   metrics=['accuracy'])\n",
    "# print(conv_model.summary())\n",
    "\n",
    "# # когда перезапускаю эту ячейку, обучение продолжается с того места, где закончили?\n",
    "# # callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "# #         monitor='val_loss',\n",
    "# #         min_delta=0,\n",
    "# #         patience=0,\n",
    "# #         verbose=0,\n",
    "# #         mode='auto',\n",
    "# #         baseline=None,\n",
    "# #         restore_best_weights=False\n",
    "# #     )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9dbbe733-0b33-45de-9e55-9bf1a01e00cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# conv_model = tf.keras.applications.MobileNetV2(input_shape=(64,64,3),\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "727d8e51-3a9f-4456-bda8-ec8593dcc449",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd861975-5459-4d34-898c-88e1de8b5d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def alpaca_model(image_shape=(64,64,3), data_augmentation=data_augmenter()):\n",
    "\n",
    "#     base_model = tf.keras.applications.MobileNetV2(input_shape=image_shape,\n",
    "#                                                    include_top=False, \n",
    "#                                                    weights='imagenet') \n",
    "    \n",
    "#     base_model.trainable = True\n",
    "    \n",
    "#     inputs = tf.keras.Input(shape=image_shape) \n",
    "    \n",
    "#     x = data_augmentation(inputs)\n",
    "    \n",
    "#     x = tf.keras.applications.mobilenet_v2.preprocess_input(x) \n",
    "    \n",
    "#     x = base_model(x, training=True) \n",
    "    \n",
    "#     x = tfl.GlobalAveragePooling2D()(x) \n",
    "    \n",
    "#     x = tfl.Dropout(0.2)(x)\n",
    "        \n",
    "#     prediction_layer = tfl.Dense(units=200, activation='softmax')\n",
    "    \n",
    "#     outputs = prediction_layer(x) \n",
    "#     model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "#     return model\n",
    "    \n",
    "# conv_model = alpaca_model()\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b823c2f-7040-4579-ad35-b1176f0845aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 305s 240ms/step - loss: 5.2693 - accuracy: 0.0108 - val_loss: 5.2482 - val_accuracy: 0.0099\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 313s 250ms/step - loss: 5.0794 - accuracy: 0.0214 - val_loss: 5.3497 - val_accuracy: 0.0146\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 4.8677 - accuracy: 0.0342 - val_loss: 4.8929 - val_accuracy: 0.0316\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 4.6749 - accuracy: 0.0501 - val_loss: 4.6619 - val_accuracy: 0.0504\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 306s 245ms/step - loss: 4.4543 - accuracy: 0.0742 - val_loss: 4.4925 - val_accuracy: 0.0657\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 4.2751 - accuracy: 0.0945 - val_loss: 4.3596 - val_accuracy: 0.0783\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 4.1537 - accuracy: 0.1093 - val_loss: 4.2838 - val_accuracy: 0.0923\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 4.0635 - accuracy: 0.1235 - val_loss: 4.3002 - val_accuracy: 0.0962\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 3.9871 - accuracy: 0.1332 - val_loss: 4.2161 - val_accuracy: 0.1091\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 3.9202 - accuracy: 0.1416 - val_loss: 4.4474 - val_accuracy: 0.0970\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 307s 245ms/step - loss: 3.8617 - accuracy: 0.1524 - val_loss: 4.1024 - val_accuracy: 0.1225\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 3.8066 - accuracy: 0.1600 - val_loss: 4.0812 - val_accuracy: 0.1279\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 3.7609 - accuracy: 0.1673 - val_loss: 4.1420 - val_accuracy: 0.1287\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 308s 246ms/step - loss: 3.7130 - accuracy: 0.1736 - val_loss: 4.0549 - val_accuracy: 0.1382\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 3.6715 - accuracy: 0.1796 - val_loss: 4.0661 - val_accuracy: 0.1390\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 307s 246ms/step - loss: 3.6262 - accuracy: 0.1860 - val_loss: 4.0975 - val_accuracy: 0.1348\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 313s 250ms/step - loss: 3.5879 - accuracy: 0.1926 - val_loss: 3.9985 - val_accuracy: 0.1503\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 314s 251ms/step - loss: 3.5439 - accuracy: 0.1995 - val_loss: 3.9609 - val_accuracy: 0.1560\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 315s 252ms/step - loss: 3.4971 - accuracy: 0.2078 - val_loss: 3.9273 - val_accuracy: 0.1620\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 314s 251ms/step - loss: 3.4575 - accuracy: 0.2141 - val_loss: 3.9011 - val_accuracy: 0.1665\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 314s 251ms/step - loss: 3.4136 - accuracy: 0.2210 - val_loss: 3.9295 - val_accuracy: 0.1648\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 314s 251ms/step - loss: 3.3698 - accuracy: 0.2292 - val_loss: 3.9124 - val_accuracy: 0.1709\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 313s 251ms/step - loss: 3.3245 - accuracy: 0.2363 - val_loss: 4.0118 - val_accuracy: 0.1589\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 313s 251ms/step - loss: 3.2823 - accuracy: 0.2424 - val_loss: 3.8479 - val_accuracy: 0.1839\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 313s 250ms/step - loss: 3.2454 - accuracy: 0.2501 - val_loss: 3.9019 - val_accuracy: 0.1746\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 313s 251ms/step - loss: 3.2081 - accuracy: 0.2557 - val_loss: 3.7766 - val_accuracy: 0.1885\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 301s 241ms/step - loss: 3.1698 - accuracy: 0.2614 - val_loss: 3.9392 - val_accuracy: 0.1735\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 291s 232ms/step - loss: 3.1367 - accuracy: 0.2693 - val_loss: 3.8371 - val_accuracy: 0.1912\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 3.0967 - accuracy: 0.2776 - val_loss: 3.7253 - val_accuracy: 0.2065\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 291s 232ms/step - loss: 3.0637 - accuracy: 0.2828 - val_loss: 3.8133 - val_accuracy: 0.1958\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 3.0210 - accuracy: 0.2880 - val_loss: 3.8445 - val_accuracy: 0.1971\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 291s 232ms/step - loss: 2.9819 - accuracy: 0.2969 - val_loss: 3.8370 - val_accuracy: 0.1996\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.9344 - accuracy: 0.3059 - val_loss: 3.7676 - val_accuracy: 0.2125\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.8873 - accuracy: 0.3136 - val_loss: 3.7131 - val_accuracy: 0.2191\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.8351 - accuracy: 0.3237 - val_loss: 3.8056 - val_accuracy: 0.2107\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.7900 - accuracy: 0.3295 - val_loss: 3.7349 - val_accuracy: 0.2238\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.7476 - accuracy: 0.3397 - val_loss: 3.8347 - val_accuracy: 0.2130\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.6978 - accuracy: 0.3504 - val_loss: 3.7737 - val_accuracy: 0.2183\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.6526 - accuracy: 0.3577 - val_loss: 3.7505 - val_accuracy: 0.2262\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.6071 - accuracy: 0.3657 - val_loss: 3.6184 - val_accuracy: 0.2426\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.5656 - accuracy: 0.3747 - val_loss: 3.6690 - val_accuracy: 0.2385\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 290s 231ms/step - loss: 2.5299 - accuracy: 0.3825 - val_loss: 3.7539 - val_accuracy: 0.2302\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.4860 - accuracy: 0.3873 - val_loss: 3.8689 - val_accuracy: 0.2200\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 289s 231ms/step - loss: 2.4481 - accuracy: 0.3966 - val_loss: 3.8298 - val_accuracy: 0.2260\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.4098 - accuracy: 0.4060 - val_loss: 3.7508 - val_accuracy: 0.2362\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.3759 - accuracy: 0.4102 - val_loss: 3.7967 - val_accuracy: 0.2353\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.3410 - accuracy: 0.4196 - val_loss: 3.7678 - val_accuracy: 0.2383\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.3046 - accuracy: 0.4250 - val_loss: 4.0078 - val_accuracy: 0.2180\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.2757 - accuracy: 0.4294 - val_loss: 3.9007 - val_accuracy: 0.2327\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 290s 232ms/step - loss: 2.2387 - accuracy: 0.4362 - val_loss: 3.7935 - val_accuracy: 0.2409\n"
     ]
    }
   ],
   "source": [
    "conv_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history = conv_model.fit(train_dataset, validation_data=test_dataset,epochs=100,workers=-1, callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.001,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=False\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2657d7-9363-4c53-b210-66315f60563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.save(\"my_model_batch_norm_relu_0_001.h5\", include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2892074b-189e-4f9e-8063-4aa033d0d9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilyau\\AppData\\Local\\Temp\\ipykernel_15488\\3744616931.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\n",
      "C:\\Users\\ilyau\\AppData\\Local\\Temp\\ipykernel_15488\\3744616931.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Epoch'), Text(0, 0.5, 'Accuracy')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss_acc = pd.DataFrame(history.history)\n",
    "df_loss= df_loss_acc[['loss','val_loss']]\n",
    "df_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\n",
    "df_acc= df_loss_acc[['accuracy','val_accuracy']]\n",
    "df_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\n",
    "df_loss.plot(title='Model loss',figsize=(6,3)).set(xlabel='Epoch',ylabel='Loss')\n",
    "df_acc.plot(title='Model Accuracy',figsize=(6,3)).set(xlabel='Epoch',ylabel='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789cc4e-7c47-4ffa-bb50-d3972d463dda",
   "metadata": {},
   "source": [
    "* data augmentation\n",
    "* normalize image\n",
    "* reshape label vector (from horizontal, to vertical)\n",
    "* create model\n",
    "* fit\n",
    "* test\n",
    "* validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
